# ===================================================================
# UPSAMPLING STRATEGY 1: Apply Gaussian Noise Upsampling to Training Set
# ===================================================================

import numpy as np
from sklearn.model_selection import train_test_split

# Gaussian Noise Upsampling Function (moved from validation to training set)
def gaussian_noise_upsampling(X, y, noise_std=0.1, random_state=42):
    """
    Generate synthetic samples for minority class using Gaussian noise.
    Applied to TRAINING set to balance classes before model training.
    """
    np.random.seed(random_state)

    # Find minority and majority classes
    unique_labels, counts = np.unique(y, return_counts=True)
    label_counts = dict(zip(unique_labels, counts))
    minority_label = min(label_counts, key=label_counts.get)
    majority_count = max(label_counts.values())
    minority_count = label_counts[minority_label]

    print(f"Original training: healthy={label_counts.get(0, 0)}, diseased={label_counts.get(1, 0)}")

    # Get minority samples and generate synthetic ones
    minority_mask = (y == minority_label)
    minority_X = X[minority_mask].copy()
    samples_needed = majority_count - minority_count

    synthetic_X_list = []
    synthetic_y_list = []

    for i in range(samples_needed):
        # Pick random minority sample as base
        base_idx = np.random.randint(0, len(minority_X))
        base_sample = minority_X[base_idx].copy()

        # Add noise only to non-zero species
        nonzero_mask = base_sample > 0
        noise = np.random.normal(0, noise_std, size=base_sample.shape)
        noise[~nonzero_mask] = 0  # Zero out noise for zero abundance species

        synthetic_sample = base_sample + noise
        synthetic_sample = np.maximum(synthetic_sample, 0)  # No negative values

        # Renormalize to maintain relative abundance
        if synthetic_sample.sum() > 0:
            synthetic_sample = synthetic_sample / synthetic_sample.sum()

        synthetic_X_list.append(synthetic_sample)
        synthetic_y_list.append(minority_label)

    # Combine original + synthetic
    X_balanced = np.vstack([X, np.array(synthetic_X_list)])
    y_balanced = np.hstack([y, np.array(synthetic_y_list)])

    final_unique, final_counts = np.unique(y_balanced, return_counts=True)
    final_label_counts = dict(zip(final_unique, final_counts))
    print(f"After up-sampling: healthy={final_label_counts.get(0, 0)}, diseased={final_label_counts.get(1, 0)}")

    stats = {"synthetic_generated": samples_needed, "final_distribution": final_label_counts}
    return X_balanced, y_balanced, stats

# Step 1: Re-split data with labels (replacing the simple split from previous cell)
print("=== SPLITTING DATA WITH LABELS ===")
(
    train_data_raw,
    valid_data_with_labels,
    train_labels,
    valid_labels,
) = train_test_split(
    all_counts, y_all, test_size=0.1, shuffle=True, stratify=y_all, random_state=42
)

print(f"Initial split - Train: {train_data_raw.shape[0]} samples, Valid: {valid_data_with_labels.shape[0]} samples")

# Step 2: Apply upsampling to TRAINING set only
print("\n=== APPLYING UPSAMPLING TO TRAINING SET ===")
train_data_balanced, train_labels_balanced, upsampling_stats = gaussian_noise_upsampling(
    train_data_raw, train_labels, noise_std=0.1, random_state=42
)

print(f"Training set after upsampling: {train_data_balanced.shape[0]} samples")
print(f"Synthetic samples generated: {upsampling_stats['synthetic_generated']}")

# Update variables for compatibility with existing code
train_data = train_data_balanced  # Replace original train_data with balanced version
valid_data = valid_data_with_labels  # Keep validation data unchanged

print(f"\nFinal data shapes:")
print(f"  train_data (upsampled): {train_data.shape}")
print(f"  valid_data: {valid_data.shape}")
print(f"  train_labels_balanced: {train_labels_balanced.shape}")
print(f"  valid_labels: {valid_labels.shape}")

# Store the labels for later use
y_train = train_labels_balanced
y_valid = valid_labels{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"VYHHhpslyhCX","executionInfo":{"status":"ok","timestamp":1756434005144,"user_tz":240,"elapsed":4,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["# 1. V1 Working with full-attention across all tokens\n","# 2. Implemented attention mask\n","# 3. Try shuffling the data and remove the excess loss functions\n","# 4. More efficient vocab\n","# 5. Add LassoCV feature selection\n","# 6. Only attend to non-zero tokens per sample\n","# 7. Get rid of the appended cls embeddings at the beginning, do classification during finetuning with a weighted combination of the organisms (doesn't improve result)\n","# 8. Go back to using the cls token, pretrain on the GMHI dataset\n","# 9. Pretrain on all 7,009 samples from HMP2 + GMHI + MGX.\n","# 10. Pretrain on all data V1\n","# 11. Pretrain on all data (13k samples)"]},{"cell_type":"markdown","metadata":{"id":"c17eld0itGLo"},"source":["# Load Data"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28301,"status":"ok","timestamp":1756754306309,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"},"user_tz":240},"id":"FSsb1jnUtFyN","outputId":"d45d49cc-c1c8-4fcf-ab69-c3aa928cf495"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Do not use this, just loaded the original 4347 txt file"],"metadata":{"id":"Jcb54q75P9fW"}},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1756434032411,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"},"user_tz":240},"id":"ATEeyysYtRyX"},"outputs":[],"source":["# %cd /content/drive/My\\ Drive/Siyao_Ali/data\n","\n","# df_training_data = pd.read_csv(\n","#     \"4347_final_relative_abundances.txt\",\n","#     sep=\"\\t\",\n","#     index_col=0\n","# ).T\n","\n","# df_training_data.index.name = None\n","\n","# result = (df_training_data.sum(axis=1) - 100).abs().le(25).all()\n","# assert result, \"Some samples do not sum to ~100%\"\n","\n","# print(df_training_data.shape)\n","# print(df_training_data.index)\n","# print(df_training_data.columns)"]},{"cell_type":"markdown","source":["# Switch to the 313 species"],"metadata":{"id":"MUCALqvDDmFB"}},{"cell_type":"code","source":["# Colab / Google Drive path\n","%cd /content/drive/My\\ Drive/Siyao_Ali/data\n","\n","import pandas as pd\n","import numpy as np\n","import re\n","\n","def normalize_species_name(x: str) -> str:\n","    if pd.isna(x):\n","        return x\n","    s = str(x).strip()\n","\n","    # Drop taxonomic prefixes like s__, g__, etc.\n","    s = re.sub(r'^[a-z]__', '', s)\n","\n","    # Unify separators\n","    s = s.replace('/', ' ')\n","    s = s.replace('_', ' ')\n","    s = s.replace('-', ' ')\n","\n","    # Standardize \"sp.\" -> \"sp\"\n","    s = re.sub(r'(?i)\\bsp\\.\\b', 'sp', s)\n","\n","    # Remove remaining punctuation except alphanumerics and spaces\n","    s = re.sub(r'[^A-Za-z0-9 ]+', ' ', s)\n","\n","    # Collapse multiple spaces\n","    s = re.sub(r'\\s+', ' ', s).strip()\n","\n","    return s\n","\n","# 1) Load 4347 abundance table\n","df_training_data = pd.read_csv(\n","    \"4347_final_relative_abundances.txt\",\n","    sep=\"\\t\",\n","    index_col=0\n",").T\n","\n","df_training_data.index.name = None\n","\n","result = (df_training_data.sum(axis=1) - 100).abs().le(25).all()\n","assert result, \"Some samples do not sum to ~100%\"\n","\n","print(\"Original df_training_data shape:\", df_training_data.shape)   # (n_samples, n_species_raw)\n","print(\"Samples:\", len(df_training_data.index))\n","print(\"Raw species columns:\", len(df_training_data.columns))\n","\n","# Make a clean view with normalized species column names\n","df_training_data_clean = df_training_data.copy()\n","df_training_data_clean.columns = [normalize_species_name(c) for c in df_training_data.columns]\n","\n","# 2) Robust loader for 313 species\n","def load_313_species_from_excel(path: str, min_unique: int = 200):\n","    xls = pd.ExcelFile(path)\n","    best_list = None\n","    best_n = 0\n","\n","    for sheet in xls.sheet_names:\n","        df = pd.read_excel(xls, sheet_name=sheet, header=0)\n","\n","        # Heuristic A: Nature Supplementary layout (giant text in first col header, species in last col; first row is a header row)\n","        if \"Supplementary\" in str(df.columns[0]):\n","            series = df.iloc[1:, -1]  # skip the first metadata row, take last column\n","        else:\n","            # Heuristic B: if a column name contains \"species\", take that\n","            cand_cols = [c for c in df.columns if re.search(r\"species\", str(c), re.I)]\n","            if len(cand_cols) >= 1:\n","                series = df[cand_cols[0]]\n","            else:\n","                # Fallback: take last column\n","                series = df.iloc[:, -1]\n","\n","        # Clean up and drop header-like rows\n","        series = series.dropna().astype(str)\n","        series = series[~series.str.fullmatch(r'(?i)species|family|phylum')]\n","\n","        species_norm = series.map(normalize_species_name)\n","        species_norm = species_norm[species_norm.str.contains(r\"\\s\")]\n","        uniq = pd.unique(species_norm)\n","\n","        if len(uniq) > best_n:\n","            best_n = len(uniq)\n","            best_list = list(uniq)\n","\n","    if best_list is None or best_n < min_unique:\n","        raise ValueError(f\"Could not find a plausible 313-species column in '{path}'. Best unique count: {best_n}\")\n","    return best_list\n","\n","species_313 = load_313_species_from_excel(\"313_species.xlsx\")\n","print(\"\\nUnique species in 313 list:\", len(species_313))\n","\n","# 3) Match against abundance table\n","all_cols_clean = set(df_training_data_clean.columns)\n","matched = [s for s in species_313 if s in all_cols_clean]\n","missing = [s for s in species_313 if s not in all_cols_clean]\n","\n","print(f\"Matched species: {len(matched)}\")\n","print(f\"Missing species: {len(missing)}\")\n","\n","# example = \"s__Acidaminococcus_intestini\"\n","# print(\"Normalization demo:\", example, \"->\", normalize_species_name(example))\n","\n","# 4) Build filtered abundance with matched species only\n","df_matched = df_training_data_clean.loc[:, matched].copy()\n","print(\"\\nFiltered (matched-only) shape (samples x matched_species):\", df_matched.shape)\n","\n","pd.Series(matched, name=\"MatchedSpecies\").to_csv(\"matched_species_from_313.txt\", index=False, header=False)\n","pd.Series(missing, name=\"MissingSpecies\").to_csv(\"missing_species_from_313.txt\", index=False, header=False)\n","df_matched.to_csv(\"4347_abundance_matched_313_species.csv\")\n","\n","print(\"\\nSaved files:\")\n","print(\" - matched_species_from_313.txt\")\n","print(\" - missing_species_from_313.txt\")\n","print(\" - 4347_abundance_matched_313_species.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcE6jB2yDo3K","executionInfo":{"status":"ok","timestamp":1756754337125,"user_tz":240,"elapsed":5469,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"0a578983-c653-4ec2-d1fd-27f7d5fea709"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Siyao_Ali/data\n","Original df_training_data shape: (4347, 903)\n","Samples: 4347\n","Raw species columns: 903\n","\n","Unique species in 313 list: 313\n","Matched species: 311\n","Missing species: 2\n","\n","Filtered (matched-only) shape (samples x matched_species): (4347, 311)\n","\n","Saved files:\n"," - matched_species_from_313.txt\n"," - missing_species_from_313.txt\n"," - 4347_abundance_matched_313_species.csv\n"]}]},{"cell_type":"code","source":["df_training_data = pd.read_csv(\n","    \"4347_abundance_matched_313_species.csv\",\n","    index_col=0\n",")\n","\n","df_training_data.index.name = None\n","df_training_data = df_training_data.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n","\n","print(\"Loaded df_training_data shape:\", df_training_data.shape)   # (n_samples, n_matched_species)\n","print(\"Samples:\", len(df_training_data.index))\n","print(\"Matched species columns:\", len(df_training_data.columns))\n","\n","# Row sums will be ≤ 100% because this is a subset of species\n","row_sums = df_training_data.sum(axis=1)\n","print(\"Row sum stats (%): min/median/max =\",\n","      round(row_sums.min(), 3),\n","      round(row_sums.median(), 3),\n","      round(row_sums.max(), 3))\n","\n","# Optional sanity: all rows within [0, 100 + tolerance]\n","tol = 1e-6\n","assert (row_sums >= -tol).all() and (row_sums <= 100 + tol).all(), \"Some rows outside [0, 100]%\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tgZwXZOP3Vt","executionInfo":{"status":"ok","timestamp":1756754342046,"user_tz":240,"elapsed":218,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"71aa7a1a-aed7-4a94-d9e7-ebfff798f5f3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded df_training_data shape: (4347, 311)\n","Samples: 4347\n","Matched species columns: 311\n","Row sum stats (%): min/median/max = 28.435 92.48 99.916\n"]}]},{"cell_type":"markdown","metadata":{"id":"CEMj3aepMUHN"},"source":["# Download Packages"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44753,"status":"ok","timestamp":1756754389246,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"},"user_tz":240},"id":"mUO6pJ05HgMm","outputId":"d08587ae-532c-4ae2-df57-6d1a8c5fb9f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/169.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install --quiet scanpy\n","!pip install --quiet wandb\n","!pip install --quiet flash-attn --no-build-isolation # figure out flashAtteƒntion later\n","# !pip install --quiet hydra-core --upgrade # package for managing complex configurations for projects"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1579,"status":"ok","timestamp":1756754390833,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"},"user_tz":240},"id":"Df1JNWj71mlY","outputId":"9ecaddb4-a57d-4434-de7c-ee9252761d9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.12.11\n","Package                               Version\n","------------------------------------- -------------------\n","absl-py                               1.4.0\n","absolufy-imports                      0.3.1\n","accelerate                            1.10.1\n","aiofiles                              24.1.0\n","aiohappyeyeballs                      2.6.1\n","aiohttp                               3.12.15\n","aiosignal                             1.4.0\n","alabaster                             1.0.0\n","albucore                              0.0.24\n","albumentations                        2.0.8\n","ale-py                                0.11.2\n","altair                                5.5.0\n","anndata                               0.12.2\n","annotated-types                       0.7.0\n","antlr4-python3-runtime                4.9.3\n","anyio                                 4.10.0\n","anywidget                             0.9.18\n","argon2-cffi                           25.1.0\n","argon2-cffi-bindings                  25.1.0\n","array-api-compat                      1.12.0\n","array_record                          0.8.1\n","arviz                                 0.22.0\n","astropy                               7.1.0\n","astropy-iers-data                     0.2025.8.25.0.36.58\n","astunparse                            1.6.3\n","atpublic                              5.1\n","attrs                                 25.3.0\n","audioread                             3.0.1\n","Authlib                               1.6.2\n","autograd                              1.8.0\n","babel                                 2.17.0\n","backcall                              0.2.0\n","beartype                              0.21.0\n","beautifulsoup4                        4.13.5\n","betterproto                           2.0.0b6\n","bigframes                             2.17.0\n","bigquery-magics                       0.10.3\n","bleach                                6.2.0\n","blinker                               1.9.0\n","blis                                  1.3.0\n","blobfile                              3.0.0\n","blosc2                                3.7.2\n","bokeh                                 3.7.3\n","Bottleneck                            1.4.2\n","bqplot                                0.12.45\n","branca                                0.8.1\n","Brotli                                1.1.0\n","build                                 1.3.0\n","CacheControl                          0.14.3\n","cachetools                            5.5.2\n","catalogue                             2.0.10\n","certifi                               2025.8.3\n","cffi                                  1.17.1\n","chardet                               5.2.0\n","charset-normalizer                    3.4.3\n","chex                                  0.1.90\n","clarabel                              0.11.1\n","click                                 8.2.1\n","cloudpathlib                          0.21.1\n","cloudpickle                           3.1.1\n","cmake                                 3.31.6\n","cmdstanpy                             1.2.5\n","colorcet                              3.1.0\n","colorlover                            0.3.0\n","colour                                0.1.5\n","community                             1.0.0b1\n","confection                            0.1.5\n","cons                                  0.4.7\n","contourpy                             1.3.3\n","cramjam                               2.11.0\n","crc32c                                2.7.1\n","cryptography                          43.0.3\n","cuda-python                           12.6.2.post1\n","cudf-cu12                             25.6.0\n","cudf-polars-cu12                      25.6.0\n","cufflinks                             0.17.3\n","cuml-cu12                             25.6.0\n","cupy-cuda12x                          13.3.0\n","curl_cffi                             0.13.0\n","cuvs-cu12                             25.6.1\n","cvxopt                                1.3.2\n","cvxpy                                 1.6.7\n","cycler                                0.12.1\n","cyipopt                               1.5.0\n","cymem                                 2.0.11\n","Cython                                3.0.12\n","dask                                  2025.5.0\n","dask-cuda                             25.6.0\n","dask-cudf-cu12                        25.6.0\n","dataproc-spark-connect                0.8.3\n","datasets                              4.0.0\n","db-dtypes                             1.4.3\n","dbus-python                           1.2.18\n","debugpy                               1.8.15\n","decorator                             4.4.2\n","defusedxml                            0.7.1\n","diffusers                             0.35.1\n","dill                                  0.3.8\n","distributed                           2025.5.0\n","distributed-ucxx-cu12                 0.44.0\n","distro                                1.9.0\n","dlib                                  19.24.6\n","dm-tree                               0.1.9\n","docstring_parser                      0.17.0\n","docutils                              0.21.2\n","donfig                                0.8.1.post1\n","dopamine_rl                           4.1.2\n","duckdb                                1.3.2\n","earthengine-api                       1.5.24\n","easydict                              1.13\n","editdistance                          0.8.1\n","eerepr                                0.1.2\n","einops                                0.8.1\n","en_core_web_sm                        3.8.0\n","entrypoints                           0.4\n","et_xmlfile                            2.0.0\n","etils                                 1.13.0\n","etuples                               0.3.10\n","Farama-Notifications                  0.0.4\n","fastai                                2.8.4\n","fastapi                               0.116.1\n","fastcore                              1.8.8\n","fastdownload                          0.0.7\n","fastjsonschema                        2.21.2\n","fastprogress                          1.0.3\n","fastrlock                             0.8.3\n","fasttransform                         0.0.2\n","ffmpy                                 0.6.1\n","filelock                              3.19.1\n","firebase-admin                        6.9.0\n","flash_attn                            2.8.3\n","Flask                                 3.1.2\n","flatbuffers                           25.2.10\n","flax                                  0.10.6\n","folium                                0.20.0\n","fonttools                             4.59.1\n","frozendict                            2.4.6\n","frozenlist                            1.7.0\n","fsspec                                2025.3.0\n","future                                1.0.0\n","gast                                  0.6.0\n","gcsfs                                 2025.3.0\n","GDAL                                  3.8.4\n","gdown                                 5.2.0\n","geemap                                0.35.3\n","geocoder                              1.38.1\n","geographiclib                         2.1\n","geopandas                             1.1.1\n","geopy                                 2.4.1\n","gin-config                            0.5.0\n","gitdb                                 4.0.12\n","GitPython                             3.1.45\n","glob2                                 0.7\n","google                                2.0.3\n","google-adk                            1.12.0\n","google-ai-generativelanguage          0.6.15\n","google-api-core                       2.25.1\n","google-api-python-client              2.179.0\n","google-auth                           2.38.0\n","google-auth-httplib2                  0.2.0\n","google-auth-oauthlib                  1.2.2\n","google-cloud-aiplatform               1.110.0\n","google-cloud-appengine-logging        1.6.2\n","google-cloud-audit-log                0.3.2\n","google-cloud-bigquery                 3.36.0\n","google-cloud-bigquery-connection      1.18.3\n","google-cloud-bigquery-storage         2.32.0\n","google-cloud-bigtable                 2.32.0\n","google-cloud-core                     2.4.3\n","google-cloud-dataproc                 5.21.0\n","google-cloud-datastore                2.21.0\n","google-cloud-firestore                2.21.0\n","google-cloud-functions                1.20.4\n","google-cloud-language                 2.17.2\n","google-cloud-logging                  3.12.1\n","google-cloud-resource-manager         1.14.2\n","google-cloud-secret-manager           2.24.0\n","google-cloud-spanner                  3.57.0\n","google-cloud-speech                   2.33.0\n","google-cloud-storage                  2.19.0\n","google-cloud-trace                    1.16.2\n","google-cloud-translate                3.21.1\n","google-colab                          1.0.0\n","google-crc32c                         1.7.1\n","google-genai                          1.31.0\n","google-generativeai                   0.8.5\n","google-pasta                          0.2.0\n","google-resumable-media                2.7.2\n","googleapis-common-protos              1.70.0\n","googledrivedownloader                 1.1.0\n","gradio                                5.43.1\n","gradio_client                         1.12.1\n","graphviz                              0.21\n","greenlet                              3.2.4\n","groovy                                0.1.2\n","grpc-google-iam-v1                    0.14.2\n","grpc-interceptor                      0.15.4\n","grpcio                                1.74.0\n","grpcio-status                         1.71.2\n","grpclib                               0.4.8\n","gspread                               6.2.1\n","gspread-dataframe                     4.0.0\n","gym                                   0.25.2\n","gym-notices                           0.1.0\n","gymnasium                             1.2.0\n","h11                                   0.16.0\n","h2                                    4.3.0\n","h5netcdf                              1.6.4\n","h5py                                  3.14.0\n","hdbscan                               0.8.40\n","hf_transfer                           0.1.9\n","hf-xet                                1.1.8\n","highspy                               1.11.0\n","holidays                              0.79\n","holoviews                             1.21.0\n","hpack                                 4.1.0\n","html5lib                              1.1\n","httpcore                              1.0.9\n","httpimport                            1.4.1\n","httplib2                              0.22.0\n","httpx                                 0.28.1\n","httpx-sse                             0.4.1\n","huggingface-hub                       0.34.4\n","humanize                              4.13.0\n","hyperframe                            6.1.0\n","hyperopt                              0.2.7\n","ibis-framework                        9.5.0\n","idna                                  3.10\n","imageio                               2.37.0\n","imageio-ffmpeg                        0.6.0\n","imagesize                             1.4.1\n","imbalanced-learn                      0.14.0\n","immutabledict                         4.2.1\n","importlib_metadata                    8.7.0\n","importlib_resources                   6.5.2\n","imutils                               0.5.4\n","inflect                               7.5.0\n","iniconfig                             2.1.0\n","intel-cmplr-lib-ur                    2025.2.1\n","intel-openmp                          2025.2.1\n","ipyevents                             2.0.2\n","ipyfilechooser                        0.6.0\n","ipykernel                             6.17.1\n","ipyleaflet                            0.20.0\n","ipyparallel                           8.8.0\n","ipython                               7.34.0\n","ipython-genutils                      0.2.0\n","ipython-sql                           0.5.0\n","ipytree                               0.2.2\n","ipywidgets                            7.7.1\n","itsdangerous                          2.2.0\n","jaraco.classes                        3.4.0\n","jaraco.context                        6.0.1\n","jaraco.functools                      4.3.0\n","jax                                   0.5.3\n","jax-cuda12-pjrt                       0.5.3\n","jax-cuda12-plugin                     0.5.3\n","jaxlib                                0.5.3\n","jeepney                               0.9.0\n","jieba                                 0.42.1\n","Jinja2                                3.1.6\n","jiter                                 0.10.0\n","joblib                                1.5.1\n","jsonpatch                             1.33\n","jsonpickle                            4.1.1\n","jsonpointer                           3.0.0\n","jsonschema                            4.25.1\n","jsonschema-specifications             2025.4.1\n","jupyter-client                        6.1.12\n","jupyter-console                       6.1.0\n","jupyter_core                          5.8.1\n","jupyter_kernel_gateway                2.5.2\n","jupyter-leaflet                       0.20.0\n","jupyter-server                        1.16.0\n","jupyterlab_pygments                   0.3.0\n","jupyterlab_widgets                    3.0.15\n","jupytext                              1.17.2\n","kaggle                                1.7.4.5\n","kagglehub                             0.3.12\n","keras                                 3.10.0\n","keras-hub                             0.21.1\n","keras-nlp                             0.21.1\n","keyring                               25.6.0\n","keyrings.google-artifactregistry-auth 1.1.2\n","kiwisolver                            1.4.9\n","langchain                             0.3.27\n","langchain-core                        0.3.74\n","langchain-text-splitters              0.3.9\n","langcodes                             3.5.0\n","langsmith                             0.4.16\n","language_data                         1.3.0\n","launchpadlib                          1.10.16\n","lazr.restfulclient                    0.14.4\n","lazr.uri                              1.0.6\n","lazy_loader                           0.4\n","legacy-api-wrap                       1.4.1\n","libclang                              18.1.1\n","libcudf-cu12                          25.6.0\n","libcugraph-cu12                       25.6.0\n","libcuml-cu12                          25.6.0\n","libcuvs-cu12                          25.6.1\n","libkvikio-cu12                        25.6.0\n","libpysal                              4.13.0\n","libraft-cu12                          25.6.0\n","librmm-cu12                           25.6.0\n","librosa                               0.11.0\n","libucx-cu12                           1.18.1\n","libucxx-cu12                          0.44.0\n","lightgbm                              4.6.0\n","linkify-it-py                         2.0.3\n","llvmlite                              0.43.0\n","locket                                1.0.0\n","logical-unification                   0.4.6\n","lxml                                  5.4.0\n","Mako                                  1.1.3\n","marisa-trie                           1.3.0\n","Markdown                              3.8.2\n","markdown-it-py                        4.0.0\n","MarkupSafe                            3.0.2\n","matplotlib                            3.10.0\n","matplotlib-inline                     0.1.7\n","matplotlib-venn                       1.1.2\n","mcp                                   1.13.1\n","mdit-py-plugins                       0.5.0\n","mdurl                                 0.1.2\n","miniKanren                            1.0.5\n","missingno                             0.5.2\n","mistune                               3.1.3\n","mizani                                0.13.5\n","mkl                                   2025.2.0\n","ml_dtypes                             0.5.3\n","mlxtend                               0.23.4\n","more-itertools                        10.7.0\n","moviepy                               1.0.3\n","mpmath                                1.3.0\n","msgpack                               1.1.1\n","multidict                             6.6.4\n","multipledispatch                      1.0.0\n","multiprocess                          0.70.16\n","multitasking                          0.0.12\n","murmurhash                            1.0.13\n","music21                               9.3.0\n","namex                                 0.1.0\n","narwhals                              2.2.0\n","natsort                               8.4.0\n","nbclassic                             1.3.1\n","nbclient                              0.10.2\n","nbconvert                             7.16.6\n","nbformat                              5.10.4\n","ndindex                               1.10.0\n","nest-asyncio                          1.6.0\n","networkx                              3.5\n","nibabel                               5.3.2\n","nltk                                  3.9.1\n","notebook                              6.5.7\n","notebook_shim                         0.2.4\n","numba                                 0.60.0\n","numba-cuda                            0.11.0\n","numcodecs                             0.16.2\n","numexpr                               2.11.0\n","numpy                                 2.0.2\n","nvidia-cublas-cu12                    12.6.4.1\n","nvidia-cuda-cupti-cu12                12.6.80\n","nvidia-cuda-nvcc-cu12                 12.5.82\n","nvidia-cuda-nvrtc-cu12                12.6.77\n","nvidia-cuda-runtime-cu12              12.6.77\n","nvidia-cudnn-cu12                     9.10.2.21\n","nvidia-cufft-cu12                     11.3.0.4\n","nvidia-cufile-cu12                    1.11.1.6\n","nvidia-curand-cu12                    10.3.7.77\n","nvidia-cusolver-cu12                  11.7.1.2\n","nvidia-cusparse-cu12                  12.5.4.2\n","nvidia-cusparselt-cu12                0.7.1\n","nvidia-ml-py                          12.575.51\n","nvidia-nccl-cu12                      2.27.3\n","nvidia-nvjitlink-cu12                 12.6.85\n","nvidia-nvtx-cu12                      12.6.77\n","nvtx                                  0.2.13\n","nx-cugraph-cu12                       25.6.0\n","oauth2client                          4.1.3\n","oauthlib                              3.3.1\n","omegaconf                             2.3.0\n","openai                                1.101.0\n","opencv-contrib-python                 4.12.0.88\n","opencv-python                         4.12.0.88\n","opencv-python-headless                4.12.0.88\n","openpyxl                              3.1.5\n","opentelemetry-api                     1.36.0\n","opentelemetry-exporter-gcp-trace      1.9.0\n","opentelemetry-resourcedetector-gcp    1.9.0a0\n","opentelemetry-sdk                     1.36.0\n","opentelemetry-semantic-conventions    0.57b0\n","opt_einsum                            3.4.0\n","optax                                 0.2.5\n","optree                                0.17.0\n","orbax-checkpoint                      0.11.23\n","orjson                                3.11.2\n","osqp                                  1.0.4\n","packaging                             25.0\n","pandas                                2.2.2\n","pandas-datareader                     0.10.0\n","pandas-gbq                            0.29.2\n","pandas-stubs                          2.2.2.240909\n","pandocfilters                         1.5.1\n","panel                                 1.7.5\n","param                                 2.2.1\n","parso                                 0.8.5\n","parsy                                 2.1\n","partd                                 1.4.2\n","patsy                                 1.0.1\n","peewee                                3.18.2\n","peft                                  0.17.1\n","pexpect                               4.9.0\n","pickleshare                           0.7.5\n","pillow                                11.3.0\n","pip                                   24.1.2\n","platformdirs                          4.3.8\n","plotly                                5.24.1\n","plotnine                              0.14.5\n","pluggy                                1.6.0\n","plum-dispatch                         2.5.7\n","ply                                   3.11\n","polars                                1.25.2\n","pooch                                 1.8.2\n","portpicker                            1.5.2\n","preshed                               3.0.10\n","prettytable                           3.16.0\n","proglog                               0.1.12\n","progressbar2                          4.5.0\n","prometheus_client                     0.22.1\n","promise                               2.3\n","prompt_toolkit                        3.0.51\n","propcache                             0.3.2\n","prophet                               1.1.7\n","proto-plus                            1.26.1\n","protobuf                              5.29.5\n","psutil                                5.9.5\n","psycopg2                              2.9.10\n","psygnal                               0.14.1\n","ptyprocess                            0.7.0\n","py-cpuinfo                            9.0.0\n","py4j                                  0.10.9.7\n","pyarrow                               18.1.0\n","pyasn1                                0.6.1\n","pyasn1_modules                        0.4.2\n","pycairo                               1.28.0\n","pycocotools                           2.0.10\n","pycparser                             2.22\n","pycryptodomex                         3.23.0\n","pydantic                              2.11.7\n","pydantic_core                         2.33.2\n","pydantic-settings                     2.10.1\n","pydata-google-auth                    1.9.1\n","pydot                                 3.0.4\n","pydotplus                             2.0.2\n","PyDrive2                              1.21.3\n","pydub                                 0.25.1\n","pyerfa                                2.0.1.5\n","pygame                                2.6.1\n","pygit2                                1.18.2\n","Pygments                              2.19.2\n","PyGObject                             3.42.0\n","PyJWT                                 2.10.1\n","pylibcudf-cu12                        25.6.0\n","pylibcugraph-cu12                     25.6.0\n","pylibraft-cu12                        25.6.0\n","pymc                                  5.25.1\n","pynndescent                           0.5.13\n","pynvjitlink-cu12                      0.7.0\n","pynvml                                12.0.0\n","pyogrio                               0.11.1\n","pyomo                                 6.9.3\n","PyOpenGL                              3.1.10\n","pyOpenSSL                             24.2.1\n","pyparsing                             3.2.3\n","pyperclip                             1.9.0\n","pyproj                                3.7.2\n","pyproject_hooks                       1.2.0\n","pyshp                                 2.3.1\n","PySocks                               1.7.1\n","pyspark                               3.5.1\n","pytensor                              2.31.7\n","pytest                                8.4.1\n","python-apt                            0.0.0\n","python-box                            7.3.2\n","python-dateutil                       2.9.0.post0\n","python-dotenv                         1.1.1\n","python-louvain                        0.16\n","python-multipart                      0.0.20\n","python-slugify                        8.0.4\n","python-snappy                         0.7.3\n","python-utils                          3.9.1\n","pytz                                  2025.2\n","pyviz_comms                           3.0.6\n","PyWavelets                            1.9.0\n","PyYAML                                6.0.2\n","pyzmq                                 26.2.1\n","raft-dask-cu12                        25.6.0\n","rapids-dask-dependency                25.6.0\n","rapids-logger                         0.1.1\n","ratelim                               0.1.6\n","referencing                           0.36.2\n","regex                                 2024.11.6\n","requests                              2.32.4\n","requests-oauthlib                     2.0.0\n","requests-toolbelt                     1.0.0\n","requirements-parser                   0.9.0\n","rich                                  13.9.4\n","rmm-cu12                              25.6.0\n","roman-numerals-py                     3.1.0\n","rpds-py                               0.27.0\n","rpy2                                  3.5.17\n","rsa                                   4.9.1\n","ruff                                  0.12.10\n","safehttpx                             0.1.6\n","safetensors                           0.6.2\n","scanpy                                1.11.4\n","scikit-image                          0.25.2\n","scikit-learn                          1.6.1\n","scipy                                 1.16.1\n","scooby                                0.10.1\n","scs                                   3.2.8\n","seaborn                               0.13.2\n","SecretStorage                         3.3.3\n","semantic-version                      2.10.0\n","Send2Trash                            1.8.3\n","sentence-transformers                 5.1.0\n","sentencepiece                         0.2.1\n","sentry-sdk                            2.35.0\n","session-info2                         0.2.1\n","setuptools                            75.2.0\n","shap                                  0.48.0\n","shapely                               2.1.1\n","shellingham                           1.5.4\n","simple-parsing                        0.1.7\n","simplejson                            3.20.1\n","simsimd                               6.5.1\n","six                                   1.17.0\n","sklearn-pandas                        2.2.0\n","slicer                                0.0.8\n","smart_open                            7.3.0.post1\n","smmap                                 5.0.2\n","sniffio                               1.3.1\n","snowballstemmer                       3.0.1\n","sortedcontainers                      2.4.0\n","soundfile                             0.13.1\n","soupsieve                             2.7\n","soxr                                  0.5.0.post1\n","spacy                                 3.8.7\n","spacy-legacy                          3.0.12\n","spacy-loggers                         1.0.5\n","spanner-graph-notebook                1.1.7\n","Sphinx                                8.2.3\n","sphinxcontrib-applehelp               2.0.0\n","sphinxcontrib-devhelp                 2.0.0\n","sphinxcontrib-htmlhelp                2.1.0\n","sphinxcontrib-jsmath                  1.0.1\n","sphinxcontrib-qthelp                  2.0.0\n","sphinxcontrib-serializinghtml         2.0.0\n","SQLAlchemy                            2.0.43\n","sqlglot                               25.20.2\n","sqlparse                              0.5.3\n","srsly                                 2.5.1\n","sse-starlette                         3.0.2\n","stanio                                0.5.1\n","starlette                             0.47.3\n","statsmodels                           0.14.5\n","stringzilla                           3.12.6\n","stumpy                                1.13.0\n","sympy                                 1.13.3\n","tables                                3.10.2\n","tabulate                              0.9.0\n","tbb                                   2022.2.0\n","tblib                                 3.1.0\n","tcmlib                                1.4.0\n","tenacity                              8.5.0\n","tensorboard                           2.19.0\n","tensorboard-data-server               0.7.2\n","tensorflow                            2.19.0\n","tensorflow-datasets                   4.9.9\n","tensorflow_decision_forests           1.12.0\n","tensorflow-hub                        0.16.1\n","tensorflow-metadata                   1.17.2\n","tensorflow-probability                0.25.0\n","tensorflow-text                       2.19.0\n","tensorstore                           0.1.76\n","termcolor                             3.1.0\n","terminado                             0.18.1\n","text-unidecode                        1.3\n","textblob                              0.19.0\n","tf_keras                              2.19.0\n","tf-slim                               1.1.0\n","thinc                                 8.3.6\n","threadpoolctl                         3.6.0\n","tifffile                              2025.6.11\n","tiktoken                              0.11.0\n","timm                                  1.0.19\n","tinycss2                              1.4.0\n","tokenizers                            0.21.4\n","toml                                  0.10.2\n","tomlkit                               0.13.3\n","toolz                                 0.12.1\n","torch                                 2.8.0+cu126\n","torchao                               0.10.0\n","torchaudio                            2.8.0+cu126\n","torchdata                             0.11.0\n","torchsummary                          1.5.1\n","torchtune                             0.6.1\n","torchvision                           0.23.0+cu126\n","tornado                               6.4.2\n","tqdm                                  4.67.1\n","traitlets                             5.7.1\n","traittypes                            0.2.1\n","transformers                          4.55.4\n","treelite                              4.4.1\n","treescope                             0.1.10\n","triton                                3.4.0\n","tsfresh                               0.21.0\n","tweepy                                4.16.0\n","typeguard                             4.4.4\n","typer                                 0.16.1\n","types-pytz                            2025.2.0.20250809\n","types-setuptools                      80.9.0.20250822\n","typing_extensions                     4.15.0\n","typing-inspection                     0.4.1\n","tzdata                                2025.2\n","tzlocal                               5.3.1\n","uc-micro-py                           1.0.3\n","ucx-py-cu12                           0.44.0\n","ucxx-cu12                             0.44.0\n","umap-learn                            0.5.9.post2\n","umf                                   0.11.0\n","uritemplate                           4.2.0\n","urllib3                               2.5.0\n","uvicorn                               0.35.0\n","vega-datasets                         0.9.0\n","wadllib                               1.3.6\n","wandb                                 0.21.1\n","wasabi                                1.1.3\n","watchdog                              6.0.0\n","wcwidth                               0.2.13\n","weasel                                0.4.1\n","webcolors                             24.11.1\n","webencodings                          0.5.1\n","websocket-client                      1.8.0\n","websockets                            15.0.1\n","Werkzeug                              3.1.3\n","wheel                                 0.45.1\n","widgetsnbextension                    3.6.10\n","wordcloud                             1.9.4\n","wrapt                                 1.17.3\n","wurlitzer                             3.1.1\n","xarray                                2025.8.0\n","xarray-einstats                       0.9.1\n","xgboost                               3.0.4\n","xlrd                                  2.0.2\n","xxhash                                3.5.0\n","xyzservices                           2025.4.0\n","yarl                                  1.20.1\n","ydf                                   0.13.0\n","yellowbrick                           1.5\n","yfinance                              0.2.65\n","zarr                                  3.1.2\n","zict                                  3.0.0\n","zipp                                  3.23.0\n","zstandard                             0.24.0\n"]}],"source":["!python --version\n","!pip list"]},{"cell_type":"markdown","metadata":{"id":"fMjn8-1MMX5K"},"source":["# Imports"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10276,"status":"ok","timestamp":1756754401112,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"},"user_tz":240},"id":"e_Q3hi1mIh8A","outputId":"a0f7a116-6093-48af-9e39-46c528651224"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Siyao_Ali/data\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1700435987.py:49: UserWarning: flash_attn is not installed\n","  warnings.warn(\"flash_attn is not installed\")\n"]}],"source":["import scanpy as sc\n","from scanpy.get import _get_obs_rep, _set_obs_rep\n","'''\n","Scanpy is a scalable toolkit for analyzing single-cell gene expression data built jointly with anndata. It includes preprocessing, visualization, clustering, trajectory inference and differential expression testing. The Python-based implementation efficiently deals with datasets of more than one million cells.\n","'''\n","import wandb\n","'''\n","Install W&B and start tracking your machine learning experiments in minutes.\n","'''\n","import random\n","import os\n","import numpy as np\n","import torch\n","from torch import nn, Tensor\n","import time\n","import logging\n","from pathlib import Path\n","import sys\n","import gc\n","import traceback\n","from tqdm import trange\n","# import torchtext; torchtext.disable_torchtext_deprecation_warning()\n","# from torchtext.vocab import Vocab\n","# import torchtext.vocab as torch_vocab\n","import torch\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, Sampler, SubsetRandomSampler, BatchSampler\n","from torch.autograd import Function\n","from typing import Dict, Iterable, List, Optional, Tuple, Union, Any, Sequence, Mapping\n","from collections import Counter, OrderedDict\n","from typing_extensions import Self\n","import json\n","import copy\n","import pickle\n","import numpy as np\n","from anndata import AnnData # anndata is a Python package for handling annotated data matrices in memory and on disk\n","from scipy.sparse import issparse\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","from sklearn.linear_model import LassoCV\n","from sklearn.ensemble import RandomForestClassifier\n","import xgboost as xgb\n","try: # figure out flashAttention later, as has a lot of dependencies\n","    from flash_attn.flash_blocksparse_attention import FlashBlocksparseMHA # Changed from from flash_attn.flash_attention import FlashMHA as this FlashMHA actually gets recognized as a package\n","    flash_attn_available = True\n","except ImportError:\n","    import warnings\n","    warnings.warn(\"flash_attn is not installed\")\n","    flash_attn_available = False\n","\n","print(os.getcwd())\n","\n","sc.set_figure_params(figsize=(4, 4))\n","os.environ[\"KMP_WARNINGS\"] = \"off\""]},{"cell_type":"markdown","metadata":{"id":"Q7fJgjMLM1Ks"},"source":["# Param, Input Dataframe, and Logging Setup"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1756754441428,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"},"user_tz":240},"id":"ixGk__NuM9np","outputId":"c19bf942-023e-46c1-e3d7-82a9b2912ff1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Siyao_Ali\n","\u001b[0m\u001b[01;34mdata\u001b[0m/                                         \u001b[01;34msave\u001b[0m/\n","local_microbiomeGPT_10fold_CV.ipynb           \u001b[01;34mwandb\u001b[0m/\n","local_microbiomeGPT_pretraining_gpu_11.ipynb\n"]}],"source":["%cd /content/drive/My\\ Drive/Siyao_Ali/\n","%ls"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"id":"ZUKnFLnFNAV5","outputId":"eb9a223b-c41f-4f36-b0be-e54eb6e082cf","executionInfo":{"status":"ok","timestamp":1756754473783,"user_tz":240,"elapsed":30966,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.\n","/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n","  | |_| | '_ \\/ _` / _` |  _/ -_)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiyaozhu1017\u001b[0m (\u001b[33msiyaozhu1017-harvard-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/My Drive/Siyao_Ali/wandb/run-20250901_192111-1614jyr0</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT/runs/1614jyr0' target=\"_blank\">decent-donkey-13</a></strong> to <a href='https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT' target=\"_blank\">https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT/runs/1614jyr0' target=\"_blank\">https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT/runs/1614jyr0</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'seed': 42, 'mask_ratio': 0.25, 'n_bins': 100, 'max_seq_len': 10000, 'do_log1p_normalization': False, 'append_cls': True, 'include_zero_gene': False, 'lr': 0.0001, 'batch_size': 64, 'embsize': 512, 'nlayers': 8, 'nhead': 8, 'd_hid': 512, 'input_emb_style': 'continuous', 'dropout': 0.2, 'use_batch_norm': True, 'schedule_ratio': 0.9, 'epochs': 30, 'log_interval': 25, 'amp': True}\n"]}],"source":["hyperparameter_defaults = dict(\n","    seed=42,\n","    mask_ratio=0.25,\n","    n_bins=100,\n","    max_seq_len = 10000, # WANT IT TO BE LARGER THAN THE ACTUAL SEQUENCE LENGTH SO NOTHING IS TRUNCATED\n","    do_log1p_normalization = False, # disable as values already between 0 and 100\n","    append_cls = True, # set it to true so it matches the manuscript\n","    include_zero_gene = False,\n","    lr=1e-4,\n","    batch_size=64,\n","    embsize=512, # embedding size\n","    nlayers=8, # number of transformer layers\n","    nhead=8, # number of attention heads in each layer\n","    d_hid=512, # dimension of MLP hidden layer after each attention layer\n","    input_emb_style=\"continuous\", # add organism and expression embeddings\n","    dropout=0.2,\n","    use_batch_norm = True, # whether to batch norm the input embeddings before feeding into model\n","    schedule_ratio=0.9,  # ratio of epochs for learning rate schedule\n","    epochs=30,\n","    log_interval=25, # CHANGED FROM 100\n","    amp=True,  # Automatic Mixed Precision\n",")\n","\n","\n","'''\n","wandb.init() spawns a new background process to log data to a run, and it also syncs data to wandb.ai by default, so you can see live visualizations.\n","Call wandb.init() to start a run before logging data with wandb.log()\n","Each time this cell is run a new run for the scGPT project is created (and the old currently running run is finished)\n","'''\n","run = wandb.init(\n","    config=hyperparameter_defaults, # Track hyperparameters and run metadata\n","    project=\"microbiomeGPT\", # Set the project where this run will be logged\n","    reinit=True, # Allow multiple wandb.init() calls in the same process. (default: False)\n","    settings=wandb.Settings(start_method=\"fork\"),\n",")\n","config = wandb.config\n","print(config)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXDB4Yo0PcOG","executionInfo":{"status":"ok","timestamp":1756434357806,"user_tz":240,"elapsed":7,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"bfb82a37-a7a2-4c7c-8c36-2a38162fec24"},"outputs":[{"output_type":"stream","name":"stdout","text":["save to save/dev_microbiomeGPT-Aug29-02-25\n"]}],"source":["pad_token = \"<pad>\"\n","special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n","mask_value = -1\n","pad_value = -2\n","save_dir = Path(f\"./save/dev_microbiomeGPT-{time.strftime('%b%d-%H-%M')}/\") # create path\n","save_dir.mkdir(parents=True, exist_ok=True) # create save directory at the specified path\n","print(f\"save to {save_dir}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bInYRL2mNHwj","executionInfo":{"status":"ok","timestamp":1756434357833,"user_tz":240,"elapsed":26,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\"set random seed.\"\"\"\n","    random.seed(seed) # sets seed for python built in random library\n","    np.random.seed(seed) # sets seed for numpys random number generator\n","    torch.manual_seed(seed) # sets seed for pytorches random number generator\n","    torch.cuda.manual_seed_all(seed) # sets the seed for all GPUs. This function is necessary for multi-GPU models to ensure determinism.\n","    os.environ['PYTHONHASHSEED'] = str(seed) # # Ensures hash-based operations are deterministic\n","    torch.backends.cudnn.deterministic = True # configures PyTorch's CuDNN backend (a GPU-accelerated library for deep neural networks) to use deterministic algorithms\n","    torch.backends.cudnn.benchmark = False # disables the CuDNN auto-tuner, which by default tries to find the fastest convolution algorithms for your hardware configuration during runtime. However, the auto-tuner can introduce non-deterministic behavior because the fastest algorithm might change depending on input sizes\n","\n","# ensure reproducibility, good for experiment reproducability\n","set_seed(config.seed)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"bfZjgFRDbqAu","executionInfo":{"status":"ok","timestamp":1756434357845,"user_tz":240,"elapsed":4,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["# Convert the NumPy array into an AnnData object\n","adata = AnnData(df_training_data)\n","adata.var = adata.var.rename_axis('organism_name')\n","adata.var['organism_name'] = adata.var.index"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7FkthWBstiC","executionInfo":{"status":"ok","timestamp":1756434357852,"user_tz":240,"elapsed":5,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"95255714-da9a-4994-97e8-dde65c6b7eb2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AnnData object with n_obs × n_vars = 4347 × 311\n","    var: 'organism_name'"]},"metadata":{},"execution_count":14}],"source":["adata"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uPvo_BybPr_Z","executionInfo":{"status":"ok","timestamp":1756434357859,"user_tz":240,"elapsed":5,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"4b64165b-6750-47f1-c57f-6361336023ba"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["np.float64(85.39672)"]},"metadata":{},"execution_count":15}],"source":["adata.X[90].sum()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YuV2g93Iswc8","executionInfo":{"status":"ok","timestamp":1756434357880,"user_tz":240,"elapsed":20,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"65797f4d-4894-4f6b-96a4-1bf0600587ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.1420e-02, 0.0000e+00, 0.0000e+00, ..., 1.2577e-01, 3.1613e-01,\n","        1.1288e-01],\n","       [0.0000e+00, 6.0020e-02, 0.0000e+00, ..., 1.4972e+00, 0.0000e+00,\n","        0.0000e+00],\n","       [8.8000e-04, 0.0000e+00, 0.0000e+00, ..., 3.4900e-03, 0.0000e+00,\n","        0.0000e+00],\n","       ...,\n","       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 8.0640e-02, 0.0000e+00,\n","        0.0000e+00],\n","       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 7.9900e-03, 0.0000e+00,\n","        0.0000e+00],\n","       [0.0000e+00, 7.7000e-04, 8.1800e-03, ..., 1.5440e-02, 0.0000e+00,\n","        0.0000e+00]])"]},"metadata":{},"execution_count":16}],"source":["adata.X"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"id":"7SrBQ0q9s1c2","executionInfo":{"status":"ok","timestamp":1756434357893,"user_tz":240,"elapsed":12,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"8fd87ea0-a84f-4459-81e0-885b8b4032c4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: []\n","Index: [ACVD_1, ACVD_2, ACVD_3, ACVD_4, ACVD_5, ACVD_6, ACVD_7, ACVD_8, ACVD_9, ACVD_10, ACVD_11, ACVD_12, ACVD_13, ACVD_14, ACVD_15, ACVD_16, ACVD_17, ACVD_18, ACVD_19, ACVD_20, ACVD_21, ACVD_22, ACVD_23, ACVD_24, ACVD_25, ACVD_26, ACVD_27, ACVD_28, ACVD_29, ACVD_30, ACVD_31, ACVD_32, ACVD_33, ACVD_34, ACVD_35, ACVD_36, ACVD_37, ACVD_38, ACVD_39, ACVD_40, ACVD_41, ACVD_42, ACVD_43, ACVD_44, ACVD_45, ACVD_46, ACVD_47, ACVD_48, ACVD_49, ACVD_50, ACVD_51, ACVD_52, ACVD_53, ACVD_54, ACVD_55, ACVD_56, ACVD_57, ACVD_58, ACVD_59, ACVD_60, ACVD_61, ACVD_62, ACVD_63, ACVD_64, ACVD_65, ACVD_66, ACVD_67, ACVD_68, ACVD_69, ACVD_70, ACVD_71, ACVD_72, ACVD_73, ACVD_74, ACVD_75, ACVD_76, ACVD_77, ACVD_78, ACVD_79, ACVD_80, ACVD_81, ACVD_82, ACVD_83, ACVD_84, ACVD_85, ACVD_86, ACVD_87, ACVD_88, ACVD_89, ACVD_90, ACVD_91, ACVD_92, ACVD_93, ACVD_94, ACVD_95, ACVD_96, ACVD_97, ACVD_98, ACVD_99, ACVD_100, ...]\n","\n","[4347 rows x 0 columns]"],"text/html":["\n","  <div id=\"df-50ae8692-605f-47a4-aaf6-597740028f0e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ACVD_1</th>\n","    </tr>\n","    <tr>\n","      <th>ACVD_2</th>\n","    </tr>\n","    <tr>\n","      <th>ACVD_3</th>\n","    </tr>\n","    <tr>\n","      <th>ACVD_4</th>\n","    </tr>\n","    <tr>\n","      <th>ACVD_5</th>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","    </tr>\n","    <tr>\n","      <th>Underweight_4343</th>\n","    </tr>\n","    <tr>\n","      <th>Underweight_4344</th>\n","    </tr>\n","    <tr>\n","      <th>Underweight_4345</th>\n","    </tr>\n","    <tr>\n","      <th>Underweight_4346</th>\n","    </tr>\n","    <tr>\n","      <th>Underweight_4347</th>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4347 rows × 0 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50ae8692-605f-47a4-aaf6-597740028f0e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-50ae8692-605f-47a4-aaf6-597740028f0e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-50ae8692-605f-47a4-aaf6-597740028f0e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-43f5990c-ad55-472a-a2c2-1ac1a0430099\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43f5990c-ad55-472a-a2c2-1ac1a0430099')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-43f5990c-ad55-472a-a2c2-1ac1a0430099 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"adata\",\n  \"rows\": 4347,\n  \"fields\": []\n}"}},"metadata":{},"execution_count":17}],"source":["adata.obs"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442},"id":"rZ6ZalmKs3ki","executionInfo":{"status":"ok","timestamp":1756434357933,"user_tz":240,"elapsed":39,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"f034cd1d-a7f5-46b6-cd47-6536dd0715bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         organism_name\n","organism_name                                         \n","Abiotrophia defectiva            Abiotrophia defectiva\n","Acidaminococcus fermentans  Acidaminococcus fermentans\n","Acidaminococcus intestini    Acidaminococcus intestini\n","Actinomyces graevenitzii      Actinomyces graevenitzii\n","Actinomyces odontolyticus    Actinomyces odontolyticus\n","...                                                ...\n","Veillonella atypica                Veillonella atypica\n","Veillonella dispar                  Veillonella dispar\n","Veillonella parvula                Veillonella parvula\n","Weissella cibaria                    Weissella cibaria\n","Weissella confusa                    Weissella confusa\n","\n","[311 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-afa7a28c-8ef9-47d8-a281-3dd50305752d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>organism_name</th>\n","    </tr>\n","    <tr>\n","      <th>organism_name</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Abiotrophia defectiva</th>\n","      <td>Abiotrophia defectiva</td>\n","    </tr>\n","    <tr>\n","      <th>Acidaminococcus fermentans</th>\n","      <td>Acidaminococcus fermentans</td>\n","    </tr>\n","    <tr>\n","      <th>Acidaminococcus intestini</th>\n","      <td>Acidaminococcus intestini</td>\n","    </tr>\n","    <tr>\n","      <th>Actinomyces graevenitzii</th>\n","      <td>Actinomyces graevenitzii</td>\n","    </tr>\n","    <tr>\n","      <th>Actinomyces odontolyticus</th>\n","      <td>Actinomyces odontolyticus</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>Veillonella atypica</th>\n","      <td>Veillonella atypica</td>\n","    </tr>\n","    <tr>\n","      <th>Veillonella dispar</th>\n","      <td>Veillonella dispar</td>\n","    </tr>\n","    <tr>\n","      <th>Veillonella parvula</th>\n","      <td>Veillonella parvula</td>\n","    </tr>\n","    <tr>\n","      <th>Weissella cibaria</th>\n","      <td>Weissella cibaria</td>\n","    </tr>\n","    <tr>\n","      <th>Weissella confusa</th>\n","      <td>Weissella confusa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>311 rows × 1 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afa7a28c-8ef9-47d8-a281-3dd50305752d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-afa7a28c-8ef9-47d8-a281-3dd50305752d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-afa7a28c-8ef9-47d8-a281-3dd50305752d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-05b00026-907b-4b85-abe4-ee71c226378e\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05b00026-907b-4b85-abe4-ee71c226378e')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-05b00026-907b-4b85-abe4-ee71c226378e button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"cannot insert organism_name, already exists"}},"metadata":{},"execution_count":18}],"source":["adata.var"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JK0_VxHPs8Z_","executionInfo":{"status":"ok","timestamp":1756434357939,"user_tz":240,"elapsed":4,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"9b358228-babd-492b-dc7c-1cf71f34075f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict()"]},"metadata":{},"execution_count":19}],"source":["adata.uns"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKOHEvTes-gY","executionInfo":{"status":"ok","timestamp":1756434357958,"user_tz":240,"elapsed":18,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"1f1459bf-4930-4bd0-82bc-e413e90e611b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AxisArrays with keys: "]},"metadata":{},"execution_count":20}],"source":["adata.obsm"]},{"cell_type":"markdown","metadata":{"id":"ZT85iNzonsyV"},"source":["# Setting Up a Logger"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"TXRul_k0SwiT","executionInfo":{"status":"ok","timestamp":1756434357960,"user_tz":240,"elapsed":1,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["logger = logging.getLogger(\"microbiomeGPT\") # This retrieves a logger instance with the name \"microbiomeGPT\". If a logger with this name doesn’t exist, it will be created\n","# check if logger has been initialized\n","if not logger.hasHandlers() or len(logger.handlers) == 0: # This checks if the logger has any handlers attached. Handlers are responsible for sending the log messages to their final destination (e.g., console, file)\n","    logger.propagate = False # This prevents log messages from being passed to ancestor loggers. This is useful if you want to isolate logging to just this logger.\n","    logger.setLevel(logging.INFO) # Sets the logging level to INFO, which means the logger will handle messages with severity level INFO and above (i.e., WARNING, ERROR, and CRITICAL).\n","    handler = logging.StreamHandler(sys.stdout) # A StreamHandler is created, which sends log messages to sys.stdout (the standard output, typically the console).\n","    handler.setLevel(logging.INFO) # The handler is also set to INFO level.\n","    formatter = logging.Formatter(\n","        \"%(name)s - %(levelname)s - %(message)s\", datefmt=\"%H:%M:%S\"\n","    ) # The format string \"%(name)s - %(levelname)s - %(message)s\" specifies that each log message will include the logger name, log level, and the log message itself. The datefmt=\"%H:%M:%S\" specifies the time format.\n","    handler.setFormatter(formatter)\n","    logger.addHandler(handler) # The configured StreamHandler is added to the logger. This means that the logger will now send its output to sys.stdout formatted according to the specified formatter.\n","\n","def add_file_handler(logger: logging.Logger, log_file_path: Path):\n","    \"\"\"\n","    Add a file handler to the logger.\n","    \"\"\"\n","    h = logging.FileHandler(log_file_path)\n","\n","    # format showing time, name, function, and message\n","    formatter = logging.Formatter(\n","        \"%(asctime)s-%(name)s-%(levelname)s-%(funcName)s: %(message)s\",\n","        datefmt=\"%H:%M:%S\",\n","    )\n","    h.setFormatter(formatter)\n","    h.setLevel(logger.level)\n","    logger.addHandler(h)\n","\n","# Add another handler to the logger that logs messages processed by this logger to the specified file in addition to the other handlers (e.g., StreamHandler for console output) that are attached to the logger.\n","add_file_handler(logger, save_dir / \"run.log\") # A FileHandler is created, which writes log messages to a file specified by log_file_path. (save_dir / \"run.log\")"]},{"cell_type":"markdown","metadata":{"id":"quThxDWlzaj5"},"source":["# Create Vocab"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"yKqT6kKnzcoW","executionInfo":{"status":"ok","timestamp":1756434357983,"user_tz":240,"elapsed":22,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["class OrganismVocab:\n","    \"\"\"\n","    Vocabulary for organisms.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        organism_list: List[str],\n","        specials: Optional[List[str]] = None,\n","        special_first: bool = True,\n","        default_token: Optional[str] = \"<pad>\",\n","    ) -> None:\n","        \"\"\"\n","        Initialize the vocabulary.\n","        Note: add specials only works when init from a gene list.\n","\n","        Args:\n","            organism_list_or_vocab (List[str]): List of organism names.\n","            specials (List[str]): List of special tokens.\n","            special_first (bool): Whether to add special tokens to the beginning\n","                of the vocabulary.\n","            default_token (str): Default token, by default will set to \"<pad>\",\n","                if \"<pad>\" is in the vocabulary.\n","        \"\"\"\n","\n","        self.vocab = []\n","        self.itos = dict()\n","        self.stoi = dict()\n","        self.default_index = None\n","\n","        if specials is not None:\n","          if special_first:\n","            organism_list = specials + organism_list\n","          else:\n","            organism_list = organism_list + specials\n","\n","        self.vocab = organism_list\n","        self.stoi = {value: index for index, value in enumerate(organism_list)}\n","        self.itos = {index: value for index, value in enumerate(organism_list)}\n","\n","        if default_token is not None:\n","            self.set_default_token(default_token)\n","\n","    def __contains__(self, token: str):\n","        return token in self.stoi\n","\n","    def __call__(self, tokens):\n","        return [self.stoi[token] for token in tokens]\n","\n","    def __getitem__(self, token: str):\n","        return self.stoi[token]\n","\n","    def __len__(self):\n","        return len(self.vocab)\n","\n","    def append_token(self, token: str):\n","        \"\"\"\n","        Append a token to the vocabulary.\n","        \"\"\"\n","        self.vocab.append(token)\n","        self.stoi[token] = len(self.vocab) - 1\n","        self.itos[len(self.vocab) - 1] = token\n","\n","    def get_itos(self):\n","        \"\"\"\n","        Get the index to string mapping.\n","        \"\"\"\n","        return self.itos\n","\n","    def get_stoi(self):\n","        \"\"\"\n","        Get the string to index mapping.\n","        \"\"\"\n","        return self.stoi\n","\n","    @classmethod\n","    def from_file(cls, file_path: Union[Path, str]) -> Self:\n","        \"\"\"\n","        Load the vocabulary from a file. The file should be either a pickle or a\n","        json file of token to index mapping.\n","        \"\"\"\n","        if isinstance(file_path, str):\n","            file_path = Path(file_path)\n","        if file_path.suffix == \".pkl\":\n","            with file_path.open(\"rb\") as f:\n","                vocab = pickle.load(f)\n","                return cls(vocab)\n","        elif file_path.suffix == \".json\":\n","            with file_path.open(\"r\") as f:\n","                token2idx = json.load(f)\n","                return cls.from_dict(token2idx)\n","        else:\n","            raise ValueError(\n","                f\"{file_path} is not a valid file type. \"\n","                \"Only .pkl and .json are supported.\"\n","            )\n","\n","    @classmethod\n","    def from_dict(\n","        cls,\n","        token2idx: Dict[str, int],\n","        default_token: Optional[str] = \"<pad>\",\n","    ) -> Self:\n","        \"\"\"\n","        Load the vocabulary from a dictionary.\n","\n","        Args:\n","            token2idx (Dict[str, int]): Dictionary mapping tokens to indices.\n","        \"\"\"\n","        # initiate an empty vocabulary first\n","        vocab = cls(list(token2idx.keys()), default_token = default_token)\n","\n","        return vocab\n","\n","    def set_default_token(self, default_token: str) -> None:\n","        \"\"\"\n","        Set the default token.\n","\n","        Args:\n","            default_token (str): Default token.\n","        \"\"\"\n","        if default_token not in self.vocab:\n","            raise ValueError(f\"{default_token} is not in the vocabulary.\")\n","        self.default_index = self.stoi[default_token] # Value of default index. This index will be returned when OOV token is queried.\n","\n","    def get_default_index(self) -> Optional[int]:\n","        \"\"\"\n","        Get the default index.\n","        \"\"\"\n","        return self.default_index"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zAnUeVq2YLz","executionInfo":{"status":"ok","timestamp":1756434358090,"user_tz":240,"elapsed":104,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"66b17a7c-7222-4a00-be77-09a780f016ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 'Abiotrophia defectiva', 1: 'Acidaminococcus fermentans', 2: 'Acidaminococcus intestini', 3: 'Actinomyces graevenitzii', 4: 'Actinomyces odontolyticus', 5: 'Actinomyces oris', 6: 'Actinomyces turicensis', 7: 'Actinomyces viscosus', 8: 'Adlercreutzia equolifaciens', 9: 'Aggregatibacter segnis', 10: 'Akkermansia muciniphila', 11: 'Alistipes finegoldii', 12: 'Alistipes indistinctus', 13: 'Alistipes onderdonkii', 14: 'Alistipes putredinis', 15: 'Alistipes senegalensis', 16: 'Alistipes shahii', 17: 'Alistipes sp AP11', 18: 'Alistipes sp HGB5', 19: 'Alloscardovia omnicolens', 20: 'Anaerococcus obesiensis', 21: 'Anaerococcus vaginalis', 22: 'Anaerofustis stercorihominis', 23: 'Anaeroglobus geminatus', 24: 'Anaerostipes caccae', 25: 'Anaerostipes hadrus', 26: 'Anaerotruncus colihominis', 27: 'Atopobium parvulum', 28: 'Atopobium rimae', 29: 'Atopobium vaginae', 30: 'Bacteroidales bacterium ph8', 31: 'Bacteroides caccae', 32: 'Bacteroides cellulosilyticus', 33: 'Bacteroides clarus', 34: 'Bacteroides coprocola', 35: 'Bacteroides coprophilus', 36: 'Bacteroides dorei', 37: 'Bacteroides eggerthii', 38: 'Bacteroides faecis', 39: 'Bacteroides finegoldii', 40: 'Bacteroides fragilis', 41: 'Bacteroides intestinalis', 42: 'Bacteroides massiliensis', 43: 'Bacteroides nordii', 44: 'Bacteroides oleiciplenus', 45: 'Bacteroides ovatus', 46: 'Bacteroides pectinophilus', 47: 'Bacteroides plebeius', 48: 'Bacteroides salyersiae', 49: 'Bacteroides sp 2 1 22', 50: 'Bacteroides sp 3 1 19', 51: 'Bacteroides sp 4 3 47FAA', 52: 'Bacteroides stercoris', 53: 'Bacteroides thetaiotaomicron', 54: 'Bacteroides uniformis', 55: 'Bacteroides vulgatus', 56: 'Bacteroides xylanisolvens', 57: 'Barnesiella intestinihominis', 58: 'Bifidobacterium adolescentis', 59: 'Bifidobacterium angulatum', 60: 'Bifidobacterium animalis', 61: 'Bifidobacterium bifidum', 62: 'Bifidobacterium breve', 63: 'Bifidobacterium catenulatum', 64: 'Bifidobacterium dentium', 65: 'Bifidobacterium longum', 66: 'Bifidobacterium pseudocatenulatum', 67: 'Bilophila wadsworthia', 68: 'Blautia hansenii', 69: 'Blautia hydrogenotrophica', 70: 'Blautia producta', 71: 'Burkholderiales bacterium 1 1 47', 72: 'Butyricicoccus pullicaecorum', 73: 'Butyricimonas synergistica', 74: 'Butyrivibrio crossotus', 75: 'Campylobacter hominis', 76: 'Catenibacterium mitsuokai', 77: 'Citrobacter freundii', 78: 'Clostridiaceae bacterium JC118', 79: 'Clostridiales bacterium 1 7 47FAA', 80: 'Clostridium sp ATCC BAA 442', 81: 'Clostridium sp KLE 1755', 82: 'Clostridium sp L2 50', 83: 'Clostridium asparagiforme', 84: 'Clostridium bartlettii', 85: 'Clostridium bolteae', 86: 'Clostridium celatum', 87: 'Clostridium citroniae', 88: 'Clostridium clostridioforme', 89: 'Clostridium difficile', 90: 'Clostridium hathewayi', 91: 'Clostridium hylemonae', 92: 'Clostridium innocuum', 93: 'Clostridium leptum', 94: 'Clostridium methylpentosum', 95: 'Clostridium nexile', 96: 'Clostridium perfringens', 97: 'Clostridium ramosum', 98: 'Clostridium scindens', 99: 'Clostridium spiroforme', 100: 'Clostridium symbiosum', 101: 'Collinsella aerofaciens', 102: 'Collinsella intestinalis', 103: 'Collinsella tanakaei', 104: 'Coprobacillus sp 29 1', 105: 'Coprobacillus sp D6', 106: 'Coprobacter fastidiosus', 107: 'Coprococcus sp ART55 1', 108: 'Coprococcus catus', 109: 'Coprococcus comes', 110: 'Coprococcus eutactus', 111: 'Coriobacteriaceae bacterium phI', 112: 'Corynebacterium durum', 113: 'Desulfovibrio desulfuricans', 114: 'Desulfovibrio piger', 115: 'Dialister invisus', 116: 'Dialister succinatiphilus', 117: 'Dorea formicigenerans', 118: 'Dorea longicatena', 119: 'Eggerthella lenta', 120: 'Enterobacter aerogenes', 121: 'Enterobacter cloacae', 122: 'Enterococcus avium', 123: 'Enterococcus casseliflavus', 124: 'Enterococcus durans', 125: 'Enterococcus faecalis', 126: 'Enterococcus faecium', 127: 'Erysipelotrichaceae bacterium 2 2 44A', 128: 'Erysipelotrichaceae bacterium 21 3', 129: 'Erysipelotrichaceae bacterium 3 1 53', 130: 'Erysipelotrichaceae bacterium 5 2 54FAA', 131: 'Erysipelotrichaceae bacterium 6 1 45', 132: 'Escherichia coli', 133: 'Eubacterium biforme', 134: 'Eubacterium brachy', 135: 'Eubacterium cylindroides', 136: 'Eubacterium dolichum', 137: 'Eubacterium eligens', 138: 'Eubacterium hallii', 139: 'Eubacterium infirmum', 140: 'Eubacterium limosum', 141: 'Eubacterium ramulus', 142: 'Eubacterium rectale', 143: 'Eubacterium siraeum', 144: 'Eubacterium sp 3 1 31', 145: 'Eubacterium ventriosum', 146: 'Faecalibacterium prausnitzii', 147: 'Finegoldia magna', 148: 'Flavonifractor plautii', 149: 'Fusobacterium gonidiaformans', 150: 'Fusobacterium mortiferum', 151: 'Fusobacterium nucleatum', 152: 'Fusobacterium periodonticum', 153: 'Fusobacterium ulcerans', 154: 'Fusobacterium varium', 155: 'Gardnerella vaginalis', 156: 'Gemella haemolysans', 157: 'Gemella morbillorum', 158: 'Gemella sanguinis', 159: 'Gordonibacter pamelaeae', 160: 'Granulicatella adiacens', 161: 'Granulicatella elegans', 162: 'Haemophilus haemolyticus', 163: 'Haemophilus parainfluenzae', 164: 'Haemophilus pittmaniae', 165: 'Haemophilus sputorum', 166: 'Holdemania filiformis', 167: 'Holdemania sp AP2', 168: 'Klebsiella oxytoca', 169: 'Klebsiella pneumoniae', 170: 'Lachnospiraceae bacterium 1 1 57FAA', 171: 'Lachnospiraceae bacterium 1 4 56FAA', 172: 'Lachnospiraceae bacterium 2 1 46FAA', 173: 'Lachnospiraceae bacterium 2 1 58FAA', 174: 'Lachnospiraceae bacterium 3 1 46FAA', 175: 'Lachnospiraceae bacterium 3 1 57FAA CT1', 176: 'Lachnospiraceae bacterium 4 1 37FAA', 177: 'Lachnospiraceae bacterium 5 1 57FAA', 178: 'Lachnospiraceae bacterium 5 1 63FAA', 179: 'Lachnospiraceae bacterium 6 1 63FAA', 180: 'Lachnospiraceae bacterium 7 1 58FAA', 181: 'Lachnospiraceae bacterium 8 1 57FAA', 182: 'Lachnospiraceae bacterium 9 1 43BFAA', 183: 'Lactobacillus acidophilus', 184: 'Lactobacillus amylovorus', 185: 'Lactobacillus casei paracasei', 186: 'Lactobacillus crispatus', 187: 'Lactobacillus curvatus', 188: 'Lactobacillus delbrueckii', 189: 'Lactobacillus fermentum', 190: 'Lactobacillus gasseri', 191: 'Lactobacillus iners', 192: 'Lactobacillus mucosae', 193: 'Lactobacillus oris', 194: 'Lactobacillus plantarum', 195: 'Lactobacillus reuteri', 196: 'Lactobacillus rhamnosus', 197: 'Lactobacillus ruminis', 198: 'Lactobacillus sakei', 199: 'Lactobacillus salivarius', 200: 'Lactobacillus sanfranciscensis', 201: 'Lactobacillus vaginalis', 202: 'Lactococcus garvieae', 203: 'Lactococcus lactis', 204: 'Lactococcus raffinolactis', 205: 'Leuconostoc lactis', 206: 'Leuconostoc mesenteroides', 207: 'Leuconostoc pseudomesenteroides', 208: 'Megamonas funiformis', 209: 'Megamonas hypermegale', 210: 'Megamonas rupellensis', 211: 'Megasphaera elsdenii', 212: 'Megasphaera micronuciformis', 213: 'Methanobrevibacter smithii', 214: 'Methanosphaera stadtmanae', 215: 'Mitsuokella multacida', 216: 'Morganella morganii', 217: 'Odoribacter laneus', 218: 'Odoribacter splanchnicus', 219: 'Oribacterium sinus', 220: 'Oscillibacter sp KLE 1728', 221: 'Oscillibacter sp KLE 1745', 222: 'Oxalobacter formigenes', 223: 'Parabacteroides distasonis', 224: 'Parabacteroides goldsteinii', 225: 'Parabacteroides johnsonii', 226: 'Parabacteroides merdae', 227: 'Paraprevotella clara', 228: 'Paraprevotella xylaniphila', 229: 'Parascardovia denticolens', 230: 'Parasutterella excrementihominis', 231: 'Parvimonas micra', 232: 'Pediococcus pentosaceus', 233: 'Peptoniphilus harei', 234: 'Peptoniphilus lacrimalis', 235: 'Peptostreptococcus anaerobius', 236: 'Peptostreptococcus stomatis', 237: 'Phascolarctobacterium succinatutens', 238: 'Porphyromonas asaccharolytica', 239: 'Porphyromonas bennonis', 240: 'Porphyromonas somerae', 241: 'Porphyromonas uenonis', 242: 'Prevotella bivia', 243: 'Prevotella buccalis', 244: 'Prevotella copri', 245: 'Prevotella disiens', 246: 'Prevotella stercorea', 247: 'Prevotella timonensis', 248: 'Propionibacterium freudenreichii', 249: 'Proteus mirabilis', 250: 'Pseudoflavonifractor capillosus', 251: 'Pyramidobacter piscolens', 252: 'Raoultella ornithinolytica', 253: 'Roseburia hominis', 254: 'Roseburia intestinalis', 255: 'Roseburia inulinivorans', 256: 'Rothia dentocariosa', 257: 'Rothia mucilaginosa', 258: 'Ruminococcaceae bacterium D16', 259: 'Ruminococcus albus', 260: 'Ruminococcus bromii', 261: 'Ruminococcus callidus', 262: 'Ruminococcus champanellensis', 263: 'Ruminococcus flavefaciens', 264: 'Ruminococcus gnavus', 265: 'Ruminococcus lactaris', 266: 'Ruminococcus obeum', 267: 'Ruminococcus sp 5 1 39BFAA', 268: 'Ruminococcus sp JC304', 269: 'Ruminococcus torques', 270: 'Saccharomyces cerevisiae', 271: 'Scardovia wiggsiae', 272: 'Shigella flexneri', 273: 'Shigella sonnei', 274: 'Slackia piriformis', 275: 'Solobacterium moorei', 276: 'Staphylococcus aureus', 277: 'Streptococcus agalactiae', 278: 'Streptococcus anginosus', 279: 'Streptococcus australis', 280: 'Streptococcus constellatus', 281: 'Streptococcus cristatus', 282: 'Streptococcus gordonii', 283: 'Streptococcus infantarius', 284: 'Streptococcus infantis', 285: 'Streptococcus intermedius', 286: 'Streptococcus lutetiensis', 287: 'Streptococcus macedonicus', 288: 'Streptococcus mitis oralis pneumoniae', 289: 'Streptococcus mutans', 290: 'Streptococcus oligofermentans', 291: 'Streptococcus parasanguinis', 292: 'Streptococcus pasteurianus', 293: 'Streptococcus peroris', 294: 'Streptococcus salivarius', 295: 'Streptococcus sanguinis', 296: 'Streptococcus sobrinus', 297: 'Streptococcus thermophilus', 298: 'Streptococcus tigurinus', 299: 'Streptococcus vestibularis', 300: 'Subdoligranulum sp 4 3 54A2FAA', 301: 'Subdoligranulum variabile', 302: 'Succinatimonas hippei', 303: 'Sutterella wadsworthensis', 304: 'Turicibacter sanguinis', 305: 'Varibaculum cambriense', 306: 'Veillonella atypica', 307: 'Veillonella dispar', 308: 'Veillonella parvula', 309: 'Weissella cibaria', 310: 'Weissella confusa', 311: '<pad>', 312: '<cls>', 313: '<eoc>'}\n","314\n","311\n","{'Abiotrophia defectiva': 0, 'Acidaminococcus fermentans': 1, 'Acidaminococcus intestini': 2, 'Actinomyces graevenitzii': 3, 'Actinomyces odontolyticus': 4, 'Actinomyces oris': 5, 'Actinomyces turicensis': 6, 'Actinomyces viscosus': 7, 'Adlercreutzia equolifaciens': 8, 'Aggregatibacter segnis': 9, 'Akkermansia muciniphila': 10, 'Alistipes finegoldii': 11, 'Alistipes indistinctus': 12, 'Alistipes onderdonkii': 13, 'Alistipes putredinis': 14, 'Alistipes senegalensis': 15, 'Alistipes shahii': 16, 'Alistipes sp AP11': 17, 'Alistipes sp HGB5': 18, 'Alloscardovia omnicolens': 19, 'Anaerococcus obesiensis': 20, 'Anaerococcus vaginalis': 21, 'Anaerofustis stercorihominis': 22, 'Anaeroglobus geminatus': 23, 'Anaerostipes caccae': 24, 'Anaerostipes hadrus': 25, 'Anaerotruncus colihominis': 26, 'Atopobium parvulum': 27, 'Atopobium rimae': 28, 'Atopobium vaginae': 29, 'Bacteroidales bacterium ph8': 30, 'Bacteroides caccae': 31, 'Bacteroides cellulosilyticus': 32, 'Bacteroides clarus': 33, 'Bacteroides coprocola': 34, 'Bacteroides coprophilus': 35, 'Bacteroides dorei': 36, 'Bacteroides eggerthii': 37, 'Bacteroides faecis': 38, 'Bacteroides finegoldii': 39, 'Bacteroides fragilis': 40, 'Bacteroides intestinalis': 41, 'Bacteroides massiliensis': 42, 'Bacteroides nordii': 43, 'Bacteroides oleiciplenus': 44, 'Bacteroides ovatus': 45, 'Bacteroides pectinophilus': 46, 'Bacteroides plebeius': 47, 'Bacteroides salyersiae': 48, 'Bacteroides sp 2 1 22': 49, 'Bacteroides sp 3 1 19': 50, 'Bacteroides sp 4 3 47FAA': 51, 'Bacteroides stercoris': 52, 'Bacteroides thetaiotaomicron': 53, 'Bacteroides uniformis': 54, 'Bacteroides vulgatus': 55, 'Bacteroides xylanisolvens': 56, 'Barnesiella intestinihominis': 57, 'Bifidobacterium adolescentis': 58, 'Bifidobacterium angulatum': 59, 'Bifidobacterium animalis': 60, 'Bifidobacterium bifidum': 61, 'Bifidobacterium breve': 62, 'Bifidobacterium catenulatum': 63, 'Bifidobacterium dentium': 64, 'Bifidobacterium longum': 65, 'Bifidobacterium pseudocatenulatum': 66, 'Bilophila wadsworthia': 67, 'Blautia hansenii': 68, 'Blautia hydrogenotrophica': 69, 'Blautia producta': 70, 'Burkholderiales bacterium 1 1 47': 71, 'Butyricicoccus pullicaecorum': 72, 'Butyricimonas synergistica': 73, 'Butyrivibrio crossotus': 74, 'Campylobacter hominis': 75, 'Catenibacterium mitsuokai': 76, 'Citrobacter freundii': 77, 'Clostridiaceae bacterium JC118': 78, 'Clostridiales bacterium 1 7 47FAA': 79, 'Clostridium sp ATCC BAA 442': 80, 'Clostridium sp KLE 1755': 81, 'Clostridium sp L2 50': 82, 'Clostridium asparagiforme': 83, 'Clostridium bartlettii': 84, 'Clostridium bolteae': 85, 'Clostridium celatum': 86, 'Clostridium citroniae': 87, 'Clostridium clostridioforme': 88, 'Clostridium difficile': 89, 'Clostridium hathewayi': 90, 'Clostridium hylemonae': 91, 'Clostridium innocuum': 92, 'Clostridium leptum': 93, 'Clostridium methylpentosum': 94, 'Clostridium nexile': 95, 'Clostridium perfringens': 96, 'Clostridium ramosum': 97, 'Clostridium scindens': 98, 'Clostridium spiroforme': 99, 'Clostridium symbiosum': 100, 'Collinsella aerofaciens': 101, 'Collinsella intestinalis': 102, 'Collinsella tanakaei': 103, 'Coprobacillus sp 29 1': 104, 'Coprobacillus sp D6': 105, 'Coprobacter fastidiosus': 106, 'Coprococcus sp ART55 1': 107, 'Coprococcus catus': 108, 'Coprococcus comes': 109, 'Coprococcus eutactus': 110, 'Coriobacteriaceae bacterium phI': 111, 'Corynebacterium durum': 112, 'Desulfovibrio desulfuricans': 113, 'Desulfovibrio piger': 114, 'Dialister invisus': 115, 'Dialister succinatiphilus': 116, 'Dorea formicigenerans': 117, 'Dorea longicatena': 118, 'Eggerthella lenta': 119, 'Enterobacter aerogenes': 120, 'Enterobacter cloacae': 121, 'Enterococcus avium': 122, 'Enterococcus casseliflavus': 123, 'Enterococcus durans': 124, 'Enterococcus faecalis': 125, 'Enterococcus faecium': 126, 'Erysipelotrichaceae bacterium 2 2 44A': 127, 'Erysipelotrichaceae bacterium 21 3': 128, 'Erysipelotrichaceae bacterium 3 1 53': 129, 'Erysipelotrichaceae bacterium 5 2 54FAA': 130, 'Erysipelotrichaceae bacterium 6 1 45': 131, 'Escherichia coli': 132, 'Eubacterium biforme': 133, 'Eubacterium brachy': 134, 'Eubacterium cylindroides': 135, 'Eubacterium dolichum': 136, 'Eubacterium eligens': 137, 'Eubacterium hallii': 138, 'Eubacterium infirmum': 139, 'Eubacterium limosum': 140, 'Eubacterium ramulus': 141, 'Eubacterium rectale': 142, 'Eubacterium siraeum': 143, 'Eubacterium sp 3 1 31': 144, 'Eubacterium ventriosum': 145, 'Faecalibacterium prausnitzii': 146, 'Finegoldia magna': 147, 'Flavonifractor plautii': 148, 'Fusobacterium gonidiaformans': 149, 'Fusobacterium mortiferum': 150, 'Fusobacterium nucleatum': 151, 'Fusobacterium periodonticum': 152, 'Fusobacterium ulcerans': 153, 'Fusobacterium varium': 154, 'Gardnerella vaginalis': 155, 'Gemella haemolysans': 156, 'Gemella morbillorum': 157, 'Gemella sanguinis': 158, 'Gordonibacter pamelaeae': 159, 'Granulicatella adiacens': 160, 'Granulicatella elegans': 161, 'Haemophilus haemolyticus': 162, 'Haemophilus parainfluenzae': 163, 'Haemophilus pittmaniae': 164, 'Haemophilus sputorum': 165, 'Holdemania filiformis': 166, 'Holdemania sp AP2': 167, 'Klebsiella oxytoca': 168, 'Klebsiella pneumoniae': 169, 'Lachnospiraceae bacterium 1 1 57FAA': 170, 'Lachnospiraceae bacterium 1 4 56FAA': 171, 'Lachnospiraceae bacterium 2 1 46FAA': 172, 'Lachnospiraceae bacterium 2 1 58FAA': 173, 'Lachnospiraceae bacterium 3 1 46FAA': 174, 'Lachnospiraceae bacterium 3 1 57FAA CT1': 175, 'Lachnospiraceae bacterium 4 1 37FAA': 176, 'Lachnospiraceae bacterium 5 1 57FAA': 177, 'Lachnospiraceae bacterium 5 1 63FAA': 178, 'Lachnospiraceae bacterium 6 1 63FAA': 179, 'Lachnospiraceae bacterium 7 1 58FAA': 180, 'Lachnospiraceae bacterium 8 1 57FAA': 181, 'Lachnospiraceae bacterium 9 1 43BFAA': 182, 'Lactobacillus acidophilus': 183, 'Lactobacillus amylovorus': 184, 'Lactobacillus casei paracasei': 185, 'Lactobacillus crispatus': 186, 'Lactobacillus curvatus': 187, 'Lactobacillus delbrueckii': 188, 'Lactobacillus fermentum': 189, 'Lactobacillus gasseri': 190, 'Lactobacillus iners': 191, 'Lactobacillus mucosae': 192, 'Lactobacillus oris': 193, 'Lactobacillus plantarum': 194, 'Lactobacillus reuteri': 195, 'Lactobacillus rhamnosus': 196, 'Lactobacillus ruminis': 197, 'Lactobacillus sakei': 198, 'Lactobacillus salivarius': 199, 'Lactobacillus sanfranciscensis': 200, 'Lactobacillus vaginalis': 201, 'Lactococcus garvieae': 202, 'Lactococcus lactis': 203, 'Lactococcus raffinolactis': 204, 'Leuconostoc lactis': 205, 'Leuconostoc mesenteroides': 206, 'Leuconostoc pseudomesenteroides': 207, 'Megamonas funiformis': 208, 'Megamonas hypermegale': 209, 'Megamonas rupellensis': 210, 'Megasphaera elsdenii': 211, 'Megasphaera micronuciformis': 212, 'Methanobrevibacter smithii': 213, 'Methanosphaera stadtmanae': 214, 'Mitsuokella multacida': 215, 'Morganella morganii': 216, 'Odoribacter laneus': 217, 'Odoribacter splanchnicus': 218, 'Oribacterium sinus': 219, 'Oscillibacter sp KLE 1728': 220, 'Oscillibacter sp KLE 1745': 221, 'Oxalobacter formigenes': 222, 'Parabacteroides distasonis': 223, 'Parabacteroides goldsteinii': 224, 'Parabacteroides johnsonii': 225, 'Parabacteroides merdae': 226, 'Paraprevotella clara': 227, 'Paraprevotella xylaniphila': 228, 'Parascardovia denticolens': 229, 'Parasutterella excrementihominis': 230, 'Parvimonas micra': 231, 'Pediococcus pentosaceus': 232, 'Peptoniphilus harei': 233, 'Peptoniphilus lacrimalis': 234, 'Peptostreptococcus anaerobius': 235, 'Peptostreptococcus stomatis': 236, 'Phascolarctobacterium succinatutens': 237, 'Porphyromonas asaccharolytica': 238, 'Porphyromonas bennonis': 239, 'Porphyromonas somerae': 240, 'Porphyromonas uenonis': 241, 'Prevotella bivia': 242, 'Prevotella buccalis': 243, 'Prevotella copri': 244, 'Prevotella disiens': 245, 'Prevotella stercorea': 246, 'Prevotella timonensis': 247, 'Propionibacterium freudenreichii': 248, 'Proteus mirabilis': 249, 'Pseudoflavonifractor capillosus': 250, 'Pyramidobacter piscolens': 251, 'Raoultella ornithinolytica': 252, 'Roseburia hominis': 253, 'Roseburia intestinalis': 254, 'Roseburia inulinivorans': 255, 'Rothia dentocariosa': 256, 'Rothia mucilaginosa': 257, 'Ruminococcaceae bacterium D16': 258, 'Ruminococcus albus': 259, 'Ruminococcus bromii': 260, 'Ruminococcus callidus': 261, 'Ruminococcus champanellensis': 262, 'Ruminococcus flavefaciens': 263, 'Ruminococcus gnavus': 264, 'Ruminococcus lactaris': 265, 'Ruminococcus obeum': 266, 'Ruminococcus sp 5 1 39BFAA': 267, 'Ruminococcus sp JC304': 268, 'Ruminococcus torques': 269, 'Saccharomyces cerevisiae': 270, 'Scardovia wiggsiae': 271, 'Shigella flexneri': 272, 'Shigella sonnei': 273, 'Slackia piriformis': 274, 'Solobacterium moorei': 275, 'Staphylococcus aureus': 276, 'Streptococcus agalactiae': 277, 'Streptococcus anginosus': 278, 'Streptococcus australis': 279, 'Streptococcus constellatus': 280, 'Streptococcus cristatus': 281, 'Streptococcus gordonii': 282, 'Streptococcus infantarius': 283, 'Streptococcus infantis': 284, 'Streptococcus intermedius': 285, 'Streptococcus lutetiensis': 286, 'Streptococcus macedonicus': 287, 'Streptococcus mitis oralis pneumoniae': 288, 'Streptococcus mutans': 289, 'Streptococcus oligofermentans': 290, 'Streptococcus parasanguinis': 291, 'Streptococcus pasteurianus': 292, 'Streptococcus peroris': 293, 'Streptococcus salivarius': 294, 'Streptococcus sanguinis': 295, 'Streptococcus sobrinus': 296, 'Streptococcus thermophilus': 297, 'Streptococcus tigurinus': 298, 'Streptococcus vestibularis': 299, 'Subdoligranulum sp 4 3 54A2FAA': 300, 'Subdoligranulum variabile': 301, 'Succinatimonas hippei': 302, 'Sutterella wadsworthensis': 303, 'Turicibacter sanguinis': 304, 'Varibaculum cambriense': 305, 'Veillonella atypica': 306, 'Veillonella dispar': 307, 'Veillonella parvula': 308, 'Weissella cibaria': 309, 'Weissella confusa': 310, '<pad>': 311, '<cls>': 312, '<eoc>': 313}\n","{'Abiotrophia defectiva': 0, 'Acidaminococcus fermentans': 1, 'Acidaminococcus intestini': 2, 'Actinomyces graevenitzii': 3, 'Actinomyces odontolyticus': 4, 'Actinomyces oris': 5, 'Actinomyces turicensis': 6, 'Actinomyces viscosus': 7, 'Adlercreutzia equolifaciens': 8, 'Aggregatibacter segnis': 9, 'Akkermansia muciniphila': 10, 'Alistipes finegoldii': 11, 'Alistipes indistinctus': 12, 'Alistipes onderdonkii': 13, 'Alistipes putredinis': 14, 'Alistipes senegalensis': 15, 'Alistipes shahii': 16, 'Alistipes sp AP11': 17, 'Alistipes sp HGB5': 18, 'Alloscardovia omnicolens': 19, 'Anaerococcus obesiensis': 20, 'Anaerococcus vaginalis': 21, 'Anaerofustis stercorihominis': 22, 'Anaeroglobus geminatus': 23, 'Anaerostipes caccae': 24, 'Anaerostipes hadrus': 25, 'Anaerotruncus colihominis': 26, 'Atopobium parvulum': 27, 'Atopobium rimae': 28, 'Atopobium vaginae': 29, 'Bacteroidales bacterium ph8': 30, 'Bacteroides caccae': 31, 'Bacteroides cellulosilyticus': 32, 'Bacteroides clarus': 33, 'Bacteroides coprocola': 34, 'Bacteroides coprophilus': 35, 'Bacteroides dorei': 36, 'Bacteroides eggerthii': 37, 'Bacteroides faecis': 38, 'Bacteroides finegoldii': 39, 'Bacteroides fragilis': 40, 'Bacteroides intestinalis': 41, 'Bacteroides massiliensis': 42, 'Bacteroides nordii': 43, 'Bacteroides oleiciplenus': 44, 'Bacteroides ovatus': 45, 'Bacteroides pectinophilus': 46, 'Bacteroides plebeius': 47, 'Bacteroides salyersiae': 48, 'Bacteroides sp 2 1 22': 49, 'Bacteroides sp 3 1 19': 50, 'Bacteroides sp 4 3 47FAA': 51, 'Bacteroides stercoris': 52, 'Bacteroides thetaiotaomicron': 53, 'Bacteroides uniformis': 54, 'Bacteroides vulgatus': 55, 'Bacteroides xylanisolvens': 56, 'Barnesiella intestinihominis': 57, 'Bifidobacterium adolescentis': 58, 'Bifidobacterium angulatum': 59, 'Bifidobacterium animalis': 60, 'Bifidobacterium bifidum': 61, 'Bifidobacterium breve': 62, 'Bifidobacterium catenulatum': 63, 'Bifidobacterium dentium': 64, 'Bifidobacterium longum': 65, 'Bifidobacterium pseudocatenulatum': 66, 'Bilophila wadsworthia': 67, 'Blautia hansenii': 68, 'Blautia hydrogenotrophica': 69, 'Blautia producta': 70, 'Burkholderiales bacterium 1 1 47': 71, 'Butyricicoccus pullicaecorum': 72, 'Butyricimonas synergistica': 73, 'Butyrivibrio crossotus': 74, 'Campylobacter hominis': 75, 'Catenibacterium mitsuokai': 76, 'Citrobacter freundii': 77, 'Clostridiaceae bacterium JC118': 78, 'Clostridiales bacterium 1 7 47FAA': 79, 'Clostridium sp ATCC BAA 442': 80, 'Clostridium sp KLE 1755': 81, 'Clostridium sp L2 50': 82, 'Clostridium asparagiforme': 83, 'Clostridium bartlettii': 84, 'Clostridium bolteae': 85, 'Clostridium celatum': 86, 'Clostridium citroniae': 87, 'Clostridium clostridioforme': 88, 'Clostridium difficile': 89, 'Clostridium hathewayi': 90, 'Clostridium hylemonae': 91, 'Clostridium innocuum': 92, 'Clostridium leptum': 93, 'Clostridium methylpentosum': 94, 'Clostridium nexile': 95, 'Clostridium perfringens': 96, 'Clostridium ramosum': 97, 'Clostridium scindens': 98, 'Clostridium spiroforme': 99, 'Clostridium symbiosum': 100, 'Collinsella aerofaciens': 101, 'Collinsella intestinalis': 102, 'Collinsella tanakaei': 103, 'Coprobacillus sp 29 1': 104, 'Coprobacillus sp D6': 105, 'Coprobacter fastidiosus': 106, 'Coprococcus sp ART55 1': 107, 'Coprococcus catus': 108, 'Coprococcus comes': 109, 'Coprococcus eutactus': 110, 'Coriobacteriaceae bacterium phI': 111, 'Corynebacterium durum': 112, 'Desulfovibrio desulfuricans': 113, 'Desulfovibrio piger': 114, 'Dialister invisus': 115, 'Dialister succinatiphilus': 116, 'Dorea formicigenerans': 117, 'Dorea longicatena': 118, 'Eggerthella lenta': 119, 'Enterobacter aerogenes': 120, 'Enterobacter cloacae': 121, 'Enterococcus avium': 122, 'Enterococcus casseliflavus': 123, 'Enterococcus durans': 124, 'Enterococcus faecalis': 125, 'Enterococcus faecium': 126, 'Erysipelotrichaceae bacterium 2 2 44A': 127, 'Erysipelotrichaceae bacterium 21 3': 128, 'Erysipelotrichaceae bacterium 3 1 53': 129, 'Erysipelotrichaceae bacterium 5 2 54FAA': 130, 'Erysipelotrichaceae bacterium 6 1 45': 131, 'Escherichia coli': 132, 'Eubacterium biforme': 133, 'Eubacterium brachy': 134, 'Eubacterium cylindroides': 135, 'Eubacterium dolichum': 136, 'Eubacterium eligens': 137, 'Eubacterium hallii': 138, 'Eubacterium infirmum': 139, 'Eubacterium limosum': 140, 'Eubacterium ramulus': 141, 'Eubacterium rectale': 142, 'Eubacterium siraeum': 143, 'Eubacterium sp 3 1 31': 144, 'Eubacterium ventriosum': 145, 'Faecalibacterium prausnitzii': 146, 'Finegoldia magna': 147, 'Flavonifractor plautii': 148, 'Fusobacterium gonidiaformans': 149, 'Fusobacterium mortiferum': 150, 'Fusobacterium nucleatum': 151, 'Fusobacterium periodonticum': 152, 'Fusobacterium ulcerans': 153, 'Fusobacterium varium': 154, 'Gardnerella vaginalis': 155, 'Gemella haemolysans': 156, 'Gemella morbillorum': 157, 'Gemella sanguinis': 158, 'Gordonibacter pamelaeae': 159, 'Granulicatella adiacens': 160, 'Granulicatella elegans': 161, 'Haemophilus haemolyticus': 162, 'Haemophilus parainfluenzae': 163, 'Haemophilus pittmaniae': 164, 'Haemophilus sputorum': 165, 'Holdemania filiformis': 166, 'Holdemania sp AP2': 167, 'Klebsiella oxytoca': 168, 'Klebsiella pneumoniae': 169, 'Lachnospiraceae bacterium 1 1 57FAA': 170, 'Lachnospiraceae bacterium 1 4 56FAA': 171, 'Lachnospiraceae bacterium 2 1 46FAA': 172, 'Lachnospiraceae bacterium 2 1 58FAA': 173, 'Lachnospiraceae bacterium 3 1 46FAA': 174, 'Lachnospiraceae bacterium 3 1 57FAA CT1': 175, 'Lachnospiraceae bacterium 4 1 37FAA': 176, 'Lachnospiraceae bacterium 5 1 57FAA': 177, 'Lachnospiraceae bacterium 5 1 63FAA': 178, 'Lachnospiraceae bacterium 6 1 63FAA': 179, 'Lachnospiraceae bacterium 7 1 58FAA': 180, 'Lachnospiraceae bacterium 8 1 57FAA': 181, 'Lachnospiraceae bacterium 9 1 43BFAA': 182, 'Lactobacillus acidophilus': 183, 'Lactobacillus amylovorus': 184, 'Lactobacillus casei paracasei': 185, 'Lactobacillus crispatus': 186, 'Lactobacillus curvatus': 187, 'Lactobacillus delbrueckii': 188, 'Lactobacillus fermentum': 189, 'Lactobacillus gasseri': 190, 'Lactobacillus iners': 191, 'Lactobacillus mucosae': 192, 'Lactobacillus oris': 193, 'Lactobacillus plantarum': 194, 'Lactobacillus reuteri': 195, 'Lactobacillus rhamnosus': 196, 'Lactobacillus ruminis': 197, 'Lactobacillus sakei': 198, 'Lactobacillus salivarius': 199, 'Lactobacillus sanfranciscensis': 200, 'Lactobacillus vaginalis': 201, 'Lactococcus garvieae': 202, 'Lactococcus lactis': 203, 'Lactococcus raffinolactis': 204, 'Leuconostoc lactis': 205, 'Leuconostoc mesenteroides': 206, 'Leuconostoc pseudomesenteroides': 207, 'Megamonas funiformis': 208, 'Megamonas hypermegale': 209, 'Megamonas rupellensis': 210, 'Megasphaera elsdenii': 211, 'Megasphaera micronuciformis': 212, 'Methanobrevibacter smithii': 213, 'Methanosphaera stadtmanae': 214, 'Mitsuokella multacida': 215, 'Morganella morganii': 216, 'Odoribacter laneus': 217, 'Odoribacter splanchnicus': 218, 'Oribacterium sinus': 219, 'Oscillibacter sp KLE 1728': 220, 'Oscillibacter sp KLE 1745': 221, 'Oxalobacter formigenes': 222, 'Parabacteroides distasonis': 223, 'Parabacteroides goldsteinii': 224, 'Parabacteroides johnsonii': 225, 'Parabacteroides merdae': 226, 'Paraprevotella clara': 227, 'Paraprevotella xylaniphila': 228, 'Parascardovia denticolens': 229, 'Parasutterella excrementihominis': 230, 'Parvimonas micra': 231, 'Pediococcus pentosaceus': 232, 'Peptoniphilus harei': 233, 'Peptoniphilus lacrimalis': 234, 'Peptostreptococcus anaerobius': 235, 'Peptostreptococcus stomatis': 236, 'Phascolarctobacterium succinatutens': 237, 'Porphyromonas asaccharolytica': 238, 'Porphyromonas bennonis': 239, 'Porphyromonas somerae': 240, 'Porphyromonas uenonis': 241, 'Prevotella bivia': 242, 'Prevotella buccalis': 243, 'Prevotella copri': 244, 'Prevotella disiens': 245, 'Prevotella stercorea': 246, 'Prevotella timonensis': 247, 'Propionibacterium freudenreichii': 248, 'Proteus mirabilis': 249, 'Pseudoflavonifractor capillosus': 250, 'Pyramidobacter piscolens': 251, 'Raoultella ornithinolytica': 252, 'Roseburia hominis': 253, 'Roseburia intestinalis': 254, 'Roseburia inulinivorans': 255, 'Rothia dentocariosa': 256, 'Rothia mucilaginosa': 257, 'Ruminococcaceae bacterium D16': 258, 'Ruminococcus albus': 259, 'Ruminococcus bromii': 260, 'Ruminococcus callidus': 261, 'Ruminococcus champanellensis': 262, 'Ruminococcus flavefaciens': 263, 'Ruminococcus gnavus': 264, 'Ruminococcus lactaris': 265, 'Ruminococcus obeum': 266, 'Ruminococcus sp 5 1 39BFAA': 267, 'Ruminococcus sp JC304': 268, 'Ruminococcus torques': 269, 'Saccharomyces cerevisiae': 270, 'Scardovia wiggsiae': 271, 'Shigella flexneri': 272, 'Shigella sonnei': 273, 'Slackia piriformis': 274, 'Solobacterium moorei': 275, 'Staphylococcus aureus': 276, 'Streptococcus agalactiae': 277, 'Streptococcus anginosus': 278, 'Streptococcus australis': 279, 'Streptococcus constellatus': 280, 'Streptococcus cristatus': 281, 'Streptococcus gordonii': 282, 'Streptococcus infantarius': 283, 'Streptococcus infantis': 284, 'Streptococcus intermedius': 285, 'Streptococcus lutetiensis': 286, 'Streptococcus macedonicus': 287, 'Streptococcus mitis oralis pneumoniae': 288, 'Streptococcus mutans': 289, 'Streptococcus oligofermentans': 290, 'Streptococcus parasanguinis': 291, 'Streptococcus pasteurianus': 292, 'Streptococcus peroris': 293, 'Streptococcus salivarius': 294, 'Streptococcus sanguinis': 295, 'Streptococcus sobrinus': 296, 'Streptococcus thermophilus': 297, 'Streptococcus tigurinus': 298, 'Streptococcus vestibularis': 299, 'Subdoligranulum sp 4 3 54A2FAA': 300, 'Subdoligranulum variabile': 301, 'Succinatimonas hippei': 302, 'Sutterella wadsworthensis': 303, 'Turicibacter sanguinis': 304, 'Varibaculum cambriense': 305, 'Veillonella atypica': 306, 'Veillonella dispar': 307, 'Veillonella parvula': 308, 'Weissella cibaria': 309, 'Weissella confusa': 310, '<pad>': 311, '<cls>': 312, '<eoc>': 313}\n","{'<eoc>': 313, '<cls>': 312, '<pad>': 311, 'Weissella confusa': 310, 'Weissella cibaria': 309, 'Veillonella parvula': 308, 'Veillonella dispar': 307, 'Veillonella atypica': 306, 'Varibaculum cambriense': 305, 'Turicibacter sanguinis': 304, 'Sutterella wadsworthensis': 303, 'Succinatimonas hippei': 302, 'Subdoligranulum variabile': 301, 'Subdoligranulum sp 4 3 54A2FAA': 300, 'Streptococcus vestibularis': 299, 'Streptococcus tigurinus': 298, 'Streptococcus thermophilus': 297, 'Streptococcus sobrinus': 296, 'Streptococcus sanguinis': 295, 'Streptococcus salivarius': 294, 'Streptococcus peroris': 293, 'Streptococcus pasteurianus': 292, 'Streptococcus parasanguinis': 291, 'Streptococcus oligofermentans': 290, 'Streptococcus mutans': 289, 'Streptococcus mitis oralis pneumoniae': 288, 'Streptococcus macedonicus': 287, 'Streptococcus lutetiensis': 286, 'Streptococcus intermedius': 285, 'Streptococcus infantis': 284, 'Streptococcus infantarius': 283, 'Streptococcus gordonii': 282, 'Streptococcus cristatus': 281, 'Streptococcus constellatus': 280, 'Streptococcus australis': 279, 'Streptococcus anginosus': 278, 'Streptococcus agalactiae': 277, 'Staphylococcus aureus': 276, 'Solobacterium moorei': 275, 'Slackia piriformis': 274, 'Shigella sonnei': 273, 'Shigella flexneri': 272, 'Scardovia wiggsiae': 271, 'Saccharomyces cerevisiae': 270, 'Ruminococcus torques': 269, 'Ruminococcus sp JC304': 268, 'Ruminococcus sp 5 1 39BFAA': 267, 'Ruminococcus obeum': 266, 'Ruminococcus lactaris': 265, 'Ruminococcus gnavus': 264, 'Ruminococcus flavefaciens': 263, 'Ruminococcus champanellensis': 262, 'Ruminococcus callidus': 261, 'Ruminococcus bromii': 260, 'Ruminococcus albus': 259, 'Ruminococcaceae bacterium D16': 258, 'Rothia mucilaginosa': 257, 'Rothia dentocariosa': 256, 'Roseburia inulinivorans': 255, 'Roseburia intestinalis': 254, 'Roseburia hominis': 253, 'Raoultella ornithinolytica': 252, 'Pyramidobacter piscolens': 251, 'Pseudoflavonifractor capillosus': 250, 'Proteus mirabilis': 249, 'Propionibacterium freudenreichii': 248, 'Prevotella timonensis': 247, 'Prevotella stercorea': 246, 'Prevotella disiens': 245, 'Prevotella copri': 244, 'Prevotella buccalis': 243, 'Prevotella bivia': 242, 'Porphyromonas uenonis': 241, 'Porphyromonas somerae': 240, 'Porphyromonas bennonis': 239, 'Porphyromonas asaccharolytica': 238, 'Phascolarctobacterium succinatutens': 237, 'Peptostreptococcus stomatis': 236, 'Peptostreptococcus anaerobius': 235, 'Peptoniphilus lacrimalis': 234, 'Peptoniphilus harei': 233, 'Pediococcus pentosaceus': 232, 'Parvimonas micra': 231, 'Parasutterella excrementihominis': 230, 'Parascardovia denticolens': 229, 'Paraprevotella xylaniphila': 228, 'Paraprevotella clara': 227, 'Parabacteroides merdae': 226, 'Parabacteroides johnsonii': 225, 'Parabacteroides goldsteinii': 224, 'Parabacteroides distasonis': 223, 'Oxalobacter formigenes': 222, 'Oscillibacter sp KLE 1745': 221, 'Oscillibacter sp KLE 1728': 220, 'Oribacterium sinus': 219, 'Odoribacter splanchnicus': 218, 'Odoribacter laneus': 217, 'Morganella morganii': 216, 'Mitsuokella multacida': 215, 'Methanosphaera stadtmanae': 214, 'Methanobrevibacter smithii': 213, 'Megasphaera micronuciformis': 212, 'Megasphaera elsdenii': 211, 'Megamonas rupellensis': 210, 'Megamonas hypermegale': 209, 'Megamonas funiformis': 208, 'Leuconostoc pseudomesenteroides': 207, 'Leuconostoc mesenteroides': 206, 'Leuconostoc lactis': 205, 'Lactococcus raffinolactis': 204, 'Lactococcus lactis': 203, 'Lactococcus garvieae': 202, 'Lactobacillus vaginalis': 201, 'Lactobacillus sanfranciscensis': 200, 'Lactobacillus salivarius': 199, 'Lactobacillus sakei': 198, 'Lactobacillus ruminis': 197, 'Lactobacillus rhamnosus': 196, 'Lactobacillus reuteri': 195, 'Lactobacillus plantarum': 194, 'Lactobacillus oris': 193, 'Lactobacillus mucosae': 192, 'Lactobacillus iners': 191, 'Lactobacillus gasseri': 190, 'Lactobacillus fermentum': 189, 'Lactobacillus delbrueckii': 188, 'Lactobacillus curvatus': 187, 'Lactobacillus crispatus': 186, 'Lactobacillus casei paracasei': 185, 'Lactobacillus amylovorus': 184, 'Lactobacillus acidophilus': 183, 'Lachnospiraceae bacterium 9 1 43BFAA': 182, 'Lachnospiraceae bacterium 8 1 57FAA': 181, 'Lachnospiraceae bacterium 7 1 58FAA': 180, 'Lachnospiraceae bacterium 6 1 63FAA': 179, 'Lachnospiraceae bacterium 5 1 63FAA': 178, 'Lachnospiraceae bacterium 5 1 57FAA': 177, 'Lachnospiraceae bacterium 4 1 37FAA': 176, 'Lachnospiraceae bacterium 3 1 57FAA CT1': 175, 'Lachnospiraceae bacterium 3 1 46FAA': 174, 'Lachnospiraceae bacterium 2 1 58FAA': 173, 'Lachnospiraceae bacterium 2 1 46FAA': 172, 'Lachnospiraceae bacterium 1 4 56FAA': 171, 'Lachnospiraceae bacterium 1 1 57FAA': 170, 'Klebsiella pneumoniae': 169, 'Klebsiella oxytoca': 168, 'Holdemania sp AP2': 167, 'Holdemania filiformis': 166, 'Haemophilus sputorum': 165, 'Haemophilus pittmaniae': 164, 'Haemophilus parainfluenzae': 163, 'Haemophilus haemolyticus': 162, 'Granulicatella elegans': 161, 'Granulicatella adiacens': 160, 'Gordonibacter pamelaeae': 159, 'Gemella sanguinis': 158, 'Gemella morbillorum': 157, 'Gemella haemolysans': 156, 'Gardnerella vaginalis': 155, 'Fusobacterium varium': 154, 'Fusobacterium ulcerans': 153, 'Fusobacterium periodonticum': 152, 'Fusobacterium nucleatum': 151, 'Fusobacterium mortiferum': 150, 'Fusobacterium gonidiaformans': 149, 'Flavonifractor plautii': 148, 'Finegoldia magna': 147, 'Faecalibacterium prausnitzii': 146, 'Eubacterium ventriosum': 145, 'Eubacterium sp 3 1 31': 144, 'Eubacterium siraeum': 143, 'Eubacterium rectale': 142, 'Eubacterium ramulus': 141, 'Eubacterium limosum': 140, 'Eubacterium infirmum': 139, 'Eubacterium hallii': 138, 'Eubacterium eligens': 137, 'Eubacterium dolichum': 136, 'Eubacterium cylindroides': 135, 'Eubacterium brachy': 134, 'Eubacterium biforme': 133, 'Escherichia coli': 132, 'Erysipelotrichaceae bacterium 6 1 45': 131, 'Erysipelotrichaceae bacterium 5 2 54FAA': 130, 'Erysipelotrichaceae bacterium 3 1 53': 129, 'Erysipelotrichaceae bacterium 21 3': 128, 'Erysipelotrichaceae bacterium 2 2 44A': 127, 'Enterococcus faecium': 126, 'Enterococcus faecalis': 125, 'Enterococcus durans': 124, 'Enterococcus casseliflavus': 123, 'Enterococcus avium': 122, 'Enterobacter cloacae': 121, 'Enterobacter aerogenes': 120, 'Eggerthella lenta': 119, 'Dorea longicatena': 118, 'Dorea formicigenerans': 117, 'Dialister succinatiphilus': 116, 'Dialister invisus': 115, 'Desulfovibrio piger': 114, 'Desulfovibrio desulfuricans': 113, 'Corynebacterium durum': 112, 'Coriobacteriaceae bacterium phI': 111, 'Coprococcus eutactus': 110, 'Coprococcus comes': 109, 'Coprococcus catus': 108, 'Coprococcus sp ART55 1': 107, 'Coprobacter fastidiosus': 106, 'Coprobacillus sp D6': 105, 'Coprobacillus sp 29 1': 104, 'Collinsella tanakaei': 103, 'Collinsella intestinalis': 102, 'Collinsella aerofaciens': 101, 'Clostridium symbiosum': 100, 'Clostridium spiroforme': 99, 'Clostridium scindens': 98, 'Clostridium ramosum': 97, 'Clostridium perfringens': 96, 'Clostridium nexile': 95, 'Clostridium methylpentosum': 94, 'Clostridium leptum': 93, 'Clostridium innocuum': 92, 'Clostridium hylemonae': 91, 'Clostridium hathewayi': 90, 'Clostridium difficile': 89, 'Clostridium clostridioforme': 88, 'Clostridium citroniae': 87, 'Clostridium celatum': 86, 'Clostridium bolteae': 85, 'Clostridium bartlettii': 84, 'Clostridium asparagiforme': 83, 'Clostridium sp L2 50': 82, 'Clostridium sp KLE 1755': 81, 'Clostridium sp ATCC BAA 442': 80, 'Clostridiales bacterium 1 7 47FAA': 79, 'Clostridiaceae bacterium JC118': 78, 'Citrobacter freundii': 77, 'Catenibacterium mitsuokai': 76, 'Campylobacter hominis': 75, 'Butyrivibrio crossotus': 74, 'Butyricimonas synergistica': 73, 'Butyricicoccus pullicaecorum': 72, 'Burkholderiales bacterium 1 1 47': 71, 'Blautia producta': 70, 'Blautia hydrogenotrophica': 69, 'Blautia hansenii': 68, 'Bilophila wadsworthia': 67, 'Bifidobacterium pseudocatenulatum': 66, 'Bifidobacterium longum': 65, 'Bifidobacterium dentium': 64, 'Bifidobacterium catenulatum': 63, 'Bifidobacterium breve': 62, 'Bifidobacterium bifidum': 61, 'Bifidobacterium animalis': 60, 'Bifidobacterium angulatum': 59, 'Bifidobacterium adolescentis': 58, 'Barnesiella intestinihominis': 57, 'Bacteroides xylanisolvens': 56, 'Bacteroides vulgatus': 55, 'Bacteroides uniformis': 54, 'Bacteroides thetaiotaomicron': 53, 'Bacteroides stercoris': 52, 'Bacteroides sp 4 3 47FAA': 51, 'Bacteroides sp 3 1 19': 50, 'Bacteroides sp 2 1 22': 49, 'Bacteroides salyersiae': 48, 'Bacteroides plebeius': 47, 'Bacteroides pectinophilus': 46, 'Bacteroides ovatus': 45, 'Bacteroides oleiciplenus': 44, 'Bacteroides nordii': 43, 'Bacteroides massiliensis': 42, 'Bacteroides intestinalis': 41, 'Bacteroides fragilis': 40, 'Bacteroides finegoldii': 39, 'Bacteroides faecis': 38, 'Bacteroides eggerthii': 37, 'Bacteroides dorei': 36, 'Bacteroides coprophilus': 35, 'Bacteroides coprocola': 34, 'Bacteroides clarus': 33, 'Bacteroides cellulosilyticus': 32, 'Bacteroides caccae': 31, 'Bacteroidales bacterium ph8': 30, 'Atopobium vaginae': 29, 'Atopobium rimae': 28, 'Atopobium parvulum': 27, 'Anaerotruncus colihominis': 26, 'Anaerostipes hadrus': 25, 'Anaerostipes caccae': 24, 'Anaeroglobus geminatus': 23, 'Anaerofustis stercorihominis': 22, 'Anaerococcus vaginalis': 21, 'Anaerococcus obesiensis': 20, 'Alloscardovia omnicolens': 19, 'Alistipes sp HGB5': 18, 'Alistipes sp AP11': 17, 'Alistipes shahii': 16, 'Alistipes senegalensis': 15, 'Alistipes putredinis': 14, 'Alistipes onderdonkii': 13, 'Alistipes indistinctus': 12, 'Alistipes finegoldii': 11, 'Akkermansia muciniphila': 10, 'Aggregatibacter segnis': 9, 'Adlercreutzia equolifaciens': 8, 'Actinomyces viscosus': 7, 'Actinomyces turicensis': 6, 'Actinomyces oris': 5, 'Actinomyces odontolyticus': 4, 'Actinomyces graevenitzii': 3, 'Acidaminococcus intestini': 2, 'Acidaminococcus fermentans': 1, 'Abiotrophia defectiva': 0}\n"]}],"source":["# Creates the vocab list, which is every gene seen across every cell across all the batches in the dataset\n","vocab_dict = {value: index for index, value in enumerate(adata.var[\"organism_name\"])}\n","vocab = OrganismVocab.from_dict(vocab_dict, default_token = None)\n","for s in special_tokens:\n","  if s not in vocab:\n","    vocab.append_token(s)\n","vocab.set_default_token(pad_token)\n","print(vocab.get_itos()) # List mapping indices to tokens.\n","l = vocab.get_itos()\n","print(len(vocab.get_itos()))\n","print(vocab.get_default_index())\n","print(vocab.get_stoi()) # Dictionary mapping tokens to indices.\n","print(dict(sorted(vocab.get_stoi().items(), key=lambda item: item[1])))\n","print(dict(sorted(vocab.get_stoi().items(), key=lambda item: item[1], reverse=True)))"]},{"cell_type":"markdown","metadata":{"id":"KRDI1eAJ9LOB"},"source":["# Preprocess Data"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"RW3rj4VP-fuz","executionInfo":{"status":"ok","timestamp":1756434358128,"user_tz":240,"elapsed":37,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["class Preprocessor:\n","    \"\"\"\n","    Prepare data into training, valid and test split. Normalize raw expression\n","    values, binning or using other transform into the preset model input format.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        use_key: Optional[str] = None,\n","        filter_gene_by_counts: Union[int, bool] = False,\n","        filter_cell_by_counts: Union[int, bool] = False,\n","        normalize_total: Union[float, bool] = 1e4,\n","        result_normed_key: Optional[str] = \"X_normed\",\n","        log1p: bool = False,\n","        result_log1p_key: str = \"X_log1p\",\n","        subset_hvg: Union[int, bool] = False,\n","        hvg_use_key: Optional[str] = None,\n","        hvg_flavor: str = \"seurat_v3\",\n","        binning: Optional[int] = None,\n","        result_binned_key: str = \"X_binned\",\n","    ):\n","        r\"\"\"\n","        Set up the preprocessor, use the args to config the workflow steps.\n","\n","        Args:\n","\n","        use_key (:class:`str`, optional):\n","            The key of :class:`~anndata.AnnData` to use for preprocessing.\n","        filter_gene_by_counts (:class:`int` or :class:`bool`, default: ``False``):\n","            Whther to filter genes by counts, if :class:`int`, filter genes with counts\n","        filter_cell_by_counts (:class:`int` or :class:`bool`, default: ``False``):\n","            Whther to filter cells by counts, if :class:`int`, filter cells with counts\n","        normalize_total (:class:`float` or :class:`bool`, default: ``1e4``):\n","            Whether to normalize the total counts of each cell to a specific value.\n","        result_normed_key (:class:`str`, default: ``\"X_normed\"``):\n","            The key of :class:`~anndata.AnnData` to store the normalized data. If\n","            :class:`None`, will use normed data to replce the :attr:`use_key`.\n","        log1p (:class:`bool`, default: ``True``):\n","            Whether to apply log1p transform to the normalized data.\n","        result_log1p_key (:class:`str`, default: ``\"X_log1p\"``):\n","            The key of :class:`~anndata.AnnData` to store the log1p transformed data.\n","        subset_hvg (:class:`int` or :class:`bool`, default: ``False``):\n","            Whether to subset highly variable genes.\n","        hvg_use_key (:class:`str`, optional):\n","            The key of :class:`~anndata.AnnData` to use for calculating highly variable\n","            genes. If :class:`None`, will use :attr:`adata.X`.\n","        hvg_flavor (:class:`str`, default: ``\"seurat_v3\"``):\n","            The flavor of highly variable genes selection. See\n","            :func:`scanpy.pp.highly_variable_genes` for more details.\n","        binning (:class:`int`, optional):\n","            Whether to bin the data into discrete values of number of bins provided.\n","        result_binned_key (:class:`str`, default: ``\"X_binned\"``):\n","            The key of :class:`~anndata.AnnData` to store the binned data.\n","        \"\"\"\n","        self.use_key = use_key\n","        self.filter_gene_by_counts = filter_gene_by_counts\n","        self.filter_cell_by_counts = filter_cell_by_counts\n","        self.normalize_total = normalize_total\n","        self.result_normed_key = result_normed_key\n","        self.log1p = log1p\n","        self.result_log1p_key = result_log1p_key\n","        self.subset_hvg = subset_hvg\n","        self.hvg_use_key = hvg_use_key\n","        self.hvg_flavor = hvg_flavor\n","        self.binning = binning\n","        self.result_binned_key = result_binned_key\n","\n","    def __call__(self, adata: AnnData, batch_key: Optional[str] = None) -> Dict:\n","        \"\"\"\n","        format controls the different input value wrapping, including categorical\n","        binned style, fixed-sum normalized counts, log1p fixed-sum normalized counts, etc.\n","\n","        Args:\n","\n","        adata (:class:`AnnData`):\n","            The :class:`AnnData` object to preprocess.\n","        batch_key (:class:`str`, optional):\n","            The key of :class:`AnnData.obs` to use for batch information. This arg\n","            is used in the highly variable gene selection step.\n","        \"\"\"\n","\n","        # data = _get_obs_rep(adata)\n","        # print(data.shape)\n","        # print(type(data))\n","        # max_, min_ = data.max(), data.min()\n","        # print(max_)\n","        # print(min_)\n","        # indices = np.where(data == 100)\n","        # print(indices)\n","        # row_name = adata.obs.index[indices[0]]\n","        # col_name = adata.var.index[indices[1]]\n","        # print(row_name)\n","        # print(col_name)\n","\n","        # row = adata[863].X\n","        # print(row)\n","\n","        key_to_process = self.use_key # is \"X\" here\n","        # preliminary checks, will use later\n","        if key_to_process == \"X\":\n","            key_to_process = None  # the following scanpy apis use arg None to use X\n","        is_logged = self.check_logged(adata, obs_key=key_to_process) # Check if the data is already log1p transformed. Is false here, reads/counts are raw values\n","        logger.info(f\"Is data already log1p transformed: {is_logged}\")\n","\n","        # step 1: filter organisms\n","        if self.filter_gene_by_counts: # use scanpy library, all organisms must appear at least 3 times across all the cells\n","            logger.info(\"Filtering genes by counts ...\")\n","            sc.pp.filter_genes(\n","                adata,\n","                min_counts=self.filter_gene_by_counts\n","                if isinstance(self.filter_gene_by_counts, int)\n","                else None,\n","            )\n","\n","        # step 2: filter cells\n","        if (\n","            isinstance(self.filter_cell_by_counts, int)\n","            and self.filter_cell_by_counts > 0\n","        ): # we don't filter cells by mRNA sequence reads here (so this if statement inside is not run)\n","            logger.info(\"Filtering cells by counts ...\")\n","            sc.pp.filter_cells(\n","                adata,\n","                min_counts=self.filter_cell_by_counts\n","                if isinstance(self.filter_cell_by_counts, int)\n","                else None,\n","            )\n","\n","        # step 3: normalize total\n","        if self.normalize_total: # normalizes the total counts for each cell in the dataset so that the total sum of counts for each cell becomes equal to a target value, stores result in adata.layers[\"X_normed\"]\n","            logger.info(\"Normalizing total counts ...\")\n","            normed_ = sc.pp.normalize_total(\n","                adata,\n","                target_sum=self.normalize_total\n","                if isinstance(self.normalize_total, float)\n","                else None,\n","                layer=key_to_process,\n","                inplace=False,\n","            )[\"X\"]\n","            key_to_process = self.result_normed_key or key_to_process\n","            _set_obs_rep(adata, normed_, layer=key_to_process)\n","\n","        # step 4: log1p\n","        if self.log1p: # set each data point x in X_normed and X_log1p to log_e(x+1) (for all x in X_normed), modifies X_normed and X_log1p\n","            logger.info(\"Log1p transforming ...\")\n","            if is_logged:\n","                logger.warning(\n","                    \"The input data seems to be already log1p transformed. \"\n","                    \"Set `log1p=False` to avoid double log1p transform.\"\n","                )\n","            if self.result_log1p_key: # shallow copy total normed data to new layer \"X_log1p\"\n","                _set_obs_rep(\n","                    adata,\n","                    copy.deepcopy(_get_obs_rep(adata, layer=key_to_process)),\n","                    layer=self.result_log1p_key,\n","                )\n","                key_to_process = self.result_log1p_key\n","            sc.pp.log1p(adata, layer=key_to_process)\n","\n","        # step 5: subset hvg, select and only retain the 1200 most highly variable genes(HVGs) across cells\n","        if self.subset_hvg:\n","            logger.info(\"Subsetting highly variable genes ...\")\n","            if batch_key is None: # batch_key = \"str_batch\"\n","                logger.warning(\n","                    \"No batch_key is provided, will use all cells for HVG selection.\"\n","                )\n","            sc.pp.highly_variable_genes(\n","                adata,\n","                layer=self.hvg_use_key, # The layer of the AnnData object from which the expression data is used for HVG selection. Since self.hvg_use_key is None, the function uses the default layer (adata.X).\n","                n_top_genes=self.subset_hvg # specifies the number of highly variable genes to select. Here, it selects the top 1200 most variable genes.\n","                if isinstance(self.subset_hvg, int)\n","                else None,\n","                batch_key=batch_key, # HVG is done batch wise since batch_key is defined. This means the algorithm first identifies highly the variable genes within each batch. The method then combines the results from all batches and selects a total of 1200 highly variable genes across all batches\n","                flavor=self.hvg_flavor, # self.hvg_flavor=\"seurat_v3\", a popular approach for HVG selection in single-cell data, especially when accounting for multiple batches\n","                subset=True, # only the HVG genes are retained\n","            )\n","\n","        # step 6: binning, essentially convert expression values in R to expression values in int format because raw counts can differ a lot between batches/mRNA read types\n","        if self.binning: #self.binning=51\n","            logger.info(\"Binning data ...\")\n","            if not isinstance(self.binning, int):\n","                raise ValueError(\n","                    \"Binning arg must be an integer, but got {}.\".format(self.binning)\n","                )\n","            n_bins = self.binning  # NOTE: the first bin is always a spectial for zero\n","            binned_rows = []\n","            bin_edges = []\n","            # layer_data = adata.X_log1p\n","            layer_data = _get_obs_rep(adata, layer=key_to_process) # key_to_process=\"X_log1p\"\n","            # Converting a sparse matrix to a dense NumPy array means transforming a matrix that uses a memory-efficient format for storing only non-zero elements (a sparse matrix) into a format where all elements, including zeros, are explicitly stored\n","            layer_data = layer_data.A if issparse(layer_data) else layer_data # In Python’s scipy.sparse module, sparse matrices are often used to efficiently handle large, sparse datasets. Sparse matrices have an .A attribute, which converts the sparse matrix to a dense NumPy array. This is useful when you want to access or manipulate the data as a dense array.\n","            if layer_data.min() < 0:\n","                raise ValueError(\n","                    f\"Assuming non-negative data, but got min value {layer_data.min()}.\"\n","                )\n","            # for i, row in enumerate(layer_data):\n","            #   if row.max() == 0:\n","            #     print(i)\n","            #     row_name = adata.obs.index[i]\n","            #     print(row_name)\n","            f = 0\n","            for row in layer_data: # iterate over the cells\n","                if row.max() == 0:\n","                    logger.warning(\n","                        \"The input data contains a row of all 0s. Please make sure \"\n","                        \"this is expected. You can use the `filter_cell_by_counts` \"\n","                        \"arg to filter out all zero rows.\"\n","                    )\n","                    binned_rows.append(np.zeros_like(row, dtype=np.int64))\n","                    bin_edges.append(np.array([0] * n_bins))\n","                    continue\n","                non_zero_ids = row.nonzero()\n","                non_zero_row = row[non_zero_ids]\n","                bins = np.quantile(non_zero_row, np.linspace(0, 1, n_bins - 1)) # np.linspace with n_bins -1 = 4 calculates 0,0.25,0.5,0.75. np.quantile then computes the number corresponding to each percentile for the row, so each bin should have roughly equal numbers\n","                # bins = np.sort(np.unique(bins))\n","                # NOTE: comment this line for now, since this will make the each category\n","                # has different relative meaning across datasets\n","                non_zero_digits = _digitize(non_zero_row, bins) # sorts the values into the bins\n","\n","                assert non_zero_digits.min() >= 1\n","                assert non_zero_digits.max() <= n_bins - 1\n","                binned_row = np.zeros_like(row, dtype=np.int64)\n","                binned_row[non_zero_ids] = non_zero_digits\n","                # print(bins)\n","                # print(binned_row)\n","                # f = f + 1\n","                # if f == 2:\n","                #   print(1/0)\n","                binned_rows.append(binned_row)\n","                bin_edges.append(np.concatenate([[0], bins]))\n","            adata.layers[self.result_binned_key] = np.stack(binned_rows)\n","            adata.obsm[\"bin_edges\"] = np.stack(bin_edges)\n","\n","    def check_logged(self, adata: AnnData, obs_key: Optional[str] = None) -> bool:\n","        \"\"\"\n","        Check if the data is already log1p transformed.\n","\n","        Args:\n","\n","        adata (:class:`AnnData`):\n","            The :class:`AnnData` object to preprocess.\n","        obs_key (:class:`str`, optional):\n","            The key of :class:`AnnData.obs` to use for batch information. This arg\n","            is used in the highly variable gene selection step.\n","        \"\"\"\n","        # data is set to adata.X by the below call\n","        data = _get_obs_rep(adata, layer=obs_key) # https://github.com/scverse/scanpy/blob/main/src/scanpy/get/get.py\n","        max_, min_ = data.max(), data.min()\n","        if max_ > 30:\n","            return False\n","        if min_ < 0:\n","            return False\n","\n","        non_zero_min = data[data > 0].min()\n","        if non_zero_min >= 1:\n","            return False\n","\n","        return True\n","\n","def _digitize(x: np.ndarray, bins: np.ndarray, side=\"both\") -> np.ndarray:\n","  \"\"\"\n","  Digitize the data into bins. This method spreads data uniformly when bins\n","  have same values.\n","\n","  Args:\n","\n","  x (:class:`np.ndarray`):\n","      The data to digitize.\n","  bins (:class:`np.ndarray`):\n","      The bins to use for digitization, in increasing order.\n","  side (:class:`str`, optional):\n","      The side to use for digitization. If \"one\", the left side is used. If\n","      \"both\", the left and right side are used. Default to \"one\".\n","\n","  Returns:\n","\n","  :class:`np.ndarray`:\n","      The digitized data.\n","  \"\"\"\n","  assert x.ndim == 1 and bins.ndim == 1\n","\n","  left_digits = np.digitize(x, bins)\n","  if side == \"one\":\n","      return left_digits\n","\n","  right_digits = np.digitize(x, bins, right=True)\n","\n","  rands = np.random.rand(len(x))  # uniform random numbers\n","\n","  digits = rands * (right_digits - left_digits) + left_digits\n","  digits = np.ceil(digits).astype(np.int64)\n","  return digits"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiMibadwbCk7","executionInfo":{"status":"ok","timestamp":1756434358138,"user_tz":240,"elapsed":9,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"a2e2bc13-3d25-427e-ab90-052e04e7ddd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["85.39672\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00518, 0.0, 0.23127, 0.22373, 0.00524, 2.01476, 0.02542, 0.0, 0.19987, 0.21755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68541, 0.0, 0.0, 0.0, 0.0, 1.87538, 0.01108, 0.03673, 0.0, 0.0, 0.0017, 0.00279, 0.02995, 4.18308, 0.03324, 0.0, 5.59897, 0.02943, 0.0, 0.68571, 0.0, 1.19949, 0.51686, 0.0, 0.0, 0.0, 7.33447, 0.48283, 2.53571, 0.76634, 0.37293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00198, 0.0, 0.97902, 0.00107, 0.0, 0.0, 0.00574, 0.01402, 0.0, 0.0, 0.0, 0.0, 0.36011, 0.0, 0.0, 0.04357, 0.0, 0.0, 0.0, 0.32664, 0.0, 0.30354, 0.0, 0.09933, 0.17717, 0.0, 0.10058, 0.0, 0.00346, 0.14605, 0.0, 0.78247, 0.0, 0.15075, 0.00388, 0.0, 1.2392, 0.4448, 0.0, 0.6295, 0.0, 0.0, 0.07315, 0.0, 0.42617, 0.0, 0.0, 0.05944, 0.0, 0.01568, 0.0, 0.0, 0.0, 0.50747, 0.25154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.00134, 0.00069, 0.0, 0.0, 3.59157, 4.15824, 0.0, 0.0, 0.28992, 0.0206, 0.0, 0.0, 0.04056, 0.0, 3.12549, 0.0, 0.0, 0.0, 2.21178, 0.0, 0.22868, 0.0, 1.12562, 0.0, 0.0, 0.0, 0.00783, 0.0, 0.0, 0.0, 0.0, 0.04288, 0.00025, 0.0, 0.0, 0.13892, 0.0, 0.00122, 0.39192, 0.0, 0.0, 0.0, 0.19225, 0.01626, 0.0, 0.19356, 0.37661, 0.0, 0.0, 0.02886, 0.0, 0.0, 0.30461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00323, 0.12639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.55074, 0.0, 0.0, 0.0, 0.0, 0.0186, 0.00943, 0.0, 2.67227, 0.0, 0.0, 0.0, 0.031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02116, 0.0, 0.0, 0.0, 0.07724, 1.9367, 0.0, 0.02097, 0.0062, 0.0, 16.05719, 0.0, 0.0, 0.0, 0.65426, 0.0, 1.45721, 3.71851, 0.0, 3.28711, 0.0, 0.0, 0.0, 0.0, 0.18682, 0.0, 0.0, 0.0, 0.01022, 0.0343, 0.0, 0.0, 0.00834, 0.0, 0.04012, 0.0, 0.0, 0.0, 0.00804, 0.0, 0.0, 0.00745, 0.0, 0.0, 0.65308, 0.01567, 0.0, 0.0, 0.0, 0.00781, 0.38295, 0.00192, 0.0, 0.40519, 0.0, 0.0, 0.00097, 0.0, 0.04412, 0.0, 0.0]\n"]}],"source":["print(adata.X[90].sum())\n","print(adata.X[90].tolist())"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFvSQfnt8o4d","executionInfo":{"status":"ok","timestamp":1756434358826,"user_tz":240,"elapsed":687,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"769e4139-b824-47a2-e5d4-951a551ee449"},"outputs":[{"output_type":"stream","name":"stdout","text":["microbiomeGPT - INFO - Is data already log1p transformed: False\n","microbiomeGPT - INFO - Binning data ...\n"]}],"source":["preprocessor = Preprocessor(\n","    use_key=\"X\",  # the key in adata.layers to use as raw data\n","    filter_gene_by_counts=None,  # step 1\n","    filter_cell_by_counts=False,  # step 2\n","    normalize_total=None,  # 3. data is already normalized and sums to 100 across each row\n","    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n","    log1p=config.do_log1p_normalization,  # 4. whether to log1p the normalized data\n","    result_log1p_key=\"X_log1p\",\n","    subset_hvg=None,  # 5. whether to subset the raw data to highly variable genes, is None here are we already are only retaining the species which have an abundance of at least 0.01% in at least 10% of the samples\n","    hvg_flavor=\"seurat_v3\" if config.do_log1p_normalization else \"cell_ranger\",\n","    binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins (binning=50 here)\n","    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",")\n","preprocessor(adata, batch_key=None)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fwtkkr--QDbB","executionInfo":{"status":"ok","timestamp":1756434358846,"user_tz":240,"elapsed":15,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"91100a89-c8aa-4e20-e470-48332afeb2c1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AnnData object with n_obs × n_vars = 4347 × 311\n","    var: 'organism_name'\n","    obsm: 'bin_edges'\n","    layers: 'X_binned'"]},"metadata":{},"execution_count":27}],"source":["adata"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jyezk7OBQB2x","executionInfo":{"status":"ok","timestamp":1756434358939,"user_tz":240,"elapsed":89,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"043a4a7b-4094-4509-c5ba-64cec48be181"},"outputs":[{"output_type":"stream","name":"stdout","text":["85.39672\n","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00518, 0.0, 0.23127, 0.22373, 0.00524, 2.01476, 0.02542, 0.0, 0.19987, 0.21755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68541, 0.0, 0.0, 0.0, 0.0, 1.87538, 0.01108, 0.03673, 0.0, 0.0, 0.0017, 0.00279, 0.02995, 4.18308, 0.03324, 0.0, 5.59897, 0.02943, 0.0, 0.68571, 0.0, 1.19949, 0.51686, 0.0, 0.0, 0.0, 7.33447, 0.48283, 2.53571, 0.76634, 0.37293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00198, 0.0, 0.97902, 0.00107, 0.0, 0.0, 0.00574, 0.01402, 0.0, 0.0, 0.0, 0.0, 0.36011, 0.0, 0.0, 0.04357, 0.0, 0.0, 0.0, 0.32664, 0.0, 0.30354, 0.0, 0.09933, 0.17717, 0.0, 0.10058, 0.0, 0.00346, 0.14605, 0.0, 0.78247, 0.0, 0.15075, 0.00388, 0.0, 1.2392, 0.4448, 0.0, 0.6295, 0.0, 0.0, 0.07315, 0.0, 0.42617, 0.0, 0.0, 0.05944, 0.0, 0.01568, 0.0, 0.0, 0.0, 0.50747, 0.25154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.00134, 0.00069, 0.0, 0.0, 3.59157, 4.15824, 0.0, 0.0, 0.28992, 0.0206, 0.0, 0.0, 0.04056, 0.0, 3.12549, 0.0, 0.0, 0.0, 2.21178, 0.0, 0.22868, 0.0, 1.12562, 0.0, 0.0, 0.0, 0.00783, 0.0, 0.0, 0.0, 0.0, 0.04288, 0.00025, 0.0, 0.0, 0.13892, 0.0, 0.00122, 0.39192, 0.0, 0.0, 0.0, 0.19225, 0.01626, 0.0, 0.19356, 0.37661, 0.0, 0.0, 0.02886, 0.0, 0.0, 0.30461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00323, 0.12639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.55074, 0.0, 0.0, 0.0, 0.0, 0.0186, 0.00943, 0.0, 2.67227, 0.0, 0.0, 0.0, 0.031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02116, 0.0, 0.0, 0.0, 0.07724, 1.9367, 0.0, 0.02097, 0.0062, 0.0, 16.05719, 0.0, 0.0, 0.0, 0.65426, 0.0, 1.45721, 3.71851, 0.0, 3.28711, 0.0, 0.0, 0.0, 0.0, 0.18682, 0.0, 0.0, 0.0, 0.01022, 0.0343, 0.0, 0.0, 0.00834, 0.0, 0.04012, 0.0, 0.0, 0.0, 0.00804, 0.0, 0.0, 0.00745, 0.0, 0.0, 0.65308, 0.01567, 0.0, 0.0, 0.0, 0.00781, 0.38295, 0.00192, 0.0, 0.40519, 0.0, 0.0, 0.00097, 0.0, 0.04412, 0.0, 0.0]\n"]}],"source":["print(adata.X[90].sum())\n","print(adata.X[90].tolist())"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StKs7aJEQFjy","executionInfo":{"status":"ok","timestamp":1756434358950,"user_tz":240,"elapsed":8,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"bd089d4c-4908-4baf-bc85-5e6117de5810"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 13, 0, 59, 57, 14, 88, 31, 0, 55, 56, 0, 0, 0, 0, 0, 0, 0, 0, 78, 0, 0, 0, 0, 86, 23, 38, 0, 0, 7, 10, 34, 96, 36, 0, 97, 33, 0, 79, 0, 83, 73, 0, 0, 0, 98, 71, 89, 79, 65, 0, 0, 0, 0, 0, 0, 0, 9, 0, 81, 4, 0, 0, 15, 24, 0, 0, 0, 0, 64, 0, 0, 41, 0, 0, 0, 63, 0, 61, 0, 46, 51, 0, 47, 0, 11, 50, 0, 80, 0, 50, 12, 0, 84, 70, 0, 75, 0, 0, 44, 0, 69, 0, 0, 43, 0, 26, 0, 0, 0, 72, 59, 0, 0, 0, 0, 0, 0, 0, 0, 1, 6, 2, 0, 0, 93, 95, 0, 0, 60, 29, 0, 0, 40, 0, 91, 0, 0, 0, 89, 0, 58, 0, 82, 0, 0, 0, 19, 0, 0, 0, 0, 40, 1, 0, 0, 49, 0, 5, 68, 0, 0, 0, 53, 27, 0, 54, 66, 0, 0, 32, 0, 0, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 48, 0, 0, 0, 0, 0, 0, 0, 74, 0, 0, 0, 0, 28, 21, 0, 90, 0, 0, 0, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 0, 0, 0, 45, 87, 0, 30, 16, 0, 99, 0, 0, 0, 77, 0, 85, 94, 0, 92, 0, 0, 0, 0, 52, 0, 0, 0, 22, 37, 0, 0, 20, 0, 39, 0, 0, 0, 20, 0, 0, 17, 0, 0, 76, 25, 0, 0, 0, 18, 67, 8, 0, 69, 0, 0, 3, 0, 42, 0, 0]\n","number of distinct values: 100\n","Value: 0, Count: 202\n","Value: 1, Count: 2\n","Value: 2, Count: 1\n","Value: 3, Count: 1\n","Value: 4, Count: 1\n","Value: 5, Count: 1\n","Value: 6, Count: 1\n","Value: 7, Count: 1\n","Value: 8, Count: 1\n","Value: 9, Count: 1\n","Value: 10, Count: 2\n","Value: 11, Count: 1\n","Value: 12, Count: 1\n","Value: 13, Count: 1\n","Value: 14, Count: 1\n","Value: 15, Count: 1\n","Value: 16, Count: 1\n","Value: 17, Count: 1\n","Value: 18, Count: 1\n","Value: 19, Count: 1\n","Value: 20, Count: 2\n","Value: 21, Count: 1\n","Value: 22, Count: 1\n","Value: 23, Count: 1\n","Value: 24, Count: 1\n","Value: 25, Count: 1\n","Value: 26, Count: 1\n","Value: 27, Count: 1\n","Value: 28, Count: 1\n","Value: 29, Count: 1\n","Value: 30, Count: 2\n","Value: 31, Count: 1\n","Value: 32, Count: 1\n","Value: 33, Count: 1\n","Value: 34, Count: 1\n","Value: 35, Count: 1\n","Value: 36, Count: 1\n","Value: 37, Count: 1\n","Value: 38, Count: 1\n","Value: 39, Count: 1\n","Value: 40, Count: 2\n","Value: 41, Count: 1\n","Value: 42, Count: 1\n","Value: 43, Count: 1\n","Value: 44, Count: 1\n","Value: 45, Count: 1\n","Value: 46, Count: 1\n","Value: 47, Count: 1\n","Value: 48, Count: 1\n","Value: 49, Count: 1\n","Value: 50, Count: 2\n","Value: 51, Count: 1\n","Value: 52, Count: 1\n","Value: 53, Count: 1\n","Value: 54, Count: 1\n","Value: 55, Count: 1\n","Value: 56, Count: 1\n","Value: 57, Count: 1\n","Value: 58, Count: 1\n","Value: 59, Count: 2\n","Value: 60, Count: 1\n","Value: 61, Count: 1\n","Value: 62, Count: 1\n","Value: 63, Count: 1\n","Value: 64, Count: 1\n","Value: 65, Count: 1\n","Value: 66, Count: 1\n","Value: 67, Count: 1\n","Value: 68, Count: 1\n","Value: 69, Count: 2\n","Value: 70, Count: 1\n","Value: 71, Count: 1\n","Value: 72, Count: 1\n","Value: 73, Count: 1\n","Value: 74, Count: 1\n","Value: 75, Count: 1\n","Value: 76, Count: 1\n","Value: 77, Count: 1\n","Value: 78, Count: 1\n","Value: 79, Count: 2\n","Value: 80, Count: 1\n","Value: 81, Count: 1\n","Value: 82, Count: 1\n","Value: 83, Count: 1\n","Value: 84, Count: 1\n","Value: 85, Count: 1\n","Value: 86, Count: 1\n","Value: 87, Count: 1\n","Value: 88, Count: 1\n","Value: 89, Count: 2\n","Value: 90, Count: 1\n","Value: 91, Count: 1\n","Value: 92, Count: 1\n","Value: 93, Count: 1\n","Value: 94, Count: 1\n","Value: 95, Count: 1\n","Value: 96, Count: 1\n","Value: 97, Count: 1\n","Value: 98, Count: 1\n","Value: 99, Count: 1\n"]}],"source":["my_list = adata.layers[\"X_binned\"][90].tolist()\n","print(my_list)\n","distinct_values = sorted(set(my_list))  # Get unique values using set\n","print(f\"number of distinct values: {len(distinct_values)}\")\n","for value in distinct_values:\n","    count = my_list.count(value)\n","    print(f\"Value: {value}, Count: {count}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nC4WE4txn06","executionInfo":{"status":"ok","timestamp":1756434358983,"user_tz":240,"elapsed":31,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"9507d5dc-3296-46f1-dbc0-43d0a9b070cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.00000000e+00, 2.50000000e-04, 4.29591837e-04, 7.47142857e-04,\n","       1.00061224e-03, 1.13122449e-03, 1.28122449e-03, 1.56040816e-03,\n","       1.85714286e-03, 1.96897959e-03, 2.72387755e-03, 3.23469388e-03,\n","       3.51142857e-03, 4.17183673e-03, 5.19959184e-03, 5.45428571e-03,\n","       5.98408163e-03, 6.99081633e-03, 7.71448980e-03, 7.82673469e-03,\n","       8.02714286e-03, 8.38448980e-03, 9.54285714e-03, 1.04306122e-02,\n","       1.21000000e-02, 1.47608163e-02, 1.56755102e-02, 1.60587755e-02,\n","       1.80269388e-02, 2.03142857e-02, 2.09548980e-02, 2.14208163e-02,\n","       2.59816327e-02, 2.90112245e-02, 2.96210204e-02, 3.04428571e-02,\n","       3.22800000e-02, 3.39538776e-02, 3.61844898e-02, 3.97048980e-02,\n","       4.05510204e-02, 4.29363265e-02, 4.36710204e-02, 4.84971429e-02,\n","       6.47561224e-02, 7.51532653e-02, 9.03136735e-02, 1.00197347e-01,\n","       1.21122653e-01, 1.37641429e-01, 1.46050000e-01, 1.53445918e-01,\n","       1.79139388e-01, 1.88482245e-01, 1.92784694e-01, 1.96779388e-01,\n","       2.10694490e-01, 2.21964286e-01, 2.27770816e-01, 2.31058571e-01,\n","       2.52323265e-01, 2.91587755e-01, 3.03780204e-01, 3.11803469e-01,\n","       3.40984286e-01, 3.66912449e-01, 3.75258163e-01, 3.81267959e-01,\n","       3.90455510e-01, 4.04377551e-01, 4.26930408e-01, 4.50232857e-01,\n","       4.88864286e-01, 5.10727755e-01, 5.32071429e-01, 5.94138367e-01,\n","       6.44899184e-01, 6.53971020e-01, 6.80960000e-01, 6.85697755e-01,\n","       7.67327551e-01, 8.14559796e-01, 1.01791388e+00, 1.15275592e+00,\n","       1.21812939e+00, 1.36377714e+00, 1.73883469e+00, 1.92293429e+00,\n","       2.00520163e+00, 2.20775918e+00, 2.54685776e+00, 2.75551449e+00,\n","       3.17166714e+00, 3.40516592e+00, 3.65374469e+00, 3.97875837e+00,\n","       4.17547592e+00, 5.31001286e+00, 7.15737816e+00, 1.60571900e+01])"]},"metadata":{},"execution_count":30}],"source":["adata.obsm[\"bin_edges\"][90]"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7tRRPDAQMgz","executionInfo":{"status":"ok","timestamp":1756434359038,"user_tz":240,"elapsed":52,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"8670d6b0-b534-45e0-98ea-9f68b932d288"},"outputs":[{"output_type":"stream","name":"stdout","text":["AnnData object with n_obs × n_vars = 4347 × 311\n","    var: 'organism_name'\n","    obsm: 'bin_edges'\n","    layers: 'X_binned'\n","(4347, 311)\n"]}],"source":["print(adata)\n","print(adata.layers[\"X_binned\"].shape)"]},{"cell_type":"markdown","metadata":{"id":"8hdRhSmnliVt"},"source":["# Create LLM Training Set/Input"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Nq0qUnMhlh7G","executionInfo":{"status":"ok","timestamp":1756434359044,"user_tz":240,"elapsed":3,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["input_layer_key = \"X_binned\"\n","all_counts = (\n","    adata.layers[input_layer_key].A # get the dense (non-memory efficient with zeros included) matrix if the normal matrix is sparse\n","    if issparse(adata.layers[input_layer_key])\n","    else adata.layers[input_layer_key]\n",")\n","organisms = adata.var[\"organism_name\"].tolist()"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93KBNzGEQRxe","executionInfo":{"status":"ok","timestamp":1756434359099,"user_tz":240,"elapsed":51,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"01aecb94-c688-4af2-d32b-bc9fef3cfab5"},"outputs":[{"output_type":"stream","name":"stdout","text":["311\n"]}],"source":["# print(adata.X[143:160])\n","print(len(organisms))"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"R2shUYpqm-PK","executionInfo":{"status":"ok","timestamp":1756434359106,"user_tz":240,"elapsed":3,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["# train_data: The binned expression data for the training data (90% of all_counts).\n","# valid_data: The binned expression data for the validation data (10% of all_counts).\n","(\n","    train_data,\n","    valid_data,\n",") = train_test_split(\n","    all_counts, test_size=0.1, shuffle=True\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KwGT1GUgfMKR","executionInfo":{"status":"ok","timestamp":1756434359180,"user_tz":240,"elapsed":71,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"58b564f3-cace-446e-ed8b-f45bd3fd1186"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 21, 0, 76, 73, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 0, 0, 0, 0, 40, 80, 0, 0, 0, 0, 0, 0, 0, 0, 71, 0, 0, 0, 0, 82, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 67, 0, 0, 0, 0, 0, 0, 0, 94, 0, 0, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 0, 0, 0, 0, 38, 0, 0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 65, 0, 0, 0, 0, 0, 0, 88, 0, 0, 63, 32, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99, 44, 51, 61, 90, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 57, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34, 28, 9, 0, 30, 59, 0, 17, 0, 0, 0, 0, 0, 0, 0, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 92, 0, 0, 0, 78, 0, 86, 96, 0, 84, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 0, 0, 69, 0, 0, 55, 0, 0, 0, 0, 0, 0, 0, 0, 23, 0, 19, 0, 0]\n"]}],"source":["print(train_data[90].tolist())"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivgOd5WxQYzD","executionInfo":{"status":"ok","timestamp":1756434359191,"user_tz":240,"elapsed":9,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"eb6d1887-abc7-490f-b80f-4c4d28e33070"},"outputs":[{"output_type":"stream","name":"stdout","text":["(3912, 311)\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 9 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","(435, 311)\n"]}],"source":["print(train_data.shape) # (3912, 903)\n","print(train_data)\n","print(valid_data.shape)"]},{"cell_type":"markdown","metadata":{"id":"yky7QTq2j-CT"},"source":["# Tokenization"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"tYvl4UhziY81","executionInfo":{"status":"ok","timestamp":1756434359243,"user_tz":240,"elapsed":50,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["organism_ids = np.array(vocab(organisms), dtype=int) # vocab(organisms) converts the list of organisms names into a list of integer indices by looking them up in the vocabulary. If any gene in genes is not found in the vocab, it will return the index of the default token (\"<pad>\", however this shouldn't happen as we should have filtered adata to just the genes in vocab). The list of gene indices returned by vocab(genes) is put into a numpy array"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_0zKgdej_zU","executionInfo":{"status":"ok","timestamp":1756434359398,"user_tz":240,"elapsed":151,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"0171d57b-4d21-43cf-ec22-b3f1314c662c"},"outputs":[{"output_type":"stream","name":"stdout","text":["microbiomeGPT - INFO - train set number of samples: 3912, \n","\t feature length: 171\n","microbiomeGPT - INFO - valid set number of samples: 435, \n","\t feature length: 181\n"]}],"source":["def tokenize_batch(\n","    data: np.ndarray,\n","    gene_ids: np.ndarray,\n","    return_pt: bool = True,\n","    append_cls: bool = True,\n","    include_zero_gene: bool = False,\n","    cls_id: int = \"<cls>\",\n","    mod_type: np.ndarray = None,\n","    cls_id_mod_type: int = None,\n",") -> List[Tuple[Union[torch.Tensor, np.ndarray]]]:\n","    \"\"\"\n","    Tokenize a batch of data. Returns a list of tuple (gene_id, count).\n","\n","    Args:\n","        data (array-like): A batch of data, with shape (batch_size, n_features).\n","            n_features equals the number of all genes.\n","        gene_ids (array-like): A batch of gene ids, with shape (n_features,).\n","        return_pt (bool): Whether to return torch tensors of gene_ids and counts,\n","            default to True.\n","\n","    Returns:\n","        list: A list of tuple (gene_id, count) of non zero gene expressions.\n","    \"\"\"\n","    if data.shape[1] != len(gene_ids):\n","        raise ValueError(\n","            f\"Number of features in data ({data.shape[1]}) does not match \"\n","            f\"number of gene_ids ({len(gene_ids)}).\"\n","        )\n","    if mod_type is not None and data.shape[1] != len(mod_type):\n","        raise ValueError(\n","            f\"Number of features in data ({data.shape[1]}) does not match \"\n","            f\"number of mod_type ({len(mod_type)}).\"\n","        )\n","\n","    tokenized_data = []\n","    for i in range(len(data)):\n","        row = data[i]\n","        mod_types = None\n","        if include_zero_gene:\n","            values = row # normalized expression counts\n","            genes = gene_ids # gene ids\n","            if mod_type is not None:\n","                mod_types = mod_type\n","        else:\n","            idx = np.nonzero(row)[0]\n","            values = row[idx]\n","            genes = gene_ids[idx]\n","            if mod_type is not None:\n","                mod_types = mod_type[idx]\n","        if append_cls:\n","            genes = np.insert(genes, 0, cls_id)\n","            values = np.insert(values, 0, 0) # cls token appended at the beginning and gets a value of 0 for its expression value\n","            if mod_type is not None:\n","                mod_types = np.insert(mod_types, 0, cls_id_mod_type)\n","        if return_pt: # convert to pytorch tensor\n","            genes = torch.from_numpy(genes).long()\n","            values = torch.from_numpy(values).float()\n","            if mod_type is not None:\n","                mod_types = torch.from_numpy(mod_types).long()\n","        tokenized_data.append((genes, values, mod_types))\n","    return tokenized_data\n","\n","def pad_batch(\n","    batch: List[Tuple],\n","    max_len: int,\n","    vocab: OrganismVocab,\n","    pad_token: str = \"<pad>\",\n","    pad_value: int = 0,\n","    cls_appended: bool = True,\n","    vocab_mod: OrganismVocab = None,\n",") -> Dict[str, torch.Tensor]:\n","    \"\"\"\n","    Pad a batch of data. Returns a list of Dict[gene_id, count].\n","\n","    Args:\n","        batch (list): A list of tuple (gene_id, count).\n","        max_len (int): The maximum length of the batch.\n","        vocab (Vocab): The vocabulary containing the pad token.\n","        pad_token (str): The token to pad with.\n","\n","    Returns:\n","        Dict[str, torch.Tensor]: A dictionary of gene_id and count.\n","    \"\"\"\n","    max_ori_len = max(len(batch[i][0]) for i in range(len(batch)))\n","    # both max_ori_len and max_len are 1201 here\n","    max_len = min(max_ori_len, max_len)\n","\n","    pad_id = vocab[pad_token] # id=36571\n","    if vocab_mod is not None:\n","        mod_pad_id = vocab_mod[pad_token]\n","    gene_ids_list = []\n","    values_list = []\n","    mod_types_list = []\n","\n","    for i in range(len(batch)):\n","        gene_ids, values, mod_types = batch[i] # gene_ids and values have len=1201 for all i, so no padding needs to be done\n","\n","        if len(gene_ids) > max_len:\n","            # sample max_len genes\n","            if not cls_appended:\n","                idx = np.random.choice(len(gene_ids), max_len, replace=False) # from the indices of gene_ids, choose 1201 random indices\n","            else:\n","                idx = np.random.choice(len(gene_ids) - 1, max_len - 1, replace=False) # from indices 0 - len(gene_ids) - 1, choose 1200 random indices\n","                idx = idx + 1 # add 1 to all chosen indices so chosen indices range from 1-->len(gene_ids), so we don't remove the <cls> token\n","                idx = np.insert(idx, 0, 0)\n","            gene_ids = gene_ids[idx]\n","            values = values[idx]\n","            if mod_types is not None:\n","                mod_types = mod_types[idx]\n","        if len(gene_ids) < max_len: # pad with <pad> tokens\n","            gene_ids = torch.cat(\n","                [\n","                    gene_ids,\n","                    torch.full(\n","                        (max_len - len(gene_ids),), pad_id, dtype=gene_ids.dtype\n","                    ),\n","                ]\n","            )\n","            values = torch.cat(\n","                [\n","                    values,\n","                    torch.full((max_len - len(values),), pad_value, dtype=values.dtype), # -2 is added as the correspond value for a pad token\n","                ]\n","            )\n","            if mod_types is not None:\n","                mod_types = torch.cat(\n","                    [\n","                        mod_types,\n","                        torch.full(\n","                            (max_len - len(mod_types),),\n","                            mod_pad_id,\n","                            dtype=mod_types.dtype,\n","                        ),\n","                    ]\n","                )\n","\n","        gene_ids_list.append(gene_ids)\n","        values_list.append(values)\n","        if mod_types is not None:\n","            mod_types_list.append(mod_types)\n","\n","    batch_padded = {\n","        \"genes\": torch.stack(gene_ids_list, dim=0),\n","        \"values\": torch.stack(values_list, dim=0),\n","    }\n","    if mod_types is not None:\n","        batch_padded[\"mod_types\"] = torch.stack(mod_types_list, dim=0)\n","    return batch_padded\n","\n","def tokenize_and_pad_batch(\n","    data: np.ndarray,\n","    gene_ids: np.ndarray,\n","    max_len: int,\n","    vocab: OrganismVocab,\n","    pad_token: str,\n","    pad_value: int,\n","    append_cls: bool = True,\n","    include_zero_gene: bool = False,\n","    cls_token: str = \"<cls>\",\n","    return_pt: bool = True,\n","    mod_type: np.ndarray = None,\n","    vocab_mod: OrganismVocab = None,\n",") -> Dict[str, torch.Tensor]:\n","    \"\"\"\n","    Tokenize and pad a batch of data. Returns a list of tuple (gene_id, count).\n","    \"\"\"\n","    cls_id = vocab[cls_token] # = 36572\n","    if mod_type is not None: # is None\n","        cls_id_mod_type = vocab_mod[cls_token]\n","    # tokenized_data set to list of ((gene ids, corresponding normalized expression values, mod_types=None),...)\n","    tokenized_data = tokenize_batch(\n","        data,\n","        gene_ids,\n","        return_pt=return_pt,\n","        append_cls=append_cls,\n","        include_zero_gene=include_zero_gene,\n","        cls_id=cls_id,\n","        mod_type=mod_type,\n","        cls_id_mod_type=cls_id_mod_type if mod_type is not None else None,\n","    )\n","\n","    batch_padded = pad_batch(\n","        tokenized_data,\n","        max_len,\n","        vocab,\n","        pad_token,\n","        pad_value,\n","        cls_appended=append_cls,\n","        vocab_mod=vocab_mod,\n","    )\n","    return batch_padded\n","\n","# <cls> token with its corresponding 0 expression value are appended to the beginning of each cell's row here\n","tokenized_train = tokenize_and_pad_batch(\n","    train_data,\n","    organism_ids,\n","    max_len=config.max_seq_len, # 10000\n","    vocab=vocab,\n","    pad_token=pad_token, # <pad>\n","    pad_value=pad_value, # = -2 is added as the correspond value for a pad token\n","    append_cls=config.append_cls,  # append <cls> token at the beginning\n","    include_zero_gene=config.include_zero_gene, # keep organisms with 0 counts\n",")\n","tokenized_valid = tokenize_and_pad_batch(\n","    valid_data,\n","    organism_ids,\n","    max_len=config.max_seq_len,\n","    vocab=vocab,\n","    pad_token=pad_token,\n","    pad_value=pad_value,\n","    append_cls=config.append_cls,\n","    include_zero_gene=config.include_zero_gene,\n",")\n","logger.info(\n","    f\"train set number of samples: {tokenized_train['genes'].shape[0]}, \"\n","    f\"\\n\\t feature length: {tokenized_train['genes'].shape[1]}\"\n",")\n","logger.info(\n","    f\"valid set number of samples: {tokenized_valid['genes'].shape[0]}, \"\n","    f\"\\n\\t feature length: {tokenized_valid['genes'].shape[1]}\"\n",")"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iBFElUzT7ulG","executionInfo":{"status":"ok","timestamp":1756434359451,"user_tz":240,"elapsed":51,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"69d1f681-0f0c-4944-fc07-a4dad76e056d"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3912, 171])\n","torch.Size([3912, 171])\n","[312, 10, 11, 13, 14, 25, 30, 31, 40, 45, 57, 65, 71, 84, 93, 97, 108, 115, 118, 119, 128, 131, 142, 143, 144, 145, 146, 148, 159, 163, 173, 174, 175, 177, 178, 180, 188, 230, 259, 260, 264, 266, 267, 269, 291, 294, 297, 306, 308, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311, 311]\n","171\n","[0.0, 11.0, 21.0, 76.0, 73.0, 46.0, 40.0, 80.0, 71.0, 82.0, 67.0, 94.0, 36.0, 42.0, 38.0, 15.0, 65.0, 88.0, 63.0, 32.0, 1.0, 13.0, 99.0, 44.0, 51.0, 61.0, 90.0, 7.0, 57.0, 3.0, 34.0, 28.0, 9.0, 30.0, 59.0, 17.0, 53.0, 26.0, 5.0, 92.0, 78.0, 86.0, 96.0, 84.0, 48.0, 69.0, 55.0, 23.0, 19.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n","[0.0, 14.0, 1.0, 7.0, 88.0, 94.0, 44.0, 40.0, 31.0, 57.0, 11.0, 9.0, 77.0, 81.0, 90.0, 33.0, 79.0, 70.0, 75.0, 68.0, 20.0, 85.0, 51.0, 16.0, 29.0, 96.0, 99.0, 42.0, 27.0, 48.0, 61.0, 24.0, 18.0, 72.0, 35.0, 92.0, 66.0, 22.0, 38.0, 64.0, 55.0, 53.0, 83.0, 46.0, 59.0, 3.0, 5.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n","[0.0, 29.0, 96.0, 66.0, 73.0, 61.0, 92.0, 56.0, 68.0, 14.0, 77.0, 90.0, 40.0, 72.0, 18.0, 23.0, 46.0, 74.0, 50.0, 87.0, 70.0, 69.0, 28.0, 85.0, 51.0, 84.0, 45.0, 48.0, 31.0, 6.0, 54.0, 13.0, 88.0, 26.0, 53.0, 89.0, 82.0, 94.0, 49.0, 66.0, 33.0, 64.0, 55.0, 16.0, 37.0, 91.0, 79.0, 83.0, 52.0, 25.0, 93.0, 81.0, 97.0, 24.0, 82.0, 1.0, 36.0, 76.0, 41.0, 32.0, 17.0, 1.0, 47.0, 62.0, 30.0, 59.0, 35.0, 17.0, 95.0, 50.0, 34.0, 8.0, 86.0, 11.0, 99.0, 5.0, 67.0, 80.0, 71.0, 3.0, 2.0, 98.0, 38.0, 60.0, 58.0, 65.0, 63.0, 27.0, 15.0, 57.0, 7.0, 33.0, 12.0, 22.0, 21.0, 44.0, 78.0, 9.0, 39.0, 10.0, 42.0, 4.0, 75.0, 20.0, 19.0, 43.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n","[0.0, 23.0, 38.0, 55.0, 42.0, 22.0, 68.0, 51.0, 10.0, 71.0, 4.0, 40.0, 19.0, 6.0, 1.0, 32.0, 87.0, 65.0, 36.0, 81.0, 69.0, 48.0, 80.0, 61.0, 64.0, 93.0, 67.0, 84.0, 92.0, 31.0, 85.0, 15.0, 72.0, 96.0, 3.0, 73.0, 91.0, 47.0, 79.0, 8.0, 60.0, 57.0, 52.0, 95.0, 12.0, 14.0, 63.0, 75.0, 26.0, 28.0, 39.0, 18.0, 97.0, 30.0, 76.0, 89.0, 99.0, 88.0, 46.0, 11.0, 27.0, 24.0, 53.0, 59.0, 16.0, 44.0, 43.0, 50.0, 77.0, 83.0, 35.0, 34.0, 20.0, 56.0, 7.0, 2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n","[0.0, 5.0, 35.0, 53.0, 83.0, 20.0, 58.0, 15.0, 34.0, 60.0, 91.0, 85.0, 94.0, 95.0, 38.0, 78.0, 41.0, 86.0, 18.0, 90.0, 89.0, 93.0, 72.0, 14.0, 65.0, 62.0, 40.0, 29.0, 30.0, 25.0, 22.0, 47.0, 43.0, 57.0, 45.0, 27.0, 32.0, 5.0, 19.0, 48.0, 73.0, 49.0, 79.0, 13.0, 63.0, 74.0, 70.0, 59.0, 44.0, 33.0, 8.0, 46.0, 96.0, 39.0, 98.0, 76.0, 3.0, 56.0, 97.0, 75.0, 99.0, 11.0, 69.0, 7.0, 28.0, 69.0, 50.0, 66.0, 79.0, 61.0, 40.0, 10.0, 64.0, 24.0, 26.0, 20.0, 50.0, 80.0, 84.0, 16.0, 68.0, 6.0, 77.0, 31.0, 1.0, 10.0, 42.0, 52.0, 67.0, 87.0, 92.0, 12.0, 10.0, 89.0, 81.0, 2.0, 71.0, 82.0, 88.0, 55.0, 30.0, 21.0, 17.0, 54.0, 1.0, 59.0, 36.0, 37.0, 51.0, 23.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n","171\n","torch.Size([435, 181])\n","torch.Size([435, 181])\n"]}],"source":["print(tokenized_train[\"genes\"].shape)\n","print(tokenized_train[\"values\"].shape)\n","print(tokenized_train[\"genes\"][90].tolist())\n","print(len(tokenized_train[\"genes\"][90].tolist()))\n","print(tokenized_train[\"values\"][90].tolist())\n","print(tokenized_train[\"values\"][91].tolist())\n","print(tokenized_train[\"values\"][92].tolist())\n","print(tokenized_train[\"values\"][93].tolist())\n","print(tokenized_train[\"values\"][94].tolist())\n","print(len(tokenized_train[\"values\"][90].tolist()))\n","print(tokenized_valid[\"genes\"].shape)\n","print(tokenized_valid[\"values\"].shape)"]},{"cell_type":"markdown","metadata":{"id":"oaRl9syv5PSz"},"source":["# Setup scGPT"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fwizd3GO5Lqy","executionInfo":{"status":"ok","timestamp":1756434359462,"user_tz":240,"elapsed":9,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"587ef40e-be60-49ae-8f21-bd7fc785e26a"},"outputs":[{"output_type":"stream","name":"stdout","text":["314\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","ntokens = len(vocab)  # size of vocabulary, 906\n","print(ntokens)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"3CpE918nV5Ik","executionInfo":{"status":"ok","timestamp":1756434359520,"user_tz":240,"elapsed":56,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"outputs":[],"source":["def masked_mse_loss(\n","    input: torch.Tensor, target: torch.Tensor, mask: torch.Tensor\n",") -> torch.Tensor:\n","    \"\"\"\n","    Compute the masked MSE loss between input and target.\n","    \"\"\"\n","    mask = mask.float()\n","\n","    mask_sum = mask.sum()\n","\n","    if mask_sum == 0: # if no values are masked, then return a loss of 0\n","        return torch.tensor(0.0)\n","\n","    loss = F.mse_loss(input * mask, target * mask, reduction=\"sum\") # input * mask and target * mask effectively zero out the elements in both input and target where the mask is 0. This means only the elements where the mask is 1 contribute to the loss calculation.\n","    return loss / mask_sum # Normalize by the Number of masked Elements\n","\n","def masked_absolute_error(\n","    input: torch.Tensor, target: torch.Tensor, mask: torch.LongTensor\n",") -> torch.Tensor:\n","    \"\"\"\n","    Compute the absolute error between the masked expression values (predicted) and the actual expression values (target)\n","    \"\"\"\n","    mask = mask.float()\n","\n","    mask_sum = mask.sum()\n","\n","    if mask_sum == 0: # if no values are masked, then return a loss of 0\n","        return torch.tensor(0.0)\n","\n","    loss = torch.abs(input * mask - target * mask).sum()\n","    return loss / mask_sum # Normalize by the Number of masked Elements\n","\n","def define_wandb_metrics():\n","    wandb.define_metric(\"valid/mse\", summary=\"min\", step_metric=\"epoch\")\n","    wandb.define_metric(\"valid/mae\", summary=\"min\", step_metric=\"epoch\")\n","\n","best_val_loss = float(\"inf\")\n","best_model = None\n","define_wandb_metrics()\n","\n","def random_mask_value(\n","    values: Union[torch.Tensor, np.ndarray],\n","    mask_ratio: float = 0.15,\n","    mask_value: int = -1,\n","    pad_value: int = 0,\n",") -> torch.Tensor:\n","    \"\"\"\n","    Randomly mask a batch of data.\n","\n","    Args:\n","        values (array-like):\n","            A batch of tokenized data, with shape (batch_size, n_features).\n","        mask_ratio (float): The ratio of genes to mask, default to 0.15.\n","        mask_value (int): The value to mask with, default to -1.\n","        pad_value (int): The value of padding in the values, will be kept unchanged.\n","\n","    Returns:\n","        torch.Tensor: A tensor of masked data.\n","    \"\"\"\n","    if isinstance(values, torch.Tensor):\n","        # it is crutial to clone the tensor, otherwise it changes the original tensor\n","        values = values.clone().detach().numpy()\n","    else:\n","        values = values.copy()\n","\n","    for i in range(len(values)): # iterate over cells\n","        row = values[i]\n","        non_padding_idx = np.nonzero(row - pad_value)[0] # returns the indices where the row value is different from the padding value, [0] removes the nesting [[indices]]\n","        n_mask = int(len(non_padding_idx) * mask_ratio) # compute number of values to mask\n","        mask_idx = np.random.choice(non_padding_idx, n_mask, replace=False) # randomly selects n_mask indices from the non-padding indices\n","        row[mask_idx] = mask_value # mask the values\n","    return torch.from_numpy(values).float()\n","\n","def prepare_data() -> Tuple[Dict[str, torch.Tensor]]:\n","    # mask 40% of the values in each cell independently with the -1 value, so can choose different genes to mask for each cell\n","    # choose only genes which are not the padding index to mask\n","    masked_values_train = random_mask_value(\n","        tokenized_train[\"values\"],\n","        mask_ratio=config.mask_ratio, # 0.4\n","        mask_value=mask_value, # -1\n","        pad_value=pad_value, # -2\n","    )\n","    masked_values_valid = random_mask_value(\n","        tokenized_valid[\"values\"],\n","        mask_ratio=config.mask_ratio,\n","        mask_value=mask_value,\n","        pad_value=pad_value,\n","    )\n","    print(\n","        f\"random masking at epoch {epoch:3d}, ratio of masked values in train: \",\n","        f\"{(masked_values_train == mask_value).sum() / (masked_values_train - pad_value).count_nonzero():.4f}\",\n","    )\n","    input_gene_ids_train, input_gene_ids_valid = (\n","        tokenized_train[\"genes\"],\n","        tokenized_valid[\"genes\"],\n","    )\n","    input_values_train, input_values_valid = masked_values_train, masked_values_valid\n","    target_values_train, target_values_valid = (\n","        tokenized_train[\"values\"],\n","        tokenized_valid[\"values\"],\n","    )\n","\n","    train_data_pt = {\n","        \"gene_ids\": input_gene_ids_train,\n","        \"values\": input_values_train, # with masks\n","        \"target_values\": target_values_train, # unmasked\n","    }\n","    valid_data_pt = {\n","        \"gene_ids\": input_gene_ids_valid,\n","        \"values\": input_values_valid, # with masks\n","        \"target_values\": target_values_valid, # unmasked\n","    }\n","\n","    return train_data_pt, valid_data_pt\n","\n","class SeqDataset(Dataset):\n","    def __init__(self, data: Dict[str, torch.Tensor]):\n","        self.data = data\n","\n","    def __len__(self):\n","        return self.data[\"gene_ids\"].shape[0]\n","\n","    # get the item at position idx across the gene_ids, values, and target_values tensors\n","    # position idx is just some gene position, determined by the dataset\n","    def __getitem__(self, idx):\n","        return {k: v[idx] for k, v in self.data.items()}\n","\n","def prepare_dataloader(\n","    data_pt: Dict[str, torch.Tensor],\n","    batch_size: int,\n","    shuffle: bool = False,\n","    drop_last: bool = False,\n","    num_workers: int = 0,\n",") -> DataLoader:\n","    dataset = SeqDataset(data_pt)\n","\n","    data_loader = DataLoader(\n","        dataset=dataset,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        drop_last=drop_last,\n","        num_workers=num_workers,\n","        pin_memory=True,\n","    )\n","    return data_loader"]},{"cell_type":"markdown","metadata":{"id":"XfadmA0jRepQ"},"source":["# Run scGPT"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvxFzQhp55b0","executionInfo":{"status":"ok","timestamp":1756434364172,"user_tz":240,"elapsed":4649,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"0c6b18be-1ba5-4264-8a7e-003b101ae006"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using batchnorm on input embeddings\n"]}],"source":["class GeneEncoder(nn.Module): # Essentially just an embedding layer for the gene names/ids\n","    def __init__(\n","        self,\n","        num_embeddings: int,\n","        embedding_dim: int,\n","        padding_idx: Optional[int] = None,\n","    ):\n","        super().__init__()\n","        self.embedding = nn.Embedding(\n","            num_embeddings, embedding_dim, padding_idx=padding_idx\n","        )\n","        self.enc_norm = nn.LayerNorm(embedding_dim) # normalize each embedding to mean 0 and variance 1\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        x = self.embedding(x)  # (batch, seq_len, embsize)\n","        x = self.enc_norm(x)\n","        return x\n","\n","class ContinuousValueEncoder(nn.Module): # int --> linear --> Relu --> linear --> LayerNorm --> Dropout --> d_model size vector\n","    \"\"\"\n","    Encode real number values to a vector using neural nets projection.\n","    \"\"\"\n","\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_value: int = 512):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.linear1 = nn.Linear(1, d_model)\n","        self.activation = nn.ReLU()\n","        self.linear2 = nn.Linear(d_model, d_model)\n","        self.norm = nn.LayerNorm(d_model)\n","        self.max_value = max_value\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Args:\n","            x: Tensor, shape [batch_size, seq_len]\n","        \"\"\"\n","\n","        x = x.unsqueeze(-1) # adds an extra dimension at the last position with 1 element, B, N --> B, N, 1\n","        # clip x to [-inf, max_value]\n","        x = torch.clamp(x, max=self.max_value)\n","        x = self.activation(self.linear1(x)) # B, N, 1, --> B, N, E\n","        x = self.linear2(x)\n","        x = self.norm(x)\n","        return self.dropout(x)\n","\n","class ExprDecoder(nn.Module): # linear --> Relu --> linear --> Relu --> int\n","    def __init__(\n","        self,\n","        d_model: int,\n","    ):\n","        super().__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(d_model, d_model),\n","            nn.LeakyReLU(),\n","            nn.Linear(d_model, d_model),\n","            nn.LeakyReLU(),\n","            nn.Linear(d_model, 1),\n","        ) #\n","\n","    def forward(self, x: Tensor) -> Dict[str, Tensor]:\n","        \"\"\"x is the output of the transformer, (batch, seq_len, d_model)\"\"\"\n","        # batch, 1201, 1024 --> FC --> batch, 1201, 1 --> batch, 1201\n","        pred_value = self.fc(x).squeeze(-1)  # (batch, seq_len)\n","\n","        return dict(pred=pred_value)\n","\n","class TransformerModel(nn.Module):\n","    def __init__(\n","        self,\n","        ntoken: int, # number of organisms in the vocab\n","        d_model: int, # emb size\n","        nhead: int, # number of self-attention heads per layer\n","        d_hid: int, # size of MLP layers after attention layers\n","        nlayers: int, # number of attention layers\n","        vocab: Any = None,\n","        dropout: float = 0.5,\n","        pad_token: str = \"<pad>\",\n","        pad_value: int = 0,\n","        input_emb_style: str = \"continuous\",\n","        use_batch_norm: bool = True,\n","        n_input_bins: Optional[int] = None,\n","        cell_emb_style: str = \"cls\",\n","    ):\n","        super().__init__()\n","        self.model_type = \"Transformer\"\n","        self.d_model = d_model\n","        self.use_batch_norm = use_batch_norm\n","        self.cell_emb_style = cell_emb_style\n","        self.input_emb_style = input_emb_style\n","        if self.input_emb_style not in [\"continuous\", \"scaling\"]:\n","            raise ValueError(\n","                f\"input_emb_style should be one of continuous, scaling, \"\n","                f\"got {input_emb_style}\"\n","            )\n","        if cell_emb_style not in [\"cls\", \"avg-pool\", \"w-pool\"]:\n","            raise ValueError(f\"Unknown cell_emb_style: {cell_emb_style}\")\n","\n","        # so each of the 36574 genes are given an embedding here, only 1200 of the most highly variable genes are in the training set though and will ever be used\n","        self.encoder = GeneEncoder(ntoken, d_model, padding_idx=vocab[pad_token])\n","\n","        # d_model = 512, dropout=0.2: turns an int into a linear vector\n","        # essentially the expression levels/values also get embeddings\n","        self.value_encoder = ContinuousValueEncoder(d_model, dropout, n_input_bins)\n","\n","        if use_batch_norm:\n","            print(\"Using batchnorm on input embeddings\")\n","            self.bn = nn.BatchNorm1d(d_model, eps=6.1e-5)\n","\n","        # This creates a single layer of the Transformer encoder., d_model=512, nhead=8, d_hid=512, dropout=0.2\n","        # batch_first=True specifies that the input tensors will have their first dimension as the batch size (i.e., input shape is (batch_size, seq_len, d_model)\n","        # can pass a custom mask attribute during its .forward call to set a custom mask during each pass\n","        encoder_layers = TransformerEncoderLayer(\n","            d_model, nhead, d_hid, dropout, batch_first=True\n","        )\n","        # This creates a Transformer encoder by stacking multiple TransformerEncoderLayer instances.\n","        # nlayers = number of transformer layers\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","\n","        # turns a linear vector into an int\n","        self.decoder = ExprDecoder(\n","            d_model, # 512\n","        )\n","\n","        # initialize gene embeddings to random uniform distribution\n","        self.init_weights()\n","\n","    def init_weights(self) -> None:\n","        initrange = 0.1\n","        # TODO: check if this initialization is helpful and shall we apply to all?\n","        self.encoder.embedding.weight.data.uniform_(-initrange, initrange)\n","\n","    def _encode(\n","        self,\n","        src: Tensor,\n","        values: Tensor,\n","        attention_mask: Optional[Tensor],\n","        src_key_padding_mask: Tensor,\n","    ) -> Tensor:\n","\n","        # src is the gene ids, embed them turns 64 cells/batch size x 1201 (<cls> 1200 most highly variable genes across the dataset) --> 64 x 1201 x 512\n","        src = self.encoder(src)  # (batch, seq_len, embsize)\n","        self.cur_gene_token_embs = src\n","\n","        # embed the masked binned expression values, 64 x 1201 --> 64 x 1201 x 512\n","        values = self.value_encoder(values)  # (batch, seq_len, embsize)\n","        if self.input_emb_style == \"scaling\":\n","            values = values.unsqueeze(2)\n","            # print(\"MULTIPLYING the gene ids embeddings and the expression embeddings\")\n","            total_embs = src * values\n","        else: # input_emb_style = \"continuous\"\n","            # print(\"ADDING the gene ids embeddings and the expression embeddings\")\n","            total_embs = src + values\n","\n","        if getattr(self, \"bn\", None) is not None:\n","            # print(\"using simple batchnorm\")\n","            total_embs = self.bn(total_embs.permute(0, 2, 1)).permute(0, 2, 1)\n","\n","        # 64, 1201, 512 --> 64, 1201, 512\n","        # no mask attribute is passed here, ie no lower triangular mask (mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool())\n","        # so the attention on all positions to all other positions, not just the past positions\n","        # print(total_embs.shape)\n","        # print(attention_mask.shape)\n","        # print(src_key_padding_mask.shape)\n","        output = self.transformer_encoder(\n","            total_embs, mask=attention_mask, src_key_padding_mask=src_key_padding_mask\n","        )\n","        return output  # (batch, seq_len, embsize)\n","\n","    def _get_cell_emb_from_layer(\n","        self, layer_output: Tensor, weights: Tensor = None\n","    ) -> Tensor:\n","        \"\"\"\n","        Args:\n","            layer_output(:obj:`Tensor`): shape (batch, seq_len, embsize)\n","            weights(:obj:`Tensor`): shape (batch, seq_len), optional and only used\n","                when :attr:`self.cell_emb_style` is \"w-pool\".\n","\n","        Returns:\n","            :obj:`Tensor`: shape (batch, embsize)\n","        \"\"\"\n","        # cell_emb_style = \"cls\"\n","        if self.cell_emb_style == \"cls\":\n","            # output from transformer layers is batch, 1201, 512, extracts the first item in the 2nd dimension, the cls embedding\n","            cell_emb = layer_output[:, 0, :]  # (batch, embsize)\n","        elif self.cell_emb_style == \"avg-pool\":\n","            cell_emb = torch.mean(layer_output, dim=1)\n","        elif self.cell_emb_style == \"w-pool\":\n","            if weights is None:\n","                raise ValueError(\"weights is required when cell_emb_style is w-pool\")\n","            if weights.dim() != 2:\n","                raise ValueError(\"weights should be 2D\")\n","            cell_emb = torch.sum(layer_output * weights.unsqueeze(2), dim=1)\n","            cell_emb = F.normalize(cell_emb, p=2, dim=1)  # (batch, embsize)\n","\n","        return cell_emb\n","\n","    def forward(\n","        self,\n","        src: Tensor,\n","        values: Tensor,\n","        attention_mask: Tensor,\n","        src_key_padding_mask: Tensor,\n","        MVC: bool = False,\n","    ) -> Mapping[str, Tensor]:\n","        \"\"\"\n","        Args:\n","            src (:obj:`Tensor`): token ids, shape [batch_size, seq_len]\n","            values (:obj:`Tensor`): token values, shape [batch_size, seq_len]\n","            src_key_padding_mask (:obj:`Tensor`): mask for src, shape [batch_size,\n","                seq_len]\n","            MVC (:obj:`bool`): if True, return the masked value prediction for cell\n","                embedding MVC output\n","\n","        Returns:\n","            dict of output Tensors.\n","        \"\"\"\n","        # 64, 1201 --> 64, 1201, 512 as the output of the transformers\n","        transformer_output = self._encode(\n","            src, values, attention_mask , src_key_padding_mask\n","        )\n","\n","        output = {}\n","        # returns dict(pred=pred_value, zero_probs=zero_probs) where pred is the logits with shape batch, 1201 and zero_probs is the logits represented as probabilities with shape batch, 1201\n","        # MAKES GENE EXPRESSION PREDICTIONS FROM LLM OUTPUTS (all 1201 outputs)\n","        mlm_output = self.decoder(\n","            transformer_output # 64, 1201, 512\n","          )\n","        output[\"mlm_output\"] = mlm_output[\"pred\"]  # (batch, seq_len)\n","\n","        cell_emb = self._get_cell_emb_from_layer(transformer_output, values) # extract the first column as the cell embedding, batch, 512\n","        output[\"cell_emb\"] = cell_emb\n","\n","        return output\n","\n","model = TransformerModel(\n","    ntokens,  # 110\n","    config.embsize, # 512\n","    config.nhead, # 8\n","    config.d_hid, # 512 (dimension of hidden layers)\n","    config.nlayers, # 12\n","    vocab=vocab,\n","    input_emb_style=config.input_emb_style,\n","    dropout=config.dropout, # 0.2\n","    pad_token=pad_token, # <pad>\n","    pad_value=pad_value, # -2\n","    use_batch_norm=config.use_batch_norm,\n","    n_input_bins=config.n_bins, # 51\n",")\n","\n","model.to(device)\n","wandb.watch(model)\n","\n","criterion = masked_mse_loss\n","optimizer = torch.optim.Adam(\n","    model.parameters(), lr=config.lr, eps=1e-4 if config.amp else 1e-8\n",")\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=config.schedule_ratio)\n","scaler = torch.amp.GradScaler('cuda', enabled=config.amp)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"fIbYo6p0ncie","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756434715345,"user_tz":240,"elapsed":351166,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"3a074e20-634b-44d6-facc-c8d821f827a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["random masking at epoch   1, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   1 |  25/ 62 batches | lr 0.0001 | ms/batch 227.87 | loss 3181.13 | mse 3181.13 | mae 49.03 |\n","microbiomeGPT - INFO - | epoch   1 |  50/ 62 batches | lr 0.0001 | ms/batch 175.63 | loss 2429.45 | mse 2429.45 | mae 40.92 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   1 | time: 12.67s | valid loss/mse 1499.5875 | mae 31.5612\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 1499.5875\n","random masking at epoch   2, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   2 |  25/ 62 batches | lr 0.0001 | ms/batch 179.45 | loss 1232.84 | mse 1232.84 | mae 29.70 |\n","microbiomeGPT - INFO - | epoch   2 |  50/ 62 batches | lr 0.0001 | ms/batch 177.28 | loss 849.68 | mse 849.68 | mae 25.20 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   2 | time: 11.31s | valid loss/mse 839.6611 | mae 25.1370\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 839.6611\n","random masking at epoch   3, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   3 |  25/ 62 batches | lr 0.0001 | ms/batch 180.96 | loss 727.95 | mse 727.95 | mae 23.40 |\n","microbiomeGPT - INFO - | epoch   3 |  50/ 62 batches | lr 0.0001 | ms/batch 176.54 | loss 561.22 | mse 561.22 | mae 19.48 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   3 | time: 11.37s | valid loss/mse 558.4017 | mae 18.9100\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 558.4017\n","random masking at epoch   4, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   4 |  25/ 62 batches | lr 0.0001 | ms/batch 181.99 | loss 547.19 | mse 547.19 | mae 19.42 |\n","microbiomeGPT - INFO - | epoch   4 |  50/ 62 batches | lr 0.0001 | ms/batch 177.48 | loss 506.84 | mse 506.84 | mae 18.18 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   4 | time: 11.44s | valid loss/mse 506.4461 | mae 17.9912\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 506.4461\n","random masking at epoch   5, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   5 |  25/ 62 batches | lr 0.0001 | ms/batch 182.73 | loss 522.34 | mse 522.34 | mae 18.78 |\n","microbiomeGPT - INFO - | epoch   5 |  50/ 62 batches | lr 0.0001 | ms/batch 176.31 | loss 499.91 | mse 499.91 | mae 18.05 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   5 | time: 11.48s | valid loss/mse 502.8701 | mae 17.5632\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 502.8701\n","random masking at epoch   6, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   6 |  25/ 62 batches | lr 0.0001 | ms/batch 184.11 | loss 499.96 | mse 499.96 | mae 18.19 |\n","microbiomeGPT - INFO - | epoch   6 |  50/ 62 batches | lr 0.0001 | ms/batch 177.38 | loss 488.22 | mse 488.22 | mae 17.65 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   6 | time: 11.57s | valid loss/mse 517.3353 | mae 17.9094\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch   7, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   7 |  25/ 62 batches | lr 0.0001 | ms/batch 184.65 | loss 503.36 | mse 503.36 | mae 18.25 |\n","microbiomeGPT - INFO - | epoch   7 |  50/ 62 batches | lr 0.0001 | ms/batch 177.47 | loss 481.92 | mse 481.92 | mae 17.56 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   7 | time: 11.57s | valid loss/mse 498.4340 | mae 17.4815\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 498.4340\n","random masking at epoch   8, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   8 |  25/ 62 batches | lr 0.0000 | ms/batch 186.29 | loss 497.17 | mse 497.17 | mae 18.15 |\n","microbiomeGPT - INFO - | epoch   8 |  50/ 62 batches | lr 0.0000 | ms/batch 178.13 | loss 480.93 | mse 480.93 | mae 17.52 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   8 | time: 11.57s | valid loss/mse 493.6682 | mae 17.4180\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 493.6682\n","random masking at epoch   9, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch   9 |  25/ 62 batches | lr 0.0000 | ms/batch 190.01 | loss 489.90 | mse 489.90 | mae 17.99 |\n","microbiomeGPT - INFO - | epoch   9 |  50/ 62 batches | lr 0.0000 | ms/batch 179.98 | loss 484.55 | mse 484.55 | mae 17.54 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch   9 | time: 11.73s | valid loss/mse 497.1666 | mae 17.3524\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  10, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  10 |  25/ 62 batches | lr 0.0000 | ms/batch 189.17 | loss 487.46 | mse 487.46 | mae 17.90 |\n","microbiomeGPT - INFO - | epoch  10 |  50/ 62 batches | lr 0.0000 | ms/batch 180.86 | loss 474.44 | mse 474.44 | mae 17.34 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  10 | time: 11.76s | valid loss/mse 482.9780 | mae 17.3297\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 482.9780\n","random masking at epoch  11, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  11 |  25/ 62 batches | lr 0.0000 | ms/batch 190.75 | loss 490.55 | mse 490.55 | mae 17.98 |\n","microbiomeGPT - INFO - | epoch  11 |  50/ 62 batches | lr 0.0000 | ms/batch 179.75 | loss 468.70 | mse 468.70 | mae 17.28 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  11 | time: 11.74s | valid loss/mse 486.5109 | mae 17.2570\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  12, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  12 |  25/ 62 batches | lr 0.0000 | ms/batch 190.11 | loss 489.04 | mse 489.04 | mae 17.90 |\n","microbiomeGPT - INFO - | epoch  12 |  50/ 62 batches | lr 0.0000 | ms/batch 179.28 | loss 471.90 | mse 471.90 | mae 17.35 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  12 | time: 11.72s | valid loss/mse 497.3027 | mae 17.4601\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  13, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  13 |  25/ 62 batches | lr 0.0000 | ms/batch 188.50 | loss 480.85 | mse 480.85 | mae 17.78 |\n","microbiomeGPT - INFO - | epoch  13 |  50/ 62 batches | lr 0.0000 | ms/batch 179.05 | loss 470.78 | mse 470.78 | mae 17.28 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  13 | time: 11.65s | valid loss/mse 483.7260 | mae 17.3539\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  14, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  14 |  25/ 62 batches | lr 0.0000 | ms/batch 187.28 | loss 485.33 | mse 485.33 | mae 17.91 |\n","microbiomeGPT - INFO - | epoch  14 |  50/ 62 batches | lr 0.0000 | ms/batch 180.63 | loss 468.74 | mse 468.74 | mae 17.23 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  14 | time: 11.68s | valid loss/mse 485.4234 | mae 17.3126\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  15, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  15 |  25/ 62 batches | lr 0.0000 | ms/batch 186.37 | loss 483.43 | mse 483.43 | mae 17.81 |\n","microbiomeGPT - INFO - | epoch  15 |  50/ 62 batches | lr 0.0000 | ms/batch 181.10 | loss 467.13 | mse 467.13 | mae 17.21 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  15 | time: 11.69s | valid loss/mse 484.8123 | mae 17.2213\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  16, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  16 |  25/ 62 batches | lr 0.0000 | ms/batch 186.42 | loss 486.56 | mse 486.56 | mae 17.93 |\n","microbiomeGPT - INFO - | epoch  16 |  50/ 62 batches | lr 0.0000 | ms/batch 182.84 | loss 452.29 | mse 452.29 | mae 16.89 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  16 | time: 11.70s | valid loss/mse 481.2435 | mae 17.2329\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 481.2435\n","random masking at epoch  17, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  17 |  25/ 62 batches | lr 0.0000 | ms/batch 194.17 | loss 487.34 | mse 487.34 | mae 17.87 |\n","microbiomeGPT - INFO - | epoch  17 |  50/ 62 batches | lr 0.0000 | ms/batch 181.20 | loss 467.42 | mse 467.42 | mae 17.18 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  17 | time: 11.87s | valid loss/mse 489.4556 | mae 17.4277\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  18, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  18 |  25/ 62 batches | lr 0.0000 | ms/batch 186.19 | loss 473.75 | mse 473.75 | mae 17.64 |\n","microbiomeGPT - INFO - | epoch  18 |  50/ 62 batches | lr 0.0000 | ms/batch 182.26 | loss 457.15 | mse 457.15 | mae 16.97 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  18 | time: 11.68s | valid loss/mse 483.5443 | mae 17.3473\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  19, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  19 |  25/ 62 batches | lr 0.0000 | ms/batch 186.52 | loss 472.46 | mse 472.46 | mae 17.59 |\n","microbiomeGPT - INFO - | epoch  19 |  50/ 62 batches | lr 0.0000 | ms/batch 181.02 | loss 467.92 | mse 467.92 | mae 17.25 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  19 | time: 11.69s | valid loss/mse 468.4302 | mae 17.0559\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 468.4302\n","random masking at epoch  20, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  20 |  25/ 62 batches | lr 0.0000 | ms/batch 186.72 | loss 472.70 | mse 472.70 | mae 17.60 |\n","microbiomeGPT - INFO - | epoch  20 |  50/ 62 batches | lr 0.0000 | ms/batch 180.49 | loss 456.50 | mse 456.50 | mae 16.96 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  20 | time: 11.68s | valid loss/mse 474.0051 | mae 17.2048\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  21, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  21 |  25/ 62 batches | lr 0.0000 | ms/batch 186.78 | loss 473.56 | mse 473.56 | mae 17.53 |\n","microbiomeGPT - INFO - | epoch  21 |  50/ 62 batches | lr 0.0000 | ms/batch 180.22 | loss 460.10 | mse 460.10 | mae 17.05 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  21 | time: 11.70s | valid loss/mse 476.9517 | mae 17.2053\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  22, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  22 |  25/ 62 batches | lr 0.0000 | ms/batch 186.89 | loss 469.26 | mse 469.26 | mae 17.55 |\n","microbiomeGPT - INFO - | epoch  22 |  50/ 62 batches | lr 0.0000 | ms/batch 178.77 | loss 457.57 | mse 457.57 | mae 16.91 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  22 | time: 11.73s | valid loss/mse 475.4594 | mae 17.1186\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  23, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  23 |  25/ 62 batches | lr 0.0000 | ms/batch 186.19 | loss 473.01 | mse 473.01 | mae 17.59 |\n","microbiomeGPT - INFO - | epoch  23 |  50/ 62 batches | lr 0.0000 | ms/batch 180.62 | loss 451.63 | mse 451.63 | mae 16.78 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  23 | time: 11.72s | valid loss/mse 463.3705 | mae 16.9713\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - Best model with score 463.3705\n","random masking at epoch  24, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  24 |  25/ 62 batches | lr 0.0000 | ms/batch 186.78 | loss 475.32 | mse 475.32 | mae 17.60 |\n","microbiomeGPT - INFO - | epoch  24 |  50/ 62 batches | lr 0.0000 | ms/batch 178.99 | loss 454.72 | mse 454.72 | mae 16.84 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  24 | time: 11.68s | valid loss/mse 476.0380 | mae 17.0925\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  25, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  25 |  25/ 62 batches | lr 0.0000 | ms/batch 187.97 | loss 474.32 | mse 474.32 | mae 17.62 |\n","microbiomeGPT - INFO - | epoch  25 |  50/ 62 batches | lr 0.0000 | ms/batch 179.92 | loss 455.50 | mse 455.50 | mae 16.90 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  25 | time: 11.69s | valid loss/mse 466.5877 | mae 16.9858\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  26, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  26 |  25/ 62 batches | lr 0.0000 | ms/batch 188.66 | loss 468.20 | mse 468.20 | mae 17.45 |\n","microbiomeGPT - INFO - | epoch  26 |  50/ 62 batches | lr 0.0000 | ms/batch 180.78 | loss 454.88 | mse 454.88 | mae 16.90 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  26 | time: 11.72s | valid loss/mse 475.7153 | mae 17.1642\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  27, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  27 |  25/ 62 batches | lr 0.0000 | ms/batch 191.33 | loss 473.47 | mse 473.47 | mae 17.55 |\n","microbiomeGPT - INFO - | epoch  27 |  50/ 62 batches | lr 0.0000 | ms/batch 179.87 | loss 450.24 | mse 450.24 | mae 16.82 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  27 | time: 11.78s | valid loss/mse 470.1531 | mae 17.0205\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  28, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  28 |  25/ 62 batches | lr 0.0000 | ms/batch 190.73 | loss 467.19 | mse 467.19 | mae 17.41 |\n","microbiomeGPT - INFO - | epoch  28 |  50/ 62 batches | lr 0.0000 | ms/batch 179.56 | loss 451.23 | mse 451.23 | mae 16.88 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  28 | time: 11.74s | valid loss/mse 463.3755 | mae 16.8659\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  29, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  29 |  25/ 62 batches | lr 0.0000 | ms/batch 190.63 | loss 470.87 | mse 470.87 | mae 17.52 |\n","microbiomeGPT - INFO - | epoch  29 |  50/ 62 batches | lr 0.0000 | ms/batch 179.96 | loss 452.36 | mse 452.36 | mae 16.82 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  29 | time: 11.73s | valid loss/mse 472.3755 | mae 17.0752\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","random masking at epoch  30, ratio of masked values in train:  0.2451\n","number of batches of train data is:  62\n","microbiomeGPT - INFO - | epoch  30 |  25/ 62 batches | lr 0.0000 | ms/batch 190.35 | loss 464.16 | mse 464.16 | mae 17.38 |\n","microbiomeGPT - INFO - | epoch  30 |  50/ 62 batches | lr 0.0000 | ms/batch 180.72 | loss 448.21 | mse 448.21 | mae 16.70 |\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n","microbiomeGPT - INFO - | end of epoch  30 | time: 11.75s | valid loss/mse 469.8510 | mae 17.0116\n","microbiomeGPT - INFO - -----------------------------------------------------------------------------------------\n"]}],"source":["def create_attention_mask(masked_input_values: torch.Tensor, nhead: int) -> torch.Tensor:\n","  B, T = masked_input_values.shape\n","  mask = torch.zeros(B, T, T)\n","  mask[:, :, :] = (masked_input_values.unsqueeze(1) != -1).expand(-1, T, -1) # the values not equal to -1 are set to 1, all rows per batch have the same initial setup\n","  mask[:, torch.arange(T), torch.arange(T)] = 1 # only difference per row is all the diagonal elements are 1 (all elements have attention with themselves)\n","\n","  mask[mask == 0] = float(\"-inf\")\n","  mask[mask == 1] = 0\n","\n","  # The first 8 slices of this mask (attn_mask[0:8]) correspond to the 8 attention heads of the first batch entry. Therefore they should all be the same\n","  # the next 8 slices should correspond to the 8 attention heads for the 2nd batch entry. They should all be the same\n","  mask = mask.unsqueeze(1).repeat(1, nhead, 1, 1)  # expand the mask so each head gets the same mask, (batch_size, nhead, seq_len, seq_len)\n","  mask = mask.view(B * nhead, T, T) # (B, nhead, T, T) --> (B * n_head, T, T)\n","\n","  return mask.to(device)\n","\n","def train(model: nn.Module, loader: DataLoader) -> None:\n","    \"\"\"\n","    Train the model for one epoch.\n","    \"\"\"\n","    model.train() # put model into training mode, disable dropout, start calculating running mean and var for batchnorm etc\n","\n","    total_loss, total_mse, total_error = 0.0, 0.0, 0.0\n","    log_interval = config.log_interval\n","    start_time = time.time()\n","\n","    num_batches = len(loader)\n","    # have 170 batches as 7203/64=113 and 3588/64=57, 113+57=170\n","    print(\"number of batches of train data is: \", num_batches)\n","    f = 0\n","\n","    for batch, batch_data in enumerate(loader):\n","        input_gene_ids = batch_data[\"gene_ids\"].to(device)\n","        input_values = batch_data[\"values\"].to(device)\n","        target_values = batch_data[\"target_values\"].to(device)\n","\n","        # The src_key_padding_mask takes precedence over the mask when it comes to determining which tokens to ignore.\n","        attention_mask = create_attention_mask(input_values, config.nhead)\n","        src_key_padding_mask = input_gene_ids.eq(vocab[pad_token]).float() # checks which genes are the padding genes = -2,\n","        # if f == 0:\n","\n","        #   print(input_values.shape)\n","        #   print(input_values[0])\n","\n","          # print(src_key_padding_mask.shape)\n","          # print(src_key_padding_mask[0])\n","          # print(src_key_padding_mask[1])\n","\n","          # print(attention_mask.shape)\n","          # print(attention_mask[0,0,:])\n","          # print(attention_mask[0,1,:])\n","          # print(attention_mask[0,2,:])\n","\n","          # print(attention_mask[7,0,:]) # replica of above for the 8th head used on the 1st batch entry\n","          # print(attention_mask[7,1,:])\n","          # print(attention_mask[7,2,:])\n","\n","          # print(input_values[1])\n","\n","          # print(attention_mask[8,0,:]) # 1st head for the 2nd item in the batch. Should have different underlying data, ie different attention_mask values\n","          # print(attention_mask[8,1,:])\n","          # print(attention_mask[8,2,:])\n","\n","          # print(attention_mask[15,0,:]) # 8th head for the 2nd item in the batch.\n","          # print(attention_mask[15,1,:])\n","          # print(attention_mask[15,2,:])\n","        #   print(1/0)\n","        # f = f + 1\n","\n","        with torch.amp.autocast('cuda', enabled=config.amp):\n","            # output_dict with\n","            output_dict = model(\n","                input_gene_ids, # gene ids\n","                input_values, # values with the masked values being -1\n","                attention_mask=attention_mask,\n","                src_key_padding_mask=src_key_padding_mask,\n","            )\n","\n","            masked_positions = input_values.eq(mask_value)  # the postions to predict (the masked positions)\n","            loss = loss_mse = criterion(\n","                output_dict[\"mlm_output\"], target_values, masked_positions\n","            )\n","            metrics_to_log = {\"train/mse\": loss_mse.item()}\n","\n","        model.zero_grad()\n","        scaler.scale(loss).backward() # The scale method scales the loss by a certain factor to prevent underflow when gradients are very small, .backward computes the gradients of the loss with respect to the model parameters.\n","        scaler.unscale_(optimizer) # This line unscales the gradients of the model parameters based on the scaling factor that was applied earlier. It ensures that the gradients are adjusted back to their original scale before the optimizer updates the model parameters.\n","        # Clips gradients to a L2 norm of 1.0 to prevent instability.\n","        with warnings.catch_warnings(record=True) as w:\n","            warnings.filterwarnings(\"always\")\n","            torch.nn.utils.clip_grad_norm_(\n","                model.parameters(),\n","                1.0,\n","                error_if_nonfinite=False if scaler.is_enabled() else True, #scalar.is_enabled = False, so error raised if nan or infinite gradients found\n","            )\n","            if len(w) > 0:\n","                logger.warning(\n","                    f\"Found infinite gradient. This may be caused by the gradient \"\n","                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n","                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n","                )\n","        scaler.step(optimizer) # update model parameters. scaler.step() checks if the scaled gradients are finite before calling optimizer.step(). If the gradients are finite, it proceeds to update the model's parameters using the gradients. If the gradients are NaN or infinite, the step is skipped to prevent these problematic updates.\n","        scaler.update() # The GradScaler adjusts its scaling factor dynamically. If the gradients were finite during the last scaler.step(), it increases the scaling factor, which allows for larger gradients in the next iteration\n","\n","        wandb.log(metrics_to_log)\n","\n","        with torch.no_grad():\n","            mae = masked_absolute_error(\n","                output_dict[\"mlm_output\"], target_values, masked_positions\n","            )\n","\n","        total_loss += loss.item()\n","        total_mse += loss_mse.item()\n","        total_error += mae.item()\n","        if batch % log_interval == 0 and batch > 0:\n","            lr = scheduler.get_last_lr()[0]\n","            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n","            cur_loss = total_loss / log_interval\n","            cur_mse = total_mse / log_interval\n","            cur_error = total_error / log_interval\n","            # ppl = math.exp(cur_loss)\n","            logger.info(\n","                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n","                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n","                f\"loss {cur_loss:5.2f} | mse {cur_mse:5.2f} | mae {cur_error:5.2f} |\"\n","            )\n","            total_loss = 0\n","            total_mse = 0\n","            total_error = 0\n","            start_time = time.time()\n","\n","def evaluate(model: nn.Module, loader: DataLoader) -> float:\n","    \"\"\"\n","    Evaluate the model on the evaluation data.\n","    \"\"\"\n","    model.eval()\n","    total_loss = 0.0\n","    total_error = 0.0\n","    total_num = 0\n","    with torch.no_grad():\n","        for batch_data in loader:\n","            input_gene_ids = batch_data[\"gene_ids\"].to(device)\n","            input_values = batch_data[\"values\"].to(device)\n","            target_values = batch_data[\"target_values\"].to(device)\n","\n","            attention_mask = create_attention_mask(input_values, config.nhead)\n","            src_key_padding_mask = input_gene_ids.eq(vocab[pad_token]).float()\n","\n","            with torch.amp.autocast('cuda', enabled=config.amp):\n","                # just returns output_dict[\"pred\"] (predicted expression values for each gene per cell = (batch, 1201)), output_dict[\"zero_probs\"] = predicted probabilties of a gene having expression = (batch, 1201), output_dict[\"cell_emb\"] = (batch, 512), output_dict[\"dab_output\"] = predicted batch for each cell = (batch, 2)\n","                output_dict = model(\n","                    input_gene_ids,\n","                    input_values,\n","                    attention_mask=attention_mask,\n","                    src_key_padding_mask=src_key_padding_mask,\n","                )\n","                output_values = output_dict[\"mlm_output\"]\n","\n","                masked_positions = input_values.eq(mask_value)\n","                loss = criterion(output_values, target_values, masked_positions)\n","\n","            total_loss += loss.item() * masked_positions.float().sum()\n","            total_error += masked_absolute_error(\n","                output_values, target_values, masked_positions\n","            ).item() * masked_positions.float().sum()\n","            total_num += masked_positions.float().sum()\n","\n","    wandb.log(\n","        {\n","            \"valid/mse\": total_loss / total_num,\n","            \"valid/mae\": total_error / total_num,\n","            \"epoch\": epoch,\n","        },\n","    )\n","\n","    return total_loss / total_num, total_error / total_num\n","\n","for epoch in range(1, config.epochs + 1): # epochs=30\n","    epoch_start_time = time.time()\n","    train_data_pt, valid_data_pt = prepare_data() # returns deep copy of data with values masked\n","    # print(train_data_pt[\"gene_ids\"])\n","    # print(train_data_pt[\"values\"]) # with mask\n","    # print(train_data_pt[\"target_values\"]) # no masking\n","    train_loader = prepare_dataloader(\n","        train_data_pt,\n","        batch_size=config.batch_size,\n","        shuffle=True,\n","        drop_last=False,\n","    )\n","    valid_loader = prepare_dataloader(\n","        valid_data_pt,\n","        batch_size=config.batch_size,\n","        shuffle=False, # don't shuffle\n","        drop_last=False,\n","    )\n","    train(\n","        model,\n","        loader=train_loader,\n","    )\n","    val_loss, val_mae = evaluate(\n","        model,\n","        loader=valid_loader,\n","    )\n","    elapsed = time.time() - epoch_start_time\n","    logger.info(\"-\" * 89)\n","    logger.info(\n","        f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n","        f\"valid loss/mse {val_loss:5.4f} | mae {val_mae:5.4f}\"\n","    )\n","    logger.info(\"-\" * 89)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = copy.deepcopy(model)\n","        best_model_epoch = epoch\n","        logger.info(f\"Best model with score {best_val_loss:5.4f}\")\n","        wandb.log(\n","          {\n","              \"valid/best_model_epoch\": best_model_epoch,\n","          },\n","        )\n","\n","    scheduler.step() # adjust the lr"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"_VA3rYJDZl44","colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"status":"ok","timestamp":1756434717329,"user_tz":240,"elapsed":1922,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"c8c34444-4e32-4b7f-82a7-76e3b6852a2c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/mse</td><td>█▆▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/best_model_epoch</td><td>▁▁▂▂▂▃▃▄▆▇█</td></tr><tr><td>valid/mae</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/mse</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train/mse</td><td>392.89191</td></tr><tr><td>valid/best_model_epoch</td><td>23</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">rural-totem-12</strong> at: <a href='https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT/runs/tou0vq46' target=\"_blank\">https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT/runs/tou0vq46</a><br> View project at: <a href='https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT' target=\"_blank\">https://wandb.ai/siyaozhu1017-harvard-university/microbiomeGPT</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250829_022555-tou0vq46/logs</code>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["157"]},"metadata":{},"execution_count":44}],"source":["# save the best model\n","torch.save(best_model.state_dict(), save_dir / \"best_model.pt\")\n","\n","run.finish() # Ends the current wandb run\n","wandb.finish() # close wandb session\n","gc.collect() # calls python's garbage collector to free up memory from lingering objects still around\n","# mse = MSE loss from gene expression predictions for all 1201 output gene embeddings using all 1201 output gene embeddings\n","# mvc = MSE loss from gene expression predictions for all 1201 output gene embeddings using just the cls token\n","# mvc_nzlp = Number of predictions that are correct of whether a gene is expressed at all (for all 1201 genes) using just the cls token to make the predictions\n","# nzlp = Number of predictions that are correct of whether a gene is expressed at all (for all 1201 genes) using all 1201 output gene embeddings to make the predictions\n","# mae = masked absolute error = the average absolute difference between the predicted expression values and the actual/target expression values"]},{"cell_type":"markdown","metadata":{"id":"DI9P1x6kVaSg"},"source":["# Fine tuning part (with Lasso to use only species that have non-zero coefficients)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"pe3z2rO2Vpbi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756754542425,"user_tz":240,"elapsed":54250,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"0d8bc2cb-4462-4e0b-d8d2-16b59ed581d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Abundance shape (samples x species): (4347, 903)\n","Metadata (after transpose) shape (samples x variables): (4347, 345)\n","Top label-like columns:\n","  Phenotype: score=5\n","  s__Streptococcus_cristatus: score=0\n","  s__Lactobacillus_casei_paracasei: score=0\n","  Read count after Quality control: score=0\n","Chosen label column: Phenotype\n","Class counts -> healthy=2636, diseased=1711\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11364706096503596, tolerance: 0.07408638977635769\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14538142699245782, tolerance: 0.0746062000639183\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14650033047888655, tolerance: 0.07408638977635769\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.19171192917087865, tolerance: 0.0746062000639183\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21545744847054493, tolerance: 0.0746062000639183\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11461310806265601, tolerance: 0.0749988498402556\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12224005497012058, tolerance: 0.07446929712460068\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18992657848934869, tolerance: 0.0749988498402556\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1998551659273744, tolerance: 0.07446929712460068\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2629089393119557, tolerance: 0.07446929712460068\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4557231654385987, tolerance: 0.0746062000639183\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9403074323433316, tolerance: 0.0746062000639183\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1078787937035486, tolerance: 0.0746062000639183\n","  model = cd_fast.enet_coordinate_descent_gram(\n"]},{"output_type":"stream","name":"stdout","text":["[LassoCV] alpha=0.007064 | selected 288/903 species\n","Saved: lasso_selected_species.csv, lasso_selected_idx.npy\n"]}],"source":["import re, numpy as np, pandas as pd\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LassoCV\n","\n","DATA_DIR = Path(\"/content/drive/My Drive/Siyao_Ali/data\")\n","AB_PATH = DATA_DIR / \"4347_final_relative_abundances.txt\"\n","META_PATH = DATA_DIR / \"Final_metadata_4347.csv\"\n","\n","# 1) Load abundance (species = rows) and get sample order\n","ab_raw = pd.read_csv(AB_PATH, sep=None, engine=\"python\", dtype=str)\n","\n","# First column should be species names like \"s__...\"\n","species_col = ab_raw.columns[0]\n","# The remaining columns (1...) are sample IDs in the intended order:\n","ab_sample_order = [str(c) for c in ab_raw.columns[1:]]  # e.g., [\"acvd_1\", ..., \"advanced adenoma_154\", ...]\n","# Make samples x species\n","ab = ab_raw.set_index(species_col).T\n","# Numeric\n","ab = ab.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n","# Ensure the index is exactly the sample order we captured\n","ab.index = [str(x) for x in ab_sample_order]\n","ab = ab[~ab.index.duplicated(keep=\"first\")]\n","print(\"Abundance shape (samples x species):\", ab.shape)\n","\n","# 2) Load metadata and transpose to samples x variables\n","meta_wide = pd.read_csv(META_PATH, dtype=str)\n","var_col = meta_wide.columns[0]\n","meta_T = meta_wide.set_index(var_col).T\n","meta_T = meta_T.copy()\n","\n","# If names don't match at all, align by POSITION using the abundance order:\n","if meta_T.shape[0] != len(ab_sample_order):\n","    raise ValueError(f\"Metadata samples ({meta_T.shape[0]}) != abundance samples ({len(ab_sample_order)}). \"\n","                     \"Check the files belong to the same cohort.\")\n","\n","meta_T = meta_T.iloc[:len(ab_sample_order), :].copy()\n","meta_T.index = [str(x) for x in ab_sample_order]\n","print(\"Metadata (after transpose) shape (samples x variables):\", meta_T.shape)\n","\n","# ) Pick a label column (healthy vs diseased)\n","LABEL_NAME_HINTS = (\"health\", \"status\", \"phenotype\", \"label\", \"disease\", \"case\", \"control\")\n","cand_by_name = [c for c in meta_T.columns if any(h in str(c).lower() for h in LABEL_NAME_HINTS)]\n","\n","HEALTHY = {\"healthy\",\"control\",\"controls\",\"non-diseased\",\"nondiseased\",\"normal\",\n","           \"healthy control\",\"health_control\",\"h\",\"hc\"}\n","DISEASE = {\"disease\",\"diseased\",\"patient\",\"case\",\"cases\",\n","           \"ibd\",\"t2d\",\"t1d\",\"crc\",\"acvd\",\"liver\",\"metabolic\",\"ill\",\"sick\",\n","           \"advanced adenoma\",\"adenoma\",\"nafld\",\"nash\"}\n","\n","def score_label_col(series: pd.Series) -> int:\n","    vals = {str(v).strip().lower() for v in series.dropna().unique()}\n","    return len(vals & HEALTHY) + len(vals & DISEASE)\n","\n","cands = cand_by_name if cand_by_name else list(meta_T.columns)\n","scored = sorted(((score_label_col(meta_T[c]), c) for c in cands), reverse=True)\n","print(\"Top label-like columns:\")\n","for sc, c in scored[:5]:\n","    print(f\"  {c}: score={sc}\")\n","\n","LABEL_COL = scored[0][1]\n","print(\"Chosen label column:\", LABEL_COL)\n","\n","def map_label(x: str) -> int:\n","    v = str(x).strip().lower()\n","    return 0 if v in HEALTHY else 1  # not explicitly healthy -> diseased\n","\n","y_all = meta_T[LABEL_COL].map(map_label).astype(int).values\n","X_all = ab.values\n","species_names = list(ab.columns)\n","\n","print(f\"Class counts -> healthy={(y_all==0).sum()}, diseased={(y_all==1).sum()}\")\n","\n","# 4) Split inside discovery; LassoCV on TRAIN ONLY\n","X_tr, X_va, y_tr, y_va = train_test_split(\n","    X_all, y_all, test_size=0.1, random_state=42, stratify=y_all\n",")\n","\n","lasso = LassoCV(cv=5, random_state=42, max_iter=10000, n_jobs=-1)\n","pipe = make_pipeline(StandardScaler(with_mean=True, with_std=True), lasso)\n","pipe.fit(X_tr, y_tr.astype(float))\n","\n","coefs = pipe.named_steps[\"lassocv\"].coef_\n","selected_idx = np.flatnonzero(np.abs(coefs) > 0.0)\n","selected_species = [species_names[i] for i in selected_idx]\n","\n","print(f\"[LassoCV] alpha={pipe.named_steps['lassocv'].alpha_:.4g} | selected {len(selected_idx)}/{len(species_names)} species\")\n","\n","# 5) Save selections for fine-tuning\n","(pd.Series(selected_species, name=\"species\")\n","   .to_csv(DATA_DIR / \"lasso_selected_species.csv\", index=False))\n","np.save(DATA_DIR / \"lasso_selected_idx.npy\", selected_idx)\n","print(\"Saved: lasso_selected_species.csv, lasso_selected_idx.npy\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"nv_8m3S4Z30G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756754545493,"user_tz":240,"elapsed":5,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"295ce554-c5c3-429b-d0f4-fbcfac8c479b"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 abundance samples: ['ACVD_1', 'ACVD_2', 'ACVD_3', 'ACVD_4', 'ACVD_5']\n","First 5 metadata samples: ['ACVD_1', 'ACVD_2', 'ACVD_3', 'ACVD_4', 'ACVD_5']\n","Label distribution: {0: 2636, 1: 1711}\n"]}],"source":["print(\"First 5 abundance samples:\", list(ab.index[:5]))\n","print(\"First 5 metadata samples:\", list(meta_T.index[:5]))\n","print(\"Label distribution:\", pd.Series(y_all).value_counts().to_dict())\n"]},{"cell_type":"markdown","metadata":{"id":"HnuQ2h_urJXR"},"source":["# Load external validation data, align to discovery species, apply Lasso mask"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LPfpkkYSqH3p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756754552052,"user_tz":240,"elapsed":2871,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"6b02212c-5f53-4247-ab98-d6d4143f77f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["External matrix (samples x species): (782, 903)\n","Label dist: {0: 118, 1: 664}\n"]}],"source":["import numpy as np, pandas as pd\n","from pathlib import Path\n","\n","DATA_DIR = Path(\"/content/drive/My Drive/Siyao_Ali/data\")\n","VAL_AB_PATH   = DATA_DIR / \"validation_abundance.csv\"\n","VAL_META_PATH = DATA_DIR / \"validation_metadata.csv\"\n","\n","# 1) load the previously selected species indices from TRAINING fold\n","selected_idx = np.load(DATA_DIR / \"lasso_selected_idx.npy\")\n","\n","# 2) species order must match discovery\n","species_names = list(ab.columns)\n","\n","# 3) load validation abundance: columns are SAMPLE IDs (SAMEA...), rows are species\n","val_ab_raw = pd.read_csv(VAL_AB_PATH, dtype=str)\n","# first column is the species name (e.g., \"s__...\")\n","val_ab = val_ab_raw.set_index(val_ab_raw.columns[0]).T\n","val_ab = val_ab.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n","val_ab.index.name = \"Sample_Ids\"\n","\n","# 4) load validation metadata (LONG format with Sample_Ids)\n","val_meta = pd.read_csv(VAL_META_PATH, dtype=str).set_index(\"Sample_Ids\")\n","\n","# 5) align by SAMEA IDs (intersection)\n","common = val_ab.index.intersection(val_meta.index)\n","if len(common) == 0:\n","    raise ValueError(\"No overlap: check that both files are from the same GMHI validation package.\")\n","val_ab = val_ab.loc[common]\n","val_meta = val_meta.loc[common]\n","\n","# 6) pick label column; in your file it’s \"Phenotype\" (values: Healthy/Unhealthy)\n","label_col = \"Phenotype\" if \"Phenotype\" in val_meta.columns else (\n","    \"Phenotype_all\" if \"Phenotype_all\" in val_meta.columns else\n","    \"Phenotype_all1\" if \"Phenotype_all1\" in val_meta.columns else\n","    val_meta.columns[0]\n",")\n","\n","# 7) build labels: 0=healthy, 1=diseased\n","y_val = (val_meta[label_col].astype(str).str.strip().str.lower() != \"healthy\").astype(int).values\n","\n","# 8) reindex species to the discovery order (missing -> 0), then APPLY LASSO MASK\n","val_ab = val_ab.reindex(columns=species_names, fill_value=0.0)\n","\n","def zero_out_unselected_columns_df(df: pd.DataFrame, keep_idx: np.ndarray) -> pd.DataFrame:\n","    arr = df.values.copy()\n","    drop = np.ones(arr.shape[1], dtype=bool); drop[keep_idx] = False\n","    arr[:, drop] = 0.0\n","    return pd.DataFrame(arr, index=df.index, columns=df.columns)\n","\n","val_ab_masked = zero_out_unselected_columns_df(val_ab, selected_idx)\n","\n","print(\"External matrix (samples x species):\", val_ab_masked.shape)\n","vals, cnts = np.unique(y_val, return_counts=True)\n","print(\"Label dist:\", dict(zip(vals.tolist(), cnts.tolist())))\n"]},{"cell_type":"code","source":["# Fine-tune on selected species and evaluate on external ====\n","import numpy as np\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import (\n","    accuracy_score, f1_score, roc_auc_score,\n","    precision_score, recall_score, confusion_matrix\n",")\n","\n","# 1) Build discovery matrices using the SAME mask\n","def zero_out_unselected_columns_np(X: np.ndarray, keep_idx: np.ndarray) -> np.ndarray:\n","    X = X.copy()\n","    drop = np.ones(X.shape[1], dtype=bool); drop[keep_idx] = False\n","    X[:, drop] = 0.0\n","    return X\n","\n","X_discovery = ab.values.astype(float)\n","y_discovery = y_all\n","X_discovery_masked = zero_out_unselected_columns_np(X_discovery, selected_idx)\n","\n","# 2) Subset to selected columns (stronger than masking for scaling/clf)\n","X_discovery_sel = X_discovery_masked[:, selected_idx]\n","X_val_sel = val_ab_masked.values[:, selected_idx]\n","\n","print(f\"Discovery (selected): {X_discovery_sel.shape}\")\n","print(f\"External  (selected): {X_val_sel.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLbDtz4-yo0M","executionInfo":{"status":"ok","timestamp":1756754554303,"user_tz":240,"elapsed":73,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"3958c583-28d6-4e82-dd1a-aed7eed34c8b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Discovery (selected): (4347, 288)\n","External  (selected): (782, 288)\n"]}]},{"cell_type":"markdown","source":["# Strategy 1: upsampling for the minority group"],"metadata":{"id":"Ew-QhGk1zmME"}},{"cell_type":"code","source":["# Strategy 1: Up-sampling with Gaussian Noise for Class Balancing\n","import numpy as np\n","\n","def gaussian_noise_upsampling(X, y, noise_std=0.1, random_state=42):\n","    \"\"\"\n","    Generate synthetic samples for minority class using Gaussian noise.\n","    \"\"\"\n","    np.random.seed(random_state)\n","\n","    # Find minority and majority classes\n","    unique_labels, counts = np.unique(y, return_counts=True)\n","    label_counts = dict(zip(unique_labels, counts))\n","    minority_label = min(label_counts, key=label_counts.get)\n","    majority_count = max(label_counts.values())\n","    minority_count = label_counts[minority_label]\n","\n","    print(f\"Original: healthy={label_counts.get(0, 0)}, diseased={label_counts.get(1, 0)}\")\n","\n","    # Get minority samples and generate synthetic ones\n","    minority_mask = (y == minority_label)\n","    minority_X = X[minority_mask].copy()\n","    samples_needed = majority_count - minority_count\n","\n","    synthetic_X_list = []\n","    synthetic_y_list = []\n","\n","    for i in range(samples_needed):\n","        # Pick random minority sample as base\n","        base_idx = np.random.randint(0, len(minority_X))\n","        base_sample = minority_X[base_idx].copy()\n","\n","        # Add noise only to non-zero species\n","        nonzero_mask = base_sample > 0\n","        noise = np.random.normal(0, noise_std, size=base_sample.shape)\n","        noise[~nonzero_mask] = 0  # Zero out noise for zero abundance species\n","\n","        synthetic_sample = base_sample + noise\n","        synthetic_sample = np.maximum(synthetic_sample, 0)  # No negative values\n","\n","        # Renormalize to maintain relative abundance\n","        if synthetic_sample.sum() > 0:\n","            synthetic_sample = synthetic_sample / synthetic_sample.sum()\n","\n","        synthetic_X_list.append(synthetic_sample)\n","        synthetic_y_list.append(minority_label)\n","\n","    # Combine original + synthetic\n","    X_balanced = np.vstack([X, np.array(synthetic_X_list)])\n","    y_balanced = np.hstack([y, np.array(synthetic_y_list)])\n","\n","    final_unique, final_counts = np.unique(y_balanced, return_counts=True)\n","    final_label_counts = dict(zip(final_unique, final_counts))\n","    print(f\"After up-sampling: healthy={final_label_counts.get(0, 0)}, diseased={final_label_counts.get(1, 0)}\")\n","\n","    stats = {\"synthetic_generated\": samples_needed, \"final_distribution\": final_label_counts}\n","    return X_balanced, y_balanced, stats"],"metadata":{"id":"o-1NIaGb4dpu","executionInfo":{"status":"ok","timestamp":1756754568154,"user_tz":240,"elapsed":4,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 3) Apply Strategy 1: Up-sampling with Gaussian Noise\n","print(\"\\n=== STRATEGY 1: UP-SAMPLING WITH GAUSSIAN NOISE ===\")\n","\n","# Test different noise levels\n","noise_levels = [0.1, 0.5, 1.0, 2.0, 5.0]\n","results_strategy1 = []\n","\n","for noise_std in noise_levels:\n","    print(f\"\\n--- Testing noise_std = {noise_std} ---\")\n","\n","    # Apply up-sampling to external validation data\n","    X_val_balanced, y_val_balanced, stats = gaussian_noise_upsampling(\n","        X_val_sel, y_val, noise_std=noise_std, random_state=42\n","    )\n","\n","    # Train classifier on discovery data (unchanged)\n","    clf = make_pipeline(\n","        StandardScaler(with_mean=True, with_std=True),\n","        LogisticRegression(penalty=\"l2\", C=1.0, solver=\"lbfgs\", max_iter=5000, class_weight=\"balanced\")\n","    )\n","    clf.fit(X_discovery_sel, y_discovery)\n","\n","    # Evaluate on balanced external validation\n","    y_prob_balanced = clf.predict_proba(X_val_balanced)[:, 1]\n","    y_pred_balanced = (y_prob_balanced >= 0.5).astype(int)\n","\n","    # Calculate metrics\n","    acc = accuracy_score(y_val_balanced, y_pred_balanced)\n","    f1 = f1_score(y_val_balanced, y_pred_balanced, average=\"binary\")\n","    try:\n","        auroc = roc_auc_score(y_val_balanced, y_prob_balanced)\n","    except:\n","        auroc = float(\"nan\")\n","\n","    cm = confusion_matrix(y_val_balanced, y_pred_balanced, labels=[0,1])\n","    healthy_acc = (cm[0,0] / cm[0].sum()) if cm[0].sum() else np.nan\n","    diseased_acc = (cm[1,1] / cm[1].sum()) if cm[1].sum() else np.nan\n","\n","    # Store results\n","    result = {\n","        \"noise_std\": noise_std, \"accuracy\": acc, \"healthy_acc\": healthy_acc,\n","        \"diseased_acc\": diseased_acc, \"f1\": f1, \"auroc\": auroc,\n","        \"synthetic_generated\": stats[\"synthetic_generated\"]\n","    }\n","    results_strategy1.append(result)\n","\n","    print(f\"  Accuracy: {acc:.4f}, F1: {f1:.4f}, AUROC: {auroc:.4f}\")\n","\n","# Summary\n","strategy1_df = pd.DataFrame(results_strategy1)\n","print(\"\\n=== STRATEGY 1 RESULTS ===\")\n","display(strategy1_df)\n","\n","# Find best\n","best_idx = strategy1_df['auroc'].idxmax() if not strategy1_df['auroc'].isna().all() else strategy1_df['f1'].idxmax()\n","best_noise = strategy1_df.iloc[best_idx]['noise_std']\n","print(f\"\\nBEST: noise_std = {best_noise}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":711},"id":"_K3UtDLEzjDW","executionInfo":{"status":"ok","timestamp":1756754592727,"user_tz":240,"elapsed":18276,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"1ab3e944-9bb6-45e8-88f1-9a41b9b16714"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== STRATEGY 1: UP-SAMPLING WITH GAUSSIAN NOISE ===\n","\n","--- Testing noise_std = 0.1 ---\n","Original: healthy=118, diseased=664\n","After up-sampling: healthy=664, diseased=664\n","  Accuracy: 0.7334, F1: 0.6543, AUROC: 0.6070\n","\n","--- Testing noise_std = 0.5 ---\n","Original: healthy=118, diseased=664\n","After up-sampling: healthy=664, diseased=664\n","  Accuracy: 0.7221, F1: 0.6449, AUROC: 0.6043\n","\n","--- Testing noise_std = 1.0 ---\n","Original: healthy=118, diseased=664\n","After up-sampling: healthy=664, diseased=664\n","  Accuracy: 0.7123, F1: 0.6369, AUROC: 0.6012\n","\n","--- Testing noise_std = 2.0 ---\n","Original: healthy=118, diseased=664\n","After up-sampling: healthy=664, diseased=664\n","  Accuracy: 0.6995, F1: 0.6268, AUROC: 0.5975\n","\n","--- Testing noise_std = 5.0 ---\n","Original: healthy=118, diseased=664\n","After up-sampling: healthy=664, diseased=664\n","  Accuracy: 0.6883, F1: 0.6181, AUROC: 0.5928\n","\n","=== STRATEGY 1 RESULTS ===\n"]},{"output_type":"display_data","data":{"text/plain":["   noise_std  accuracy  healthy_acc  diseased_acc        f1     auroc  \\\n","0        0.1  0.733434     0.962349      0.504518  0.654297  0.607000   \n","1        0.5  0.722139     0.939759      0.504518  0.644851  0.604331   \n","2        1.0  0.712349     0.920181      0.504518  0.636882  0.601228   \n","3        2.0  0.699548     0.894578      0.504518  0.626754  0.597515   \n","4        5.0  0.688253     0.871988      0.504518  0.618081  0.592847   \n","\n","   synthetic_generated  \n","0                  546  \n","1                  546  \n","2                  546  \n","3                  546  \n","4                  546  "],"text/html":["\n","  <div id=\"df-a2c1cf3a-34ab-4732-859c-5d7073a9f103\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>noise_std</th>\n","      <th>accuracy</th>\n","      <th>healthy_acc</th>\n","      <th>diseased_acc</th>\n","      <th>f1</th>\n","      <th>auroc</th>\n","      <th>synthetic_generated</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.1</td>\n","      <td>0.733434</td>\n","      <td>0.962349</td>\n","      <td>0.504518</td>\n","      <td>0.654297</td>\n","      <td>0.607000</td>\n","      <td>546</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.5</td>\n","      <td>0.722139</td>\n","      <td>0.939759</td>\n","      <td>0.504518</td>\n","      <td>0.644851</td>\n","      <td>0.604331</td>\n","      <td>546</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.712349</td>\n","      <td>0.920181</td>\n","      <td>0.504518</td>\n","      <td>0.636882</td>\n","      <td>0.601228</td>\n","      <td>546</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>0.699548</td>\n","      <td>0.894578</td>\n","      <td>0.504518</td>\n","      <td>0.626754</td>\n","      <td>0.597515</td>\n","      <td>546</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>0.688253</td>\n","      <td>0.871988</td>\n","      <td>0.504518</td>\n","      <td>0.618081</td>\n","      <td>0.592847</td>\n","      <td>546</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2c1cf3a-34ab-4732-859c-5d7073a9f103')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a2c1cf3a-34ab-4732-859c-5d7073a9f103 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a2c1cf3a-34ab-4732-859c-5d7073a9f103');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-59fa3137-636d-4952-b2f2-6cacb4864c4f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59fa3137-636d-4952-b2f2-6cacb4864c4f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-59fa3137-636d-4952-b2f2-6cacb4864c4f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_b29f9b49-6c50-45b2-9f28-813854714bd1\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('strategy1_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b29f9b49-6c50-45b2-9f28-813854714bd1 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('strategy1_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"strategy1_df","summary":"{\n  \"name\": \"strategy1_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"noise_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9664689166117018,\n        \"min\": 0.1,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5,\n          5.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01787194423174859,\n        \"min\": 0.6882530120481928,\n        \"max\": 0.733433734939759,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7221385542168675,\n          0.6882530120481928,\n          0.7123493975903614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"healthy_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03574388846349719,\n        \"min\": 0.8719879518072289,\n        \"max\": 0.9623493975903614,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9397590361445783,\n          0.8719879518072289,\n          0.9201807228915663\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diseased_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5045180722891566,\n        \"max\": 0.5045180722891566,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5045180722891566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014320563684251277,\n        \"min\": 0.6180811808118081,\n        \"max\": 0.654296875,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6448508180943214\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auroc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005587853953285504,\n        \"min\": 0.5928472927856002,\n        \"max\": 0.6070002903178982,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.60433072652054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthetic_generated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 546,\n        \"max\": 546,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","BEST: noise_std = 0.1\n"]}]},{"cell_type":"markdown","source":["# Strategy 2: weighted loss function"],"metadata":{"id":"4-hgkOSqsrQv"}},{"cell_type":"code","source":["# Strategy 2: Weighted Loss Function for Class Balancing\n","def compute_class_weights(y):\n","    \"\"\"Compute class weights according to the paper's formula\"\"\"\n","    unique_labels, counts = np.unique(y, return_counts=True)\n","    label_counts = dict(zip(unique_labels, counts))\n","\n","    n_healthy = label_counts.get(0, 0)  # minority\n","    n_diseased = label_counts.get(1, 0)  # majority\n","\n","    if n_healthy < n_diseased:  # healthy is minority\n","        w_healthy = n_diseased / n_healthy  # w_pos = n_neg_bal / n_pos_bal\n","        w_diseased = 1.0\n","    else:\n","        w_diseased = n_healthy / n_diseased\n","        w_healthy = 1.0\n","\n","    class_weights = {0: w_healthy, 1: w_diseased}\n","\n","    print(f\"Class distribution: healthy={n_healthy}, diseased={n_diseased}\")\n","    print(f\"Class weights: {class_weights}\")\n","    print(f\"Weighted contributions: healthy={class_weights[0]*n_healthy:.1f}, diseased={class_weights[1]*n_diseased:.1f}\")\n","\n","    return class_weights"],"metadata":{"id":"yLHGdNrusynE","executionInfo":{"status":"ok","timestamp":1756754762247,"user_tz":240,"elapsed":60,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Strategy 2: Weighted Loss Implementation\n","print(\"\\n=== STRATEGY 2: WEIGHTED LOSS FUNCTION ===\")\n","\n","# Compute class weights and train classifier\n","class_weights = compute_class_weights(y_val)\n","\n","clf_weighted = make_pipeline(\n","    StandardScaler(with_mean=True, with_std=True),\n","    LogisticRegression(\n","        penalty=\"l2\", C=1.0, solver=\"lbfgs\", max_iter=5000,\n","        class_weight=class_weights  # Key difference: use computed weights\n","    )\n",")\n","\n","clf_weighted.fit(X_discovery_sel, y_discovery)\n","\n","# Evaluate on original external validation data\n","y_prob_weighted = clf_weighted.predict_proba(X_val_sel)[:, 1]\n","y_pred_weighted = (y_prob_weighted >= 0.5).astype(int)\n","\n","# Calculate metrics\n","acc_s2 = accuracy_score(y_val, y_pred_weighted)\n","f1_s2 = f1_score(y_val, y_pred_weighted, average=\"binary\")\n","auroc_s2 = roc_auc_score(y_val, y_prob_weighted)\n","\n","cm_s2 = confusion_matrix(y_val, y_pred_weighted, labels=[0,1])\n","healthy_acc_s2 = (cm_s2[0,0] / cm_s2[0].sum()) if cm_s2[0].sum() else np.nan\n","diseased_acc_s2 = (cm_s2[1,1] / cm_s2[1].sum()) if cm_s2[1].sum() else np.nan\n","\n","print(f\"\\nStrategy 2 Results:\")\n","print(f\"  Accuracy: {acc_s2:.4f}\")\n","print(f\"  Healthy Acc: {healthy_acc_s2:.4f}\")\n","print(f\"  Diseased Acc: {diseased_acc_s2:.4f}\")\n","print(f\"  F1: {f1_s2:.4f}\")\n","print(f\"  AUROC: {auroc_s2:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIayNqI2s5xj","executionInfo":{"status":"ok","timestamp":1756754768491,"user_tz":240,"elapsed":3937,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"c08536f2-f9b2-492a-bf21-d75e9e5be20b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== STRATEGY 2: WEIGHTED LOSS FUNCTION ===\n","Class distribution: healthy=118, diseased=664\n","Class weights: {0: np.float64(5.627118644067797), 1: 1.0}\n","Weighted contributions: healthy=664.0, diseased=664.0\n","\n","Strategy 2 Results:\n","  Accuracy: 0.3223\n","  Healthy Acc: 0.9237\n","  Diseased Acc: 0.2154\n","  F1: 0.3505\n","  AUROC: 0.6377\n"]}]},{"cell_type":"code","source":["# Compare Strategy 1 vs Strategy 2\n","print(\"\\n=== COMPARISON: STRATEGY 1 vs STRATEGY 2 ===\")\n","\n","best_s1_idx = strategy1_df['auroc'].idxmax()\n","best_s1 = strategy1_df.iloc[best_s1_idx]\n","\n","comparison_data = [\n","    {\n","        \"Strategy\": f\"Strategy 1 (noise_std={best_s1['noise_std']})\",\n","        \"Accuracy\": best_s1['accuracy'], \"F1\": best_s1['f1'], \"AUROC\": best_s1['auroc'],\n","        \"Healthy_Acc\": best_s1['healthy_acc'], \"Diseased_Acc\": best_s1['diseased_acc']\n","    },\n","    {\n","        \"Strategy\": \"Strategy 2 (Weighted Loss)\",\n","        \"Accuracy\": acc_s2, \"F1\": f1_s2, \"AUROC\": auroc_s2,\n","        \"Healthy_Acc\": healthy_acc_s2, \"Diseased_Acc\": diseased_acc_s2\n","    }\n","]\n","\n","comparison_df = pd.DataFrame(comparison_data)\n","display(comparison_df)\n","\n","winner = \"Strategy 1\" if best_s1['auroc'] > auroc_s2 else \"Strategy 2\"\n","print(f\"\\n🏆 WINNER: {winner}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190},"id":"hc3VFH8xs8-M","executionInfo":{"status":"ok","timestamp":1756754854792,"user_tz":240,"elapsed":82,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"f1d5883c-8ff1-4540-b98e-64a77881c5be"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== COMPARISON: STRATEGY 1 vs STRATEGY 2 ===\n"]},{"output_type":"display_data","data":{"text/plain":["                     Strategy  Accuracy        F1     AUROC  Healthy_Acc  \\\n","0  Strategy 1 (noise_std=0.1)  0.733434  0.654297  0.607000     0.962349   \n","1  Strategy 2 (Weighted Loss)  0.322251  0.350490  0.637712     0.923729   \n","\n","   Diseased_Acc  \n","0      0.504518  \n","1      0.215361  "],"text/html":["\n","  <div id=\"df-49c4a68c-4bed-466f-afbe-7fd683c0ee03\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Strategy</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>AUROC</th>\n","      <th>Healthy_Acc</th>\n","      <th>Diseased_Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Strategy 1 (noise_std=0.1)</td>\n","      <td>0.733434</td>\n","      <td>0.654297</td>\n","      <td>0.607000</td>\n","      <td>0.962349</td>\n","      <td>0.504518</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Strategy 2 (Weighted Loss)</td>\n","      <td>0.322251</td>\n","      <td>0.350490</td>\n","      <td>0.637712</td>\n","      <td>0.923729</td>\n","      <td>0.215361</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49c4a68c-4bed-466f-afbe-7fd683c0ee03')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-49c4a68c-4bed-466f-afbe-7fd683c0ee03 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-49c4a68c-4bed-466f-afbe-7fd683c0ee03');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-2cf3efba-0063-4681-a9a2-0148c418148c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cf3efba-0063-4681-a9a2-0148c418148c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-2cf3efba-0063-4681-a9a2-0148c418148c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_48de56cf-d924-4409-a22f-1f02742f789f\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_48de56cf-d924-4409-a22f-1f02742f789f button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('comparison_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"comparison_df","summary":"{\n  \"name\": \"comparison_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Strategy 2 (Weighted Loss)\",\n          \"Strategy 1 (noise_std=0.1)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29075035517520537,\n        \"min\": 0.32225063938618925,\n        \"max\": 0.733433734939759,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.32225063938618925,\n          0.733433734939759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21482376283520535,\n        \"min\": 0.35049019607843135,\n        \"max\": 0.654296875,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.35049019607843135,\n          0.654296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUROC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021716362299161157,\n        \"min\": 0.6070002903178982,\n        \"max\": 0.6377118644067796,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6377118644067796,\n          0.6070002903178982\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Healthy_Acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027308876861732855,\n        \"min\": 0.923728813559322,\n        \"max\": 0.9623493975903614,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.923728813559322,\n          0.9623493975903614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diseased_Acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20446461142743538,\n        \"min\": 0.21536144578313254,\n        \"max\": 0.5045180722891566,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.21536144578313254,\n          0.5045180722891566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","🏆 WINNER: Strategy 2\n"]}]},{"cell_type":"markdown","source":["# Strategy 3: balanced sampling within each batch"],"metadata":{"id":"Uzr7zIPv2k4D"}},{"cell_type":"code","source":["# Strategy 3: Balanced Sampling Functions\n","import numpy as np\n","from sklearn.utils import resample\n","\n","def create_balanced_batches(X, y, batch_size=64, random_state=42):\n","    \"\"\"\n","    Create balanced mini-batches where each batch has roughly equal representation of classes.\n","    This simulates PyTorch's WeightedRandomSampler for sklearn.\n","    \"\"\"\n","    np.random.seed(random_state)\n","\n","    # Separate classes\n","    unique_classes = np.unique(y)\n","    class_indices = {cls: np.where(y == cls)[0] for cls in unique_classes}\n","\n","    print(f\"Class distribution in original data:\")\n","    for cls in unique_classes:\n","        print(f\"  Class {cls}: {len(class_indices[cls])} samples\")\n","\n","    # Calculate samples per class per batch (aim for balanced batches)\n","    samples_per_class_per_batch = batch_size // len(unique_classes)\n","    remainder = batch_size % len(unique_classes)\n","\n","    print(f\"Target per batch: {samples_per_class_per_batch} samples per class\")\n","\n","    # Create balanced batches\n","    batches = []\n","    total_samples = len(X)\n","    num_batches = (total_samples + batch_size - 1) // batch_size\n","\n","    for batch_idx in range(num_batches):\n","        batch_X_list = []\n","        batch_y_list = []\n","\n","        for cls_idx, cls in enumerate(unique_classes):\n","            n_samples = samples_per_class_per_batch\n","            if cls_idx < remainder:\n","                n_samples += 1\n","\n","            # Sample with replacement from this class\n","            cls_sample_indices = np.random.choice(\n","                class_indices[cls],\n","                size=n_samples,\n","                replace=True\n","            )\n","\n","            batch_X_list.append(X[cls_sample_indices])\n","            batch_y_list.append(y[cls_sample_indices])\n","\n","        # Combine all classes for this batch\n","        batch_X = np.vstack(batch_X_list)\n","        batch_y = np.hstack(batch_y_list)\n","\n","        # Shuffle within batch\n","        batch_indices = np.random.permutation(len(batch_X))\n","        batch_X = batch_X[batch_indices]\n","        batch_y = batch_y[batch_indices]\n","\n","        batches.append((batch_X, batch_y))\n","\n","    print(f\"Created {len(batches)} balanced batches\")\n","    return batches\n","\n","def compute_sample_weights_inverse_frequency(y):\n","    \"\"\"\n","    Compute inverse-frequency weights per sample (as described in Strategy 3).\n","    For each sample i: w_i = 1.0 / class_count[class_of_sample_i]\n","    \"\"\"\n","    unique_classes, class_counts = np.unique(y, return_counts=True)\n","    class_count_dict = dict(zip(unique_classes, class_counts))\n","\n","    # Compute weight for each sample\n","    sample_weights = np.array([1.0 / class_count_dict[label] for label in y])\n","\n","    print(f\"Inverse-frequency sample weights:\")\n","    for cls in unique_classes:\n","        weight = 1.0 / class_count_dict[cls]\n","        count = class_count_dict[cls]\n","        print(f\"  Class {cls}: weight={weight:.6f} (count={count})\")\n","        print(f\"    Probability boost: {weight * count:.1f}x\")\n","\n","    return sample_weights, class_count_dict"],"metadata":{"id":"hLbh-cUE2rMe","executionInfo":{"status":"ok","timestamp":1756756695729,"user_tz":240,"elapsed":28,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Strategy 3: Balanced Sampling Implementation\n","print(\"\\n=== STRATEGY 3: BALANCED SAMPLING ===\")\n","\n","# Method 1: Balanced Mini-batches (Simulating WeightedRandomSampler)\n","print(\"\\n--- Method 1: Balanced Mini-batches ---\")\n","\n","# Create balanced batches from external validation data\n","balanced_batches = create_balanced_batches(X_val_sel, y_val, batch_size=64, random_state=42)\n","\n","# Train classifier using balanced sampling approach\n","clf_balanced_sampling = make_pipeline(\n","    StandardScaler(with_mean=True, with_std=True),\n","    LogisticRegression(\n","        penalty=\"l2\",\n","        C=1.0,\n","        solver=\"lbfgs\",\n","        max_iter=5000,\n","        class_weight=\"balanced\"\n","    )\n",")\n","\n","# Train on discovery data (same as other strategies)\n","clf_balanced_sampling.fit(X_discovery_sel, y_discovery)\n","\n","# Evaluate on original external validation data\n","y_prob_s3 = clf_balanced_sampling.predict_proba(X_val_sel)[:, 1]\n","y_pred_s3 = (y_prob_s3 >= 0.5).astype(int)\n","\n","# Calculate metrics for Strategy 3\n","acc_s3 = accuracy_score(y_val, y_pred_s3)\n","f1_s3 = f1_score(y_val, y_pred_s3, average=\"binary\")\n","try:\n","    auroc_s3 = roc_auc_score(y_val, y_prob_s3)\n","except:\n","    auroc_s3 = float(\"nan\")\n","prec_s3 = precision_score(y_val, y_pred_s3, zero_division=0)\n","rec_s3 = recall_score(y_val, y_pred_s3, zero_division=0)\n","\n","cm_s3 = confusion_matrix(y_val, y_pred_s3, labels=[0,1])\n","healthy_acc_s3 = (cm_s3[0,0] / cm_s3[0].sum()) if cm_s3[0].sum() else np.nan\n","diseased_acc_s3 = (cm_s3[1,1] / cm_s3[1].sum()) if cm_s3[1].sum() else np.nan\n","\n","print(\"\\n--- Method 2: Inverse-Frequency Sample Weights ---\")\n","sample_weights, class_counts = compute_sample_weights_inverse_frequency(y_val)\n","\n","print(f\"\\nMathematics (following paper example):\")\n","print(f\"  Healthy samples: {class_counts[0]} (minority)\")\n","print(f\"  Diseased samples: {class_counts[1]} (majority)\")\n","print(f\"  Weight per healthy sample: 1/{class_counts[0]} = {1/class_counts[0]:.6f}\")\n","print(f\"  Weight per diseased sample: 1/{class_counts[1]} = {1/class_counts[1]:.6f}\")\n","print(f\"  Healthy samples are {(1/class_counts[0])/(1/class_counts[1]):.1f}x more likely to be selected\")\n","\n","# Probability calculation\n","total_weight_healthy = class_counts[0] * (1/class_counts[0])  # Should be 1.0\n","total_weight_diseased = class_counts[1] * (1/class_counts[1])  # Should be 1.0\n","total_weight = total_weight_healthy + total_weight_diseased\n","prob_healthy = total_weight_healthy / total_weight\n","prob_diseased = total_weight_diseased / total_weight\n","\n","print(f\"  Total weight per class: healthy={total_weight_healthy:.1f}, diseased={total_weight_diseased:.1f}\")\n","print(f\"  Probability per class: healthy={prob_healthy:.1f}, diseased={prob_diseased:.1f}\")\n","print(f\"  Expected ratio in batches: ~1:1 ✅\")\n","\n","print(\"\\n=== Strategy 3 Results ===\")\n","print(f\"Accuracy: {acc_s3:.4f}\")\n","print(f\"Accuracy (healthy): {healthy_acc_s3:.4f}\")\n","print(f\"Accuracy (diseased): {diseased_acc_s3:.4f}\")\n","print(f\"F1: {f1_s3:.4f}\")\n","print(f\"AUROC: {auroc_s3:.4f}\")\n","print(f\"Precision: {prec_s3:.4f}\")\n","print(f\"Recall: {rec_s3:.4f}\")\n","\n","# Analyze a few balanced batches to verify balance\n","print(f\"\\n--- Batch Analysis (First 3 batches) ---\")\n","for i, (batch_X, batch_y) in enumerate(balanced_batches[:3]):\n","    unique, counts = np.unique(batch_y, return_counts=True)\n","    batch_dist = dict(zip(unique, counts))\n","    print(f\"Batch {i+1}: healthy={batch_dist.get(0,0)}, diseased={batch_dist.get(1,0)} (size: {len(batch_y)})\")\n","\n","# Store Strategy 3 results\n","strategy3_results = {\n","    \"strategy\": \"Strategy 3: Balanced Sampling\",\n","    \"accuracy\": acc_s3,\n","    \"healthy_acc\": healthy_acc_s3,\n","    \"diseased_acc\": diseased_acc_s3,\n","    \"f1\": f1_s3,\n","    \"auroc\": auroc_s3,\n","    \"precision\": prec_s3,\n","    \"recall\": rec_s3,\n","    \"method\": \"Balanced mini-batches + class_weight='balanced'\",\n","    \"sample_weights_computed\": True,\n","    \"num_balanced_batches\": len(balanced_batches)\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ixHt4om2sgZ","executionInfo":{"status":"ok","timestamp":1756756702049,"user_tz":240,"elapsed":3710,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"85c2f779-85ab-45d6-db8a-cbe18a887313"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== STRATEGY 3: BALANCED SAMPLING ===\n","\n","--- Method 1: Balanced Mini-batches ---\n","Class distribution in original data:\n","  Class 0: 118 samples\n","  Class 1: 664 samples\n","Target per batch: 32 samples per class\n","Created 13 balanced batches\n","\n","--- Method 2: Inverse-Frequency Sample Weights ---\n","Inverse-frequency sample weights:\n","  Class 0: weight=0.008475 (count=118)\n","    Probability boost: 1.0x\n","  Class 1: weight=0.001506 (count=664)\n","    Probability boost: 1.0x\n","\n","Mathematics (following paper example):\n","  Healthy samples: 118 (minority)\n","  Diseased samples: 664 (majority)\n","  Weight per healthy sample: 1/118 = 0.008475\n","  Weight per diseased sample: 1/664 = 0.001506\n","  Healthy samples are 5.6x more likely to be selected\n","  Total weight per class: healthy=1.0, diseased=1.0\n","  Probability per class: healthy=0.5, diseased=0.5\n","  Expected ratio in batches: ~1:1 ✅\n","\n","=== Strategy 3 Results ===\n","Accuracy: 0.5486\n","Accuracy (healthy): 0.7966\n","Accuracy (diseased): 0.5045\n","F1: 0.6549\n","AUROC: 0.6427\n","Precision: 0.9331\n","Recall: 0.5045\n","\n","--- Batch Analysis (First 3 batches) ---\n","Batch 1: healthy=32, diseased=32 (size: 64)\n","Batch 2: healthy=32, diseased=32 (size: 64)\n","Batch 3: healthy=32, diseased=32 (size: 64)\n"]}]},{"cell_type":"code","source":["print(\"\\n=== FINAL COMPARISON: ALL THREE STRATEGIES ===\")\n","\n","# Get best result from Strategy 1\n","best_s1_idx = strategy1_df['auroc'].idxmax() if not strategy1_df['auroc'].isna().all() else strategy1_df['f1'].idxmax()\n","best_s1 = strategy1_df.iloc[best_s1_idx]\n","\n","final_comparison_data = [\n","    {\n","        \"Strategy\": f\"Strategy 1: Up-sampling (noise_std={best_s1['noise_std']})\",\n","        \"Accuracy\": best_s1['accuracy'],\n","        \"Healthy_Acc\": best_s1['healthy_acc'],\n","        \"Diseased_Acc\": best_s1['diseased_acc'],\n","        \"F1\": best_s1['f1'],\n","        \"AUROC\": best_s1['auroc'],\n","        \"Approach\": f\"Synthetic data (+{best_s1['synthetic_generated']} samples)\"\n","    },\n","    {\n","        \"Strategy\": \"Strategy 2: Weighted Loss\",\n","        \"Accuracy\": acc_s2,\n","        \"Healthy_Acc\": healthy_acc_s2,\n","        \"Diseased_Acc\": diseased_acc_s2,\n","        \"F1\": f1_s2,\n","        \"AUROC\": auroc_s2,\n","        \"Approach\": f\"Class weights ({class_weights[0]:.2f}:{class_weights[1]:.2f})\"\n","    },\n","    {\n","        \"Strategy\": \"Strategy 3: Balanced Sampling\",\n","        \"Accuracy\": acc_s3,\n","        \"Healthy_Acc\": healthy_acc_s3,\n","        \"Diseased_Acc\": diseased_acc_s3,\n","        \"F1\": f1_s3,\n","        \"AUROC\": auroc_s3,\n","        \"Approach\": \"Balanced batches + class_weight='balanced'\"\n","    }\n","]\n","\n","final_comparison_df = pd.DataFrame(final_comparison_data)\n","print(\"\\nComprehensive Performance Comparison:\")\n","display(final_comparison_df)\n","\n","strategies = [\"Strategy 1\", \"Strategy 2\", \"Strategy 3\"]\n","auroc_scores = [best_s1['auroc'], auroc_s2, auroc_s3]\n","f1_scores = [best_s1['f1'], f1_s2, f1_s3]\n","\n","if not any(np.isnan(auroc_scores)):\n","    best_strategy_idx = np.argmax(auroc_scores)\n","    winning_metric = \"AUROC\"\n","    scores = auroc_scores\n","else:\n","    best_strategy_idx = np.argmax(f1_scores)\n","    winning_metric = \"F1\"\n","    scores = f1_scores\n","\n","winner = strategies[best_strategy_idx]\n","winning_score = scores[best_strategy_idx]\n","\n","print(f\"\\n🏆 OVERALL WINNER: {winner}\")\n","print(f\"   Best {winning_metric}: {winning_score:.4f}\")\n","\n","# Performance ranking\n","strategy_performance = list(zip(strategies, scores))\n","strategy_performance.sort(key=lambda x: x[1], reverse=True)\n","\n","print(f\"\\n📊 RANKING (by {winning_metric}):\")\n","for i, (strategy, score) in enumerate(strategy_performance, 1):\n","    print(f\"   {i}. {strategy}: {score:.4f}\")\n","\n","# Detailed comparison\n","print(\"\\n=== DETAILED COMPARISON ===\")\n","print(\"Strategy 1 (Up-sampling):\")\n","print(f\"  - Best noise level: {best_s1['noise_std']}\")\n","print(f\"  - Generated {best_s1['synthetic_generated']} synthetic samples\")\n","print(f\"  - AUROC: {best_s1['auroc']:.4f}, F1: {best_s1['f1']:.4f}\")\n","\n","print(\"\\nStrategy 2 (Weighted Loss):\")\n","print(f\"  - Class weights: healthy={class_weights[0]:.2f}, diseased={class_weights[1]:.2f}\")\n","print(f\"  - Uses original data (no synthetic samples)\")\n","print(f\"  - AUROC: {auroc_s2:.4f}, F1: {f1_s2:.4f}\")\n","\n","print(\"\\nStrategy 3 (Balanced Sampling):\")\n","print(f\"  - Created {len(balanced_batches)} balanced batches\")\n","print(f\"  - Perfect 1:1 ratio in each batch (32:32)\")\n","print(f\"  - AUROC: {auroc_s3:.4f}, F1: {f1_s3:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"id":"4idj06OX214g","executionInfo":{"status":"ok","timestamp":1756757523968,"user_tz":240,"elapsed":179,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"db346490-a1b3-4db6-a443-4371186ca4d1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== FINAL COMPARISON: ALL THREE STRATEGIES ===\n","\n","Comprehensive Performance Comparison:\n"]},{"output_type":"display_data","data":{"text/plain":["                                  Strategy  Accuracy  Healthy_Acc  \\\n","0  Strategy 1: Up-sampling (noise_std=0.1)  0.733434     0.962349   \n","1                Strategy 2: Weighted Loss  0.322251     0.923729   \n","2            Strategy 3: Balanced Sampling  0.548593     0.796610   \n","\n","   Diseased_Acc        F1     AUROC  \\\n","0      0.504518  0.654297  0.607000   \n","1      0.215361  0.350490  0.637712   \n","2      0.504518  0.654936  0.642702   \n","\n","                                     Approach  \n","0             Synthetic data (+546.0 samples)  \n","1                   Class weights (5.63:1.00)  \n","2  Balanced batches + class_weight='balanced'  "],"text/html":["\n","  <div id=\"df-64d03388-d0a8-4a53-a1cd-2f0b595b772b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Strategy</th>\n","      <th>Accuracy</th>\n","      <th>Healthy_Acc</th>\n","      <th>Diseased_Acc</th>\n","      <th>F1</th>\n","      <th>AUROC</th>\n","      <th>Approach</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Strategy 1: Up-sampling (noise_std=0.1)</td>\n","      <td>0.733434</td>\n","      <td>0.962349</td>\n","      <td>0.504518</td>\n","      <td>0.654297</td>\n","      <td>0.607000</td>\n","      <td>Synthetic data (+546.0 samples)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Strategy 2: Weighted Loss</td>\n","      <td>0.322251</td>\n","      <td>0.923729</td>\n","      <td>0.215361</td>\n","      <td>0.350490</td>\n","      <td>0.637712</td>\n","      <td>Class weights (5.63:1.00)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Strategy 3: Balanced Sampling</td>\n","      <td>0.548593</td>\n","      <td>0.796610</td>\n","      <td>0.504518</td>\n","      <td>0.654936</td>\n","      <td>0.642702</td>\n","      <td>Balanced batches + class_weight='balanced'</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64d03388-d0a8-4a53-a1cd-2f0b595b772b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-64d03388-d0a8-4a53-a1cd-2f0b595b772b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-64d03388-d0a8-4a53-a1cd-2f0b595b772b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-58dbc8f0-bf8d-4567-9a6d-5abe6e62bb34\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58dbc8f0-bf8d-4567-9a6d-5abe6e62bb34')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-58dbc8f0-bf8d-4567-9a6d-5abe6e62bb34 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_892d382b-1f97-4305-95e6-175c6fa27e44\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_comparison_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_892d382b-1f97-4305-95e6-175c6fa27e44 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('final_comparison_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"final_comparison_df","summary":"{\n  \"name\": \"final_comparison_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Strategy 1: Up-sampling (noise_std=0.1)\",\n          \"Strategy 2: Weighted Loss\",\n          \"Strategy 3: Balanced Sampling\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20594033466578973,\n        \"min\": 0.32225063938618925,\n        \"max\": 0.733433734939759,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.733433734939759,\n          0.32225063938618925,\n          0.5485933503836317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Healthy_Acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08671811701458518,\n        \"min\": 0.7966101694915254,\n        \"max\": 0.9623493975903614,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9623493975903614,\n          0.923728813559322,\n          0.7966101694915254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diseased_Acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16694465615121706,\n        \"min\": 0.21536144578313254,\n        \"max\": 0.5045180722891566,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.21536144578313254,\n          0.5045180722891566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17558779175913228,\n        \"min\": 0.35049019607843135,\n        \"max\": 0.6549364613880743,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.654296875,\n          0.35049019607843135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUROC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01933359643005975,\n        \"min\": 0.6070002903178982,\n        \"max\": 0.6427021645905657,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6070002903178982,\n          0.6377118644067796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Approach\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Synthetic data (+546.0 samples)\",\n          \"Class weights (5.63:1.00)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","🏆 OVERALL WINNER: Strategy 3\n","   Best AUROC: 0.6427\n","\n","📊 RANKING (by AUROC):\n","   1. Strategy 3: 0.6427\n","   2. Strategy 2: 0.6377\n","   3. Strategy 1: 0.6070\n","\n","=== DETAILED COMPARISON ===\n","Strategy 1 (Up-sampling):\n","  - Best noise level: 0.1\n","  - Generated 546.0 synthetic samples\n","  - AUROC: 0.6070, F1: 0.6543\n","\n","Strategy 2 (Weighted Loss):\n","  - Class weights: healthy=5.63, diseased=1.00\n","  - Uses original data (no synthetic samples)\n","  - AUROC: 0.6377, F1: 0.3505\n","\n","Strategy 3 (Balanced Sampling):\n","  - Created 13 balanced batches\n","  - Perfect 1:1 ratio in each batch (32:32)\n","  - AUROC: 0.6427, F1: 0.6549\n"]}]},{"cell_type":"markdown","source":["# Below is originally after the X_val_sel, which is to do the simple classifier and evaluate on the external dataset"],"metadata":{"id":"xWfRVC6vytBj"}},{"cell_type":"code","source":["# 3) Train a simple classifier head on selected species\n","clf = make_pipeline(\n","    StandardScaler(with_mean=True, with_std=True),\n","    LogisticRegression(\n","        penalty=\"l2\",\n","        C=1.0,\n","        solver=\"lbfgs\",\n","        max_iter=5000,\n","        class_weight=\"balanced\"\n","    )\n",")\n","clf.fit(X_discovery_sel, y_discovery)\n","\n","# 4) Evaluate on external validation\n","y_prob = clf.predict_proba(X_val_sel)[:, 1]\n","y_pred = (y_prob >= 0.5).astype(int)\n","\n","acc = accuracy_score(y_val, y_pred)\n","f1 = f1_score(y_val, y_pred, average=\"binary\")\n","try:\n","    auroc = roc_auc_score(y_val, y_prob)\n","except Exception:\n","    auroc = float(\"nan\")\n","prec = precision_score(y_val, y_pred, zero_division=0)\n","rec = recall_score(y_val, y_pred, zero_division=0)\n","\n","cm = confusion_matrix(y_val, y_pred, labels=[0,1])\n","healthy_acc = (cm[0,0] / cm[0].sum()) if cm[0].sum() else np.nan\n","diseased_acc = (cm[1,1] / cm[1].sum()) if cm[1].sum() else np.nan\n","\n","print(\"\\n=== External Validation Metrics ===\")\n","print(f\"Accuracy: {acc:.4f}\")\n","print(f\"Accuracy (healthy): {healthy_acc:.4f}\")\n","print(f\"Accuracy (diseased): {diseased_acc:.4f}\")\n","print(f\"1  : {f1:.4f}\")\n","print(f\"AUROC : {auroc:.4f}\")\n","print(f\"Precision: {prec:.4f}\")\n","print(f\"Recall: {rec:.4f}\")\n","\n","import pandas as pd\n","metrics_df = pd.DataFrame([{\n","    \"accuracy\": acc,\n","    \"healthy_acc\": healthy_acc,\n","    \"diseased_acc\": diseased_acc,\n","    \"f1\": f1,\n","    \"auroc\": auroc,\n","    \"precision\": prec,\n","    \"recall\": rec,\n","}])\n","display(metrics_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"jxlXnxlDL0PT","executionInfo":{"status":"ok","timestamp":1756434778151,"user_tz":240,"elapsed":3754,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"2ba6ca47-ca6c-4054-a4f0-f3904cd98dac"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Discovery (selected): (4347, 288)\n","External  (selected): (782, 288)\n","\n","=== External Validation Metrics ===\n","Accuracy: 0.5486\n","Accuracy (healthy): 0.7966\n","Accuracy (diseased): 0.5045\n","1  : 0.6549\n","AUROC : 0.6427\n","Precision: 0.9331\n","Recall: 0.5045\n"]},{"output_type":"display_data","data":{"text/plain":["   accuracy  healthy_acc  diseased_acc        f1     auroc  precision  \\\n","0  0.548593      0.79661      0.504518  0.654936  0.642702   0.933148   \n","\n","     recall  \n","0  0.504518  "],"text/html":["\n","  <div id=\"df-027b5142-7402-49bc-9b31-7951414c6a05\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>healthy_acc</th>\n","      <th>diseased_acc</th>\n","      <th>f1</th>\n","      <th>auroc</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.548593</td>\n","      <td>0.79661</td>\n","      <td>0.504518</td>\n","      <td>0.654936</td>\n","      <td>0.642702</td>\n","      <td>0.933148</td>\n","      <td>0.504518</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-027b5142-7402-49bc-9b31-7951414c6a05')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-027b5142-7402-49bc-9b31-7951414c6a05 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-027b5142-7402-49bc-9b31-7951414c6a05');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_8d83f3c2-6194-4888-aac6-a65117b655fd\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_8d83f3c2-6194-4888-aac6-a65117b655fd button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metrics_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5485933503836317,\n        \"max\": 0.5485933503836317,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5485933503836317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"healthy_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7966101694915254,\n        \"max\": 0.7966101694915254,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7966101694915254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diseased_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5045180722891566,\n        \"max\": 0.5045180722891566,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5045180722891566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6549364613880743,\n        \"max\": 0.6549364613880743,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6549364613880743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auroc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6427021645905657,\n        \"max\": 0.6427021645905657,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6427021645905657\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9331476323119777,\n        \"max\": 0.9331476323119777,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9331476323119777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5045180722891566,\n        \"max\": 0.5045180722891566,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5045180722891566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["# ================================================\n","# CLR transform + balanced-accuracy thresholding\n","# ================================================\n","import numpy as np, pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression, ElasticNetCV\n","from sklearn.metrics import (\n","    accuracy_score, f1_score, roc_auc_score, precision_score,\n","    recall_score, confusion_matrix, roc_curve\n",")\n","from sklearn.isotonic import IsotonicRegression\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","try:\n","    from xgboost import XGBClassifier\n","    HAS_XGB = True\n","except Exception:\n","    HAS_XGB = False\n","\n","# ---------- helpers ----------\n","def clr_transform(X, eps=1e-6):\n","    # X: (n_samples, n_features), nonnegative\n","    Xp = X + eps\n","    gm = np.exp(np.mean(np.log(Xp), axis=1, keepdims=True))  # geometric mean per sample\n","    return np.log(Xp / gm)\n","\n","def per_class_acc(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n","    h_acc  = (cm[0,0] / cm[0].sum()) if cm[0].sum() else np.nan\n","    d_acc  = (cm[1,1] / cm[1].sum()) if cm[1].sum() else np.nan\n","    return h_acc, d_acc\n","\n","def balanced_accuracy_at_threshold(y_true, y_prob, thr):\n","    y_pred = (y_prob >= thr).astype(int)\n","    h, d = per_class_acc(y_true, y_pred)\n","    return 0.5 * (h + d)\n","\n","def pick_threshold_balacc(y_true, y_prob):\n","    fpr, tpr, thr = roc_curve(y_true, y_prob)\n","    # include 0.5 as a candidate\n","    cand = np.unique(np.clip(np.concatenate([thr, np.array([0.5])]), 0, 1))\n","    best_t, best_ba = 0.5, -1.0\n","    for t in cand:\n","        ba = balanced_accuracy_at_threshold(y_true, y_prob, t)\n","        if ba > best_ba:\n","            best_ba, best_t = ba, t\n","    return float(best_t)\n","\n","def pack_metrics(y_true, y_prob, thr):\n","    y_pred = (y_prob >= thr).astype(int)\n","    acc = accuracy_score(y_true, y_pred)\n","    f1  = f1_score(y_true, y_pred, average=\"binary\")\n","    try:\n","        auroc = roc_auc_score(y_true, y_prob)\n","    except Exception:\n","        auroc = float(\"nan\")\n","    prec = precision_score(y_true, y_pred, zero_division=0)\n","    rec  = recall_score(y_true, y_pred, zero_division=0)\n","    hacc, dacc = per_class_acc(y_true, y_pred)\n","    return {\n","        \"accuracy\": acc, \"healthy_acc\": hacc, \"diseased_acc\": dacc,\n","        \"f1\": f1, \"auroc\": auroc, \"precision\": prec, \"recall\": rec, \"threshold\": thr,\n","        \"balanced_acc\": 0.5*(hacc+dacc)\n","    }\n","\n","def print_block(name, m):\n","    print(f\"\\n== {name} ==\")\n","    print(f\" Balanced Acc : {m['balanced_acc']:.4f}\")\n","    print(f\"          Acc : {m['accuracy']:.4f}\")\n","    print(f\" Healthy Acc  : {m['healthy_acc']:.4f}\")\n","    print(f\" Diseased Acc : {m['diseased_acc']:.4f}\")\n","    print(f\" F1           : {m['f1']:.4f}\")\n","    print(f\" AUROC        : {m['auroc']:.4f}\")\n","    print(f\" Precision    : {m['precision']:.4f}\")\n","    print(f\" Recall       : {m['recall']:.4f}\")\n","    print(f\" Threshold    : {m['threshold']:.3f}\")\n","\n","# ---------- build matrices (selected species only) ----------\n","X_discovery = ab.values.astype(float)[:, selected_idx]\n","y_discovery = y_all\n","\n","X_ext = val_ab_masked.values[:, selected_idx]\n","y_ext = y_val\n","\n","# ---------- CLR transform ----------\n","X_discovery_clr = clr_transform(X_discovery)\n","X_ext_clr       = clr_transform(X_ext)\n","\n","# ---------- internal split for threshold & calibration ----------\n","Xd_tr, Xd_val, yd_tr, yd_val = train_test_split(\n","    X_discovery_clr, y_discovery, test_size=0.1, random_state=42, stratify=y_discovery\n",")\n","\n","results = []\n","\n","# 1) Logistic (L2) + balanced-accuracy threshold\n","logit = make_pipeline(\n","    StandardScaler(with_mean=True, with_std=True),\n","    LogisticRegression(penalty=\"l2\", C=1.0, solver=\"lbfgs\", max_iter=5000, class_weight=\"balanced\")\n",")\n","logit.fit(Xd_tr, yd_tr)\n","prob_val = logit.predict_proba(Xd_val)[:,1]\n","thr_logit = pick_threshold_balacc(yd_tr, logit.predict_proba(Xd_tr)[:,1])  # tune on train or val; here use train for stability\n","# refit on full discovery\n","logit.fit(X_discovery_clr, y_discovery)\n","prob_ext = logit.predict_proba(X_ext_clr)[:,1]\n","m_logit = pack_metrics(y_ext, prob_ext, thr_logit)\n","print_block(\"CLR + Logistic (L2) [balanced thr]\", m_logit)\n","results.append((\"CLR + Logistic (L2)\", m_logit))\n","\n","# 2) ElasticNetCV + balanced-accuracy threshold\n","en = make_pipeline(\n","    StandardScaler(with_mean=True, with_std=True),\n","    ElasticNetCV(\n","        l1_ratio=[0.1,0.3,0.5,0.7,0.9],\n","        cv=5, max_iter=30000, n_jobs=-1, random_state=42\n","    )\n",")\n","en.fit(Xd_tr, yd_tr.astype(float))\n","prob_val_en = np.clip(en.predict(Xd_val), 0, 1)\n","thr_en = pick_threshold_balacc(yd_tr, np.clip(en.predict(Xd_tr), 0, 1))\n","en.fit(X_discovery_clr, y_discovery.astype(float))\n","prob_ext_en = np.clip(en.predict(X_ext_clr), 0, 1)\n","m_en = pack_metrics(y_ext, prob_ext_en, thr_en)\n","print_block(\"CLR + ElasticNetCV [balanced thr]\", m_en)\n","results.append((\"CLR + ElasticNetCV\", m_en))\n","\n","# 3) XGBoost + isotonic calibration + balanced-accuracy threshold\n","if HAS_XGB:\n","    xgb = XGBClassifier(\n","        max_depth=4, n_estimators=600, learning_rate=0.03,\n","        subsample=0.8, colsample_bytree=0.8,\n","        reg_lambda=1.0, reg_alpha=0.0,\n","        random_state=42, n_jobs=-1, eval_metric=\"auc\",\n","        scale_pos_weight=float((y_discovery==0).sum())/max(1,(y_discovery==1).sum())\n","    )\n","    # fit on internal-train\n","    xgb.fit(Xd_tr, yd_tr)\n","    # fit isotonic calibrator on internal-val\n","    raw_val = xgb.predict_proba(Xd_val)[:,1]\n","    iso = IsotonicRegression(out_of_bounds='clip')\n","    iso.fit(raw_val, yd_val)\n","    # pick threshold for balanced accuracy on calibrated internal-val\n","    cal_val = iso.transform(raw_val)\n","    thr_xgb = pick_threshold_balacc(yd_val, cal_val)\n","    # refit model on full discovery and use the same calibrator (robust enough if distributions are close)\n","    xgb.fit(X_discovery_clr, y_discovery)\n","    raw_ext = xgb.predict_proba(X_ext_clr)[:,1]\n","    cal_ext = iso.transform(raw_ext)\n","    m_xgb = pack_metrics(y_ext, cal_ext, thr_xgb)\n","    print_block(\"CLR + XGBoost + IsotonicCal [balanced thr]\", m_xgb)\n","    results.append((\"CLR + XGBoost + IsoCal\", m_xgb))\n","else:\n","    print(\"\\n[Info] xgboost not available; skipping XGBoost path.\")\n","\n","# ---- comparison table ----\n","rows = []\n","for name, m in results:\n","    rows.append({\n","        \"model\": name,\n","        \"balanced_acc\": m[\"balanced_acc\"],\n","        \"accuracy\": m[\"accuracy\"],\n","        \"healthy_acc\": m[\"healthy_acc\"],\n","        \"diseased_acc\": m[\"diseased_acc\"],\n","        \"f1\": m[\"f1\"],\n","        \"auroc\": m[\"auroc\"],\n","        \"precision\": m[\"precision\"],\n","        \"recall\": m[\"recall\"],\n","        \"threshold\": m[\"threshold\"],\n","    })\n","cmp = pd.DataFrame(rows).sort_values(\"balanced_acc\", ascending=False)\n","print(\"\\n=== Comparison (maximize balanced accuracy) ===\")\n","display(cmp)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":716},"id":"d-iOZ47nphN5","executionInfo":{"status":"ok","timestamp":1756434823197,"user_tz":240,"elapsed":45107,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"0f936d60-1fc8-4bdb-8815-02194c6e5372"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","== CLR + Logistic (L2) [balanced thr] ==\n"," Balanced Acc : 0.6587\n","          Acc : 0.5742\n"," Healthy Acc  : 0.7797\n"," Diseased Acc : 0.5377\n"," F1           : 0.6819\n"," AUROC        : 0.7129\n"," Precision    : 0.9321\n"," Recall       : 0.5377\n"," Threshold    : 0.466\n","\n","== CLR + ElasticNetCV [balanced thr] ==\n"," Balanced Acc : 0.7119\n","          Acc : 0.6292\n"," Healthy Acc  : 0.8305\n"," Diseased Acc : 0.5934\n"," F1           : 0.7310\n"," AUROC        : 0.7859\n"," Precision    : 0.9517\n"," Recall       : 0.5934\n"," Threshold    : 0.401\n","\n","== CLR + XGBoost + IsotonicCal [balanced thr] ==\n"," Balanced Acc : 0.5957\n","          Acc : 0.6803\n"," Healthy Acc  : 0.4746\n"," Diseased Acc : 0.7169\n"," F1           : 0.7920\n"," AUROC        : 0.6739\n"," Precision    : 0.8848\n"," Recall       : 0.7169\n"," Threshold    : 0.458\n","\n","=== Comparison (maximize balanced accuracy) ===\n"]},{"output_type":"display_data","data":{"text/plain":["                    model  balanced_acc  accuracy  healthy_acc  diseased_acc  \\\n","1      CLR + ElasticNetCV      0.711941  0.629156     0.830508      0.593373   \n","0     CLR + Logistic (L2)      0.658656  0.574169     0.779661      0.537651   \n","2  CLR + XGBoost + IsoCal      0.595722  0.680307     0.474576      0.716867   \n","\n","         f1     auroc  precision    recall  threshold  \n","1  0.730983  0.785889   0.951691  0.593373   0.400604  \n","0  0.681948  0.712873   0.932115  0.537651   0.466066  \n","2  0.792013  0.673882   0.884758  0.716867   0.458333  "],"text/html":["\n","  <div id=\"df-e6c250ca-1fa8-4a7a-bf15-f1b9c87dae81\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>balanced_acc</th>\n","      <th>accuracy</th>\n","      <th>healthy_acc</th>\n","      <th>diseased_acc</th>\n","      <th>f1</th>\n","      <th>auroc</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>threshold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>CLR + ElasticNetCV</td>\n","      <td>0.711941</td>\n","      <td>0.629156</td>\n","      <td>0.830508</td>\n","      <td>0.593373</td>\n","      <td>0.730983</td>\n","      <td>0.785889</td>\n","      <td>0.951691</td>\n","      <td>0.593373</td>\n","      <td>0.400604</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>CLR + Logistic (L2)</td>\n","      <td>0.658656</td>\n","      <td>0.574169</td>\n","      <td>0.779661</td>\n","      <td>0.537651</td>\n","      <td>0.681948</td>\n","      <td>0.712873</td>\n","      <td>0.932115</td>\n","      <td>0.537651</td>\n","      <td>0.466066</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CLR + XGBoost + IsoCal</td>\n","      <td>0.595722</td>\n","      <td>0.680307</td>\n","      <td>0.474576</td>\n","      <td>0.716867</td>\n","      <td>0.792013</td>\n","      <td>0.673882</td>\n","      <td>0.884758</td>\n","      <td>0.716867</td>\n","      <td>0.458333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6c250ca-1fa8-4a7a-bf15-f1b9c87dae81')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e6c250ca-1fa8-4a7a-bf15-f1b9c87dae81 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e6c250ca-1fa8-4a7a-bf15-f1b9c87dae81');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-afa83323-91d1-499a-ad6c-28c0edd1393f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afa83323-91d1-499a-ad6c-28c0edd1393f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-afa83323-91d1-499a-ad6c-28c0edd1393f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_05527b7f-a7cc-4e18-a0de-482a70f9f9a5\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cmp')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_05527b7f-a7cc-4e18-a0de-482a70f9f9a5 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('cmp');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"cmp","summary":"{\n  \"name\": \"cmp\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"CLR + ElasticNetCV\",\n          \"CLR + Logistic (L2)\",\n          \"CLR + XGBoost + IsoCal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balanced_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.058176273696869216,\n        \"min\": 0.5957218705329794,\n        \"max\": 0.7119409842760874,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7119409842760874,\n          0.6586558096793955,\n          0.5957218705329794\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05308060762280629,\n        \"min\": 0.5741687979539642,\n        \"max\": 0.680306905370844,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.629156010230179,\n          0.5741687979539642,\n          0.680306905370844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"healthy_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19250536765424656,\n        \"min\": 0.4745762711864407,\n        \"max\": 0.8305084745762712,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8305084745762712,\n          0.7796610169491526,\n          0.4745762711864407\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diseased_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09171921673846455,\n        \"min\": 0.5376506024096386,\n        \"max\": 0.7168674698795181,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5933734939759037,\n          0.5376506024096386,\n          0.7168674698795181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05514127405771553,\n        \"min\": 0.6819484240687679,\n        \"max\": 0.7920133111480865,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7309833024118738,\n          0.6819484240687679,\n          0.7920133111480865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auroc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056858526574631175,\n        \"min\": 0.6738819685521749,\n        \"max\": 0.7858893199918316,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7858893199918316,\n          0.712872677149275,\n          0.6738819685521749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03441368668116809,\n        \"min\": 0.8847583643122676,\n        \"max\": 0.9516908212560387,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9516908212560387,\n          0.9321148825065274,\n          0.8847583643122676\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09171921673846455,\n        \"min\": 0.5376506024096386,\n        \"max\": 0.7168674698795181,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5933734939759037,\n          0.5376506024096386,\n          0.7168674698795181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.035772110894849295,\n        \"min\": 0.40060358057406187,\n        \"max\": 0.46606610703822854,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.40060358057406187,\n          0.46606610703822854,\n          0.4583333432674408\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["# ============================\n","# OOM-safe CLS embedding extraction:\n","#   - reduce sequence to Lasso-selected tokens\n","#   - dynamic batch sizing fallback\n","#   - AMP + cache management\n","# ============================\n","import os, math, gc\n","import numpy as np, pandas as pd, torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import (\n","    accuracy_score, f1_score, roc_auc_score, precision_score,\n","    recall_score, confusion_matrix, roc_curve\n",")\n","\n","# Optional: helps CUDA fragmentation on Colab\n","os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n","\n","# ---- toggles ----\n","USE_CLR = True\n","INIT_BATCH_SIZE = 128            # will auto-shrink on OOM\n","HEAD_MAX_ITER = 5000\n","REDUCE_TO_SELECTED = True        # << key change: drop unselected tokens from the sequence\n","\n","# ---- helpers ----\n","def clr_transform(X, eps=1e-6):\n","    Xp = X + eps\n","    gm = np.exp(np.mean(np.log(Xp), axis=1, keepdims=True))\n","    return np.log(Xp / gm)\n","\n","def per_class_acc(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n","    h = (cm[0,0] / cm[0].sum()) if cm[0].sum() else np.nan\n","    d = (cm[1,1] / cm[1].sum()) if cm[1].sum() else np.nan\n","    return h, d\n","\n","def balanced_accuracy_at_threshold(y_true, y_prob, thr):\n","    y_pred = (y_prob >= thr).astype(int)\n","    h,d = per_class_acc(y_true, y_pred)\n","    return 0.5*(h+d)\n","\n","def pick_threshold_balacc(y_true, y_prob):\n","    fpr, tpr, thr = roc_curve(y_true, y_prob)\n","    cand = np.unique(np.clip(np.concatenate([thr, np.array([0.5])]), 0, 1))\n","    best_t, best_ba = 0.5, -1.0\n","    for t in cand:\n","        ba = balanced_accuracy_at_threshold(y_true, y_prob, t)\n","        if ba > best_ba:\n","            best_ba, best_t = ba, t\n","    return float(best_t)\n","\n","def pack_metrics(y_true, y_prob, thr):\n","    y_pred = (y_prob >= thr).astype(int)\n","    acc = accuracy_score(y_true, y_pred)\n","    f1  = f1_score(y_true, y_pred)\n","    try:\n","        auroc = roc_auc_score(y_true, y_prob)\n","    except Exception:\n","        auroc = float(\"nan\")\n","    prec = precision_score(y_true, y_pred, zero_division=0)\n","    rec  = recall_score(y_true, y_pred, zero_division=0)\n","    hacc, dacc = per_class_acc(y_true, y_pred)\n","    return {\n","        \"accuracy\": acc, \"healthy_acc\": hacc, \"diseased_acc\": dacc,\n","        \"f1\": f1, \"auroc\": auroc, \"precision\": prec, \"recall\": rec, \"threshold\": thr,\n","        \"balanced_acc\": 0.5*(hacc+dacc)\n","    }\n","\n","def print_block(name, m):\n","    print(f\"\\n== {name} ==\")\n","    print(f\" Balanced Acc : {m['balanced_acc']:.4f}\")\n","    print(f\"        Acc   : {m['accuracy']:.4f}\")\n","    print(f\" Healthy Acc  : {m['healthy_acc']:.4f}\")\n","    print(f\" Diseased Acc : {m['diseased_acc']:.4f}\")\n","    print(f\" F1           : {m['f1']:.4f}\")\n","    print(f\" AUROC        : {m['auroc']:.4f}\")\n","    print(f\" Precision    : {m['precision']:.4f}\")\n","    print(f\" Recall       : {m['recall']:.4f}\")\n","    print(f\" Threshold    : {m['threshold']:.3f}\")\n","\n","# ---- 1) Build reduced gene_id vector (T_selected) ----\n","# Ensure indices are increasing (keep species order consistent)\n","selected_idx_sorted = np.sort(selected_idx)\n","reduced_species = [species_names[i] for i in selected_idx_sorted]\n","\n","# Map selected species into vocab; unknown -> pad\n","gene_id_list = []\n","missing_vocab = 0\n","for s in reduced_species:\n","    try:\n","        gene_id_list.append(int(vocab[s]))\n","    except Exception:\n","        gene_id_list.append(int(vocab[pad_token]))\n","        missing_vocab += 1\n","if missing_vocab:\n","    print(f\"[Info] {missing_vocab} selected species missing in vocab → padded.\")\n","\n","reduced_gene_ids_vec = torch.tensor(gene_id_list, dtype=torch.long)  # (T_selected,)\n","\n","# ---- 2) Prepare discovery/external matrices with only selected columns ----\n","disc_df_sel = ab[reduced_species].copy().astype(np.float32)           # (N_disc, T_sel)\n","ext_df_sel  = val_ab_masked[reduced_species].copy().astype(np.float32) # (N_ext,  T_sel)\n","\n","# Optional CLR\n","if USE_CLR:\n","    disc_df_sel.iloc[:, :] = clr_transform(disc_df_sel.values).astype(np.float32)\n","    ext_df_sel.iloc[:, :]  = clr_transform(ext_df_sel.values).astype(np.float32)\n","\n","# ---- 3) Load pretrained weights (if not already) ----\n","# Assumes `model` is already created with same config/vocab. If not, re-instantiate before this cell.\n","state = torch.load(save_dir / \"best_model.pt\", map_location=device)\n","model.load_state_dict(state, strict=False)\n","model.to(device)\n","model.eval()\n","\n","# ---- 4) OOM-safe embedding extractor with dynamic batch + reduced sequence ----\n","@torch.no_grad()\n","def extract_cell_emb_reduced(model, gene_ids_vec, values_df, batch_size, use_amp=True):\n","    # values_df: (N, T_sel)\n","    N, Tsel = values_df.shape\n","    gids = gene_ids_vec.to(device)                      # (T_sel,)\n","    assert gids.dim() == 1 and gids.shape[0] == Tsel\n","\n","    def run_with_bs(bs):\n","        embs = []\n","        for i in range(0, N, bs):\n","            xb = torch.from_numpy(values_df.iloc[i:i+bs].values).to(device)  # (B, T_sel)\n","            gid_b = gids.unsqueeze(0).expand(xb.shape[0], -1)                # (B, T_sel)\n","\n","            # No MLM masking (-1); let attention see all tokens\n","            attn = create_attention_mask(xb, config.nhead)                   # shape scales with T_sel^2\n","            src_pad = gid_b.eq(vocab[pad_token]).float()\n","\n","            with torch.amp.autocast('cuda', enabled=(use_amp and config.amp and (device.type=='cuda'))):\n","                out = model(\n","                    gid_b,\n","                    xb,\n","                    attention_mask=attn,\n","                    src_key_padding_mask=src_pad,\n","                )\n","                ce = out[\"cell_emb\"].detach().float().cpu()\n","            embs.append(ce)\n","            # free ASAP\n","            del xb, gid_b, attn, src_pad, out, ce\n","            torch.cuda.empty_cache()\n","        return torch.cat(embs, dim=0).numpy()\n","\n","    bs = int(batch_size)\n","    while True:\n","        try:\n","            torch.cuda.empty_cache()\n","            return run_with_bs(bs)\n","        except RuntimeError as e:\n","            if \"out of memory\" in str(e).lower() and bs > 8 and device.type == 'cuda':\n","                bs = max(8, bs // 2)\n","                print(f\"[OOM] Reducing batch size to {bs} and retrying…\")\n","                gc.collect()\n","                torch.cuda.empty_cache()\n","                continue\n","            # try CPU fallback once\n","            if device.type == 'cuda':\n","                print(\"[Warn] GPU OOM persists. Falling back to CPU for embedding extraction.\")\n","                cpu_dev = torch.device(\"cpu\")\n","                model_cpu = model.to(cpu_dev)\n","                # rerun on CPU in a modest batch\n","                return extract_cell_emb_reduced(model_cpu, gene_ids_vec.cpu(), values_df, batch_size=32, use_amp=False)\n","            else:\n","                raise\n","\n","# ---- 5) Extract embeddings with reduced T ----\n","disc_emb = extract_cell_emb_reduced(model, reduced_gene_ids_vec, disc_df_sel, batch_size=INIT_BATCH_SIZE, use_amp=True)\n","ext_emb  = extract_cell_emb_reduced(model, reduced_gene_ids_vec, ext_df_sel,  batch_size=INIT_BATCH_SIZE, use_amp=True)\n","print(\"Discovery embeddings:\", disc_emb.shape, \" External embeddings:\", ext_emb.shape)\n","\n","# ---- 6) Train head + threshold selection (balanced accuracy on internal split) ----\n","Xd_tr, Xd_val, yd_tr, yd_val = train_test_split(\n","    disc_emb, y_all, test_size=0.1, random_state=42, stratify=y_all\n",")\n","\n","head = make_pipeline(\n","    StandardScaler(with_mean=True, with_std=True),\n","    LogisticRegression(\n","        penalty=\"l2\", C=1.0, solver=\"lbfgs\",\n","        max_iter=HEAD_MAX_ITER, class_weight=\"balanced\"\n","    )\n",")\n","head.fit(Xd_tr, yd_tr)\n","thr = pick_threshold_balacc(yd_val, head.predict_proba(Xd_val)[:,1])\n","\n","# Refit on full discovery and evaluate on external\n","head.fit(disc_emb, y_all)\n","ext_prob = head.predict_proba(ext_emb)[:,1]\n","metrics = pack_metrics(y_val, ext_prob, thr)\n","\n","print_block(\"CLS Embeddings (selected tokens) + Logistic Head\", metrics)\n","pd.DataFrame([metrics])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":292},"id":"XqwTWxn0veaM","executionInfo":{"status":"ok","timestamp":1756434905373,"user_tz":240,"elapsed":82081,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"62c90f7e-d1a6-4af1-ab3d-62e7953c54b7"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["[Info] 288 selected species missing in vocab → padded.\n","Discovery embeddings: (4347, 512)  External embeddings: (782, 512)\n","\n","== CLS Embeddings (selected tokens) + Logistic Head ==\n"," Balanced Acc : 0.4875\n","        Acc   : 0.4847\n"," Healthy Acc  : 0.4915\n"," Diseased Acc : 0.4834\n"," F1           : 0.6144\n"," AUROC        : 0.4994\n"," Precision    : 0.8425\n"," Recall       : 0.4834\n"," Threshold    : 0.474\n"]},{"output_type":"execute_result","data":{"text/plain":["   accuracy  healthy_acc  diseased_acc        f1     auroc  precision  \\\n","0  0.484655     0.491525      0.483434  0.614354  0.499387    0.84252   \n","\n","     recall  threshold  balanced_acc  \n","0  0.483434   0.474275       0.48748  "],"text/html":["\n","  <div id=\"df-42d12050-4d09-42a6-bc8e-1c29523822d2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>healthy_acc</th>\n","      <th>diseased_acc</th>\n","      <th>f1</th>\n","      <th>auroc</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>threshold</th>\n","      <th>balanced_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.484655</td>\n","      <td>0.491525</td>\n","      <td>0.483434</td>\n","      <td>0.614354</td>\n","      <td>0.499387</td>\n","      <td>0.84252</td>\n","      <td>0.483434</td>\n","      <td>0.474275</td>\n","      <td>0.48748</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42d12050-4d09-42a6-bc8e-1c29523822d2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-42d12050-4d09-42a6-bc8e-1c29523822d2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-42d12050-4d09-42a6-bc8e-1c29523822d2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.4846547314578005,\n        \"max\": 0.4846547314578005,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4846547314578005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"healthy_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.4915254237288136,\n        \"max\": 0.4915254237288136,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4915254237288136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diseased_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.48343373493975905,\n        \"max\": 0.48343373493975905,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.48343373493975905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.614354066985646,\n        \"max\": 0.614354066985646,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.614354066985646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auroc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.499387380028589,\n        \"max\": 0.499387380028589,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.499387380028589\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.84251968503937,\n        \"max\": 0.84251968503937,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.84251968503937\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.48343373493975905,\n        \"max\": 0.48343373493975905,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.48343373493975905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.4742751023953547,\n        \"max\": 0.4742751023953547,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4742751023953547\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balanced_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.4874795793342863,\n        \"max\": 0.4874795793342863,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4874795793342863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["# Improve healthy accuracy (specificity) with calibration + constrained thresholding\n","import numpy as np, pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.isotonic import IsotonicRegression\n","from sklearn.metrics import (\n","    accuracy_score, f1_score, roc_auc_score, precision_score,\n","    recall_score, confusion_matrix, roc_curve\n",")\n","\n","TARGET_HACC = 0.70   # << set desired minimum healthy accuracy (e.g., 0.70–0.85)\n","\n","def per_class_acc(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n","    h = (cm[0,0] / cm[0].sum()) if cm[0].sum() else np.nan\n","    d = (cm[1,1] / cm[1].sum()) if cm[1].sum() else np.nan\n","    return float(h), float(d)\n","\n","def pack_metrics(y_true, y_prob, thr):\n","    y_pred = (y_prob >= thr).astype(int)\n","    acc = accuracy_score(y_true, y_pred)\n","    f1  = f1_score(y_true, y_pred)\n","    try:\n","        auroc = roc_auc_score(y_true, y_prob)\n","    except Exception:\n","        auroc = float(\"nan\")\n","    prec = precision_score(y_true, y_pred, zero_division=0)\n","    rec  = recall_score(y_true, y_pred, zero_division=0)\n","    hacc, dacc = per_class_acc(y_true, y_pred)\n","    return {\n","        \"accuracy\": acc, \"healthy_acc\": hacc, \"diseased_acc\": dacc,\n","        \"f1\": f1, \"auroc\": auroc, \"precision\": prec, \"recall\": rec,\n","        \"threshold\": float(thr), \"balanced_acc\": 0.5*(hacc+dacc)\n","    }\n","\n","def summarize(name, m):\n","    print(f\"\\n== {name} ==\")\n","    print(f\" Balanced Acc : {m['balanced_acc']:.4f}\")\n","    print(f\"        Acc   : {m['accuracy']:.4f}\")\n","    print(f\" Healthy Acc  : {m['healthy_acc']:.4f}\")\n","    print(f\" Diseased Acc : {m['diseased_acc']:.4f}\")\n","    print(f\" F1           : {m['f1']:.4f}\")\n","    print(f\" AUROC        : {m['auroc']:.4f}\")\n","    print(f\" Precision    : {m['precision']:.4f}\")\n","    print(f\" Recall       : {m['recall']:.4f}\")\n","    print(f\" Threshold    : {m['threshold']:.3f}\")\n","\n","# 1) internal split for head + calibration (no leakage to external)\n","Xd_tr, Xd_val, yd_tr, yd_val = train_test_split(\n","    disc_emb, y_all, test_size=0.1, random_state=42, stratify=y_all\n",")\n","\n","head = make_pipeline(\n","    StandardScaler(with_mean=True, with_std=True),\n","    LogisticRegression(\n","        penalty=\"l2\", C=1.0, solver=\"lbfgs\",\n","        max_iter=5000, class_weight=\"balanced\"\n","    )\n",")\n","head.fit(Xd_tr, yd_tr)\n","\n","# 2) Isotonic calibration on internal-val\n","val_prob_raw = head.predict_proba(Xd_val)[:,1]\n","iso = IsotonicRegression(out_of_bounds=\"clip\")\n","iso.fit(val_prob_raw, yd_val)\n","val_prob_cal = iso.transform(val_prob_raw)\n","\n","# 3) Choose threshold: maximize balanced accuracy subject to healthy_acc ≥ TARGET_HACC\n","cand = np.unique(np.concatenate([\n","    np.linspace(0, 1, 2001),\n","    roc_curve(yd_val, val_prob_cal)[2],\n","    np.array([0.5])\n","]))\n","best_thr, best_ba = 0.5, -1.0\n","for t in cand:\n","    y_pred = (val_prob_cal >= t).astype(int)\n","    hacc, dacc = per_class_acc(yd_val, y_pred)\n","    ba = 0.5*(hacc + dacc)\n","    if hacc >= TARGET_HACC and ba > best_ba:\n","        best_ba, best_thr = ba, float(t)\n","\n","# fallback: if constraint infeasible, use unconstrained best balanced accuracy\n","if best_ba < 0:\n","    scores = []\n","    for t in cand:\n","        y_pred = (val_prob_cal >= t).astype(int)\n","        hacc, dacc = per_class_acc(yd_val, y_pred)\n","        scores.append(0.5*(hacc + dacc))\n","    best_thr = float(cand[int(np.argmax(scores))])\n","print(f\"Chosen threshold (healthy_acc≥{TARGET_HACC:.2f} constraint): {best_thr:.3f}\")\n","\n","# 4) Refit on FULL discovery and evaluate on EXTERNAL (calibrated probs)\n","head.fit(disc_emb, y_all)\n","ext_prob_raw = head.predict_proba(ext_emb)[:,1]\n","ext_prob_cal = iso.transform(ext_prob_raw)\n","\n","metrics = pack_metrics(y_val, ext_prob_cal, best_thr)\n","summarize(\"CLS Embeddings + Logistic Head (Calibrated, healthy-acc-constrained)\", metrics)\n","\n","# Optional: show nearby operating points so you can pick a different trade-off\n","def small_table(around=best_thr, window=0.05, steps=9):\n","    grid = np.linspace(max(0, around-window), min(1, around+window), steps)\n","    rows = []\n","    for t in grid:\n","        rows.append(pack_metrics(y_val, ext_prob_cal, t) | {\"threshold\": float(t)})\n","    return pd.DataFrame(rows)[[\"threshold\",\"balanced_acc\",\"accuracy\",\"healthy_acc\",\"diseased_acc\",\"f1\",\"auroc\",\"precision\",\"recall\"]]\n","\n","display(small_table())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"WMRVFmL6mC7_","executionInfo":{"status":"ok","timestamp":1756434974980,"user_tz":240,"elapsed":69697,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"5a216cbb-7923-45f1-b253-a962d2a96385"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Chosen threshold (healthy_acc≥0.70 constraint): 0.469\n","\n","== CLS Embeddings + Logistic Head (Calibrated, healthy-acc-constrained) ==\n"," Balanced Acc : 0.4789\n","        Acc   : 0.2570\n"," Healthy Acc  : 0.7966\n"," Diseased Acc : 0.1611\n"," F1           : 0.2692\n"," AUROC        : 0.5056\n"," Precision    : 0.8168\n"," Recall       : 0.1611\n"," Threshold    : 0.469\n"]},{"output_type":"display_data","data":{"text/plain":["   threshold  balanced_acc  accuracy  healthy_acc  diseased_acc        f1  \\\n","0     0.4190      0.487480  0.484655     0.491525      0.483434  0.614354   \n","1     0.4315      0.487480  0.484655     0.491525      0.483434  0.614354   \n","2     0.4440      0.487480  0.484655     0.491525      0.483434  0.614354   \n","3     0.4565      0.487480  0.484655     0.491525      0.483434  0.614354   \n","4     0.4690      0.478877  0.257033     0.796610      0.161145  0.269182   \n","5     0.4815      0.476618  0.253197     0.796610      0.156627  0.262626   \n","6     0.4940      0.511002  0.210997     0.940678      0.081325  0.148966   \n","7     0.5065      0.511002  0.210997     0.940678      0.081325  0.148966   \n","8     0.5190      0.511002  0.210997     0.940678      0.081325  0.148966   \n","\n","     auroc  precision    recall  \n","0  0.50559   0.842520  0.483434  \n","1  0.50559   0.842520  0.483434  \n","2  0.50559   0.842520  0.483434  \n","3  0.50559   0.842520  0.483434  \n","4  0.50559   0.816794  0.161145  \n","5  0.50559   0.812500  0.156627  \n","6  0.50559   0.885246  0.081325  \n","7  0.50559   0.885246  0.081325  \n","8  0.50559   0.885246  0.081325  "],"text/html":["\n","  <div id=\"df-0cdf70b1-2ca0-44aa-b373-707209bd1776\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>balanced_acc</th>\n","      <th>accuracy</th>\n","      <th>healthy_acc</th>\n","      <th>diseased_acc</th>\n","      <th>f1</th>\n","      <th>auroc</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.4190</td>\n","      <td>0.487480</td>\n","      <td>0.484655</td>\n","      <td>0.491525</td>\n","      <td>0.483434</td>\n","      <td>0.614354</td>\n","      <td>0.50559</td>\n","      <td>0.842520</td>\n","      <td>0.483434</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.4315</td>\n","      <td>0.487480</td>\n","      <td>0.484655</td>\n","      <td>0.491525</td>\n","      <td>0.483434</td>\n","      <td>0.614354</td>\n","      <td>0.50559</td>\n","      <td>0.842520</td>\n","      <td>0.483434</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.4440</td>\n","      <td>0.487480</td>\n","      <td>0.484655</td>\n","      <td>0.491525</td>\n","      <td>0.483434</td>\n","      <td>0.614354</td>\n","      <td>0.50559</td>\n","      <td>0.842520</td>\n","      <td>0.483434</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.4565</td>\n","      <td>0.487480</td>\n","      <td>0.484655</td>\n","      <td>0.491525</td>\n","      <td>0.483434</td>\n","      <td>0.614354</td>\n","      <td>0.50559</td>\n","      <td>0.842520</td>\n","      <td>0.483434</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.4690</td>\n","      <td>0.478877</td>\n","      <td>0.257033</td>\n","      <td>0.796610</td>\n","      <td>0.161145</td>\n","      <td>0.269182</td>\n","      <td>0.50559</td>\n","      <td>0.816794</td>\n","      <td>0.161145</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.4815</td>\n","      <td>0.476618</td>\n","      <td>0.253197</td>\n","      <td>0.796610</td>\n","      <td>0.156627</td>\n","      <td>0.262626</td>\n","      <td>0.50559</td>\n","      <td>0.812500</td>\n","      <td>0.156627</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.4940</td>\n","      <td>0.511002</td>\n","      <td>0.210997</td>\n","      <td>0.940678</td>\n","      <td>0.081325</td>\n","      <td>0.148966</td>\n","      <td>0.50559</td>\n","      <td>0.885246</td>\n","      <td>0.081325</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.5065</td>\n","      <td>0.511002</td>\n","      <td>0.210997</td>\n","      <td>0.940678</td>\n","      <td>0.081325</td>\n","      <td>0.148966</td>\n","      <td>0.50559</td>\n","      <td>0.885246</td>\n","      <td>0.081325</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.5190</td>\n","      <td>0.511002</td>\n","      <td>0.210997</td>\n","      <td>0.940678</td>\n","      <td>0.081325</td>\n","      <td>0.148966</td>\n","      <td>0.50559</td>\n","      <td>0.885246</td>\n","      <td>0.081325</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cdf70b1-2ca0-44aa-b373-707209bd1776')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0cdf70b1-2ca0-44aa-b373-707209bd1776 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0cdf70b1-2ca0-44aa-b373-707209bd1776');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-450cd754-7114-4e99-a6c3-c9eba0e2bc99\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-450cd754-7114-4e99-a6c3-c9eba0e2bc99')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-450cd754-7114-4e99-a6c3-c9eba0e2bc99 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(small_table())\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03423265984407287,\n        \"min\": 0.41900000000000004,\n        \"max\": 0.519,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.5065000000000001,\n          0.43150000000000005,\n          0.48150000000000004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balanced_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013971669275091936,\n        \"min\": 0.47661833775781093,\n        \"max\": 0.5110016336532571,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.4788773739023892,\n          0.5110016336532571,\n          0.4874795793342863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1360101991862546,\n        \"min\": 0.21099744245524296,\n        \"max\": 0.4846547314578005,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2570332480818414,\n          0.21099744245524296,\n          0.4846547314578005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"healthy_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21376268229880405,\n        \"min\": 0.4915254237288136,\n        \"max\": 0.940677966101695,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4915254237288136,\n          0.7966101694915254,\n          0.940677966101695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diseased_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19787523950588037,\n        \"min\": 0.08132530120481928,\n        \"max\": 0.48343373493975905,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.16114457831325302,\n          0.08132530120481928,\n          0.48343373493975905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22523498020439786,\n        \"min\": 0.1489655172413793,\n        \"max\": 0.614354066985646,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2691823899371069,\n          0.1489655172413793,\n          0.614354066985646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auroc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.505590157239126,\n        \"max\": 0.505590157239126,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.505590157239126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028409142453884702,\n        \"min\": 0.8125,\n        \"max\": 0.8852459016393442,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.816793893129771\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19787523950588037,\n        \"min\": 0.08132530120481928,\n        \"max\": 0.48343373493975905,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.16114457831325302\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"RF_66VAurFZ6","executionInfo":{"status":"ok","timestamp":1756434975084,"user_tz":240,"elapsed":12,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["# unfreeze last several layers to fine tune"],"metadata":{"id":"b5--w6arrInV"}},{"cell_type":"code","source":["# # ============================\n","# #  - Warmup head-only\n","# #  - Unfreeze last K blocks\n","# #  - Small LR, reduced sequence\n","# # ============================\n","# import os, gc, math, time, warnings\n","# import numpy as np, pandas as pd\n","# import torch, torch.nn as nn, torch.nn.functional as F\n","# from torch.utils.data import DataLoader, TensorDataset\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.metrics import (\n","#     accuracy_score, f1_score, roc_auc_score,\n","#     precision_score, recall_score, confusion_matrix, roc_curve\n","# )\n","\n","# warnings.filterwarnings(\"ignore\")\n","# os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n","\n","# # ---- knobs ----\n","# USE_CLR         = True\n","# BATCH_SIZE      = 64        # safe default; increase if have memory => get OOM error\n","# HEAD_WARMUP_EPS = 1         # head-only warmup\n","# FT_EPS          = 3         # epochs after unfreezing last K blocks\n","# UNFREEZE_K      = 1         # how many encoder blocks to unfreeze (last K)\n","# LR_HEAD_WARMUP  = 1e-3\n","# LR_HEAD_FT      = 1e-3\n","# LR_ENC_FT       = 1e-5\n","# WEIGHT_DECAY    = 0.0\n","# AMP_ENABLED     = bool(getattr(config, \"amp\", False)) and (device.type == \"cuda\")\n","\n","# # ---- helpers ----\n","# def clr_transform(X, eps=1e-6):\n","#     Xp = X + eps\n","#     gm = np.exp(np.mean(np.log(Xp), axis=1, keepdims=True))\n","#     return np.log(Xp / gm)\n","\n","# def per_class_acc(y_true, y_pred):\n","#     cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n","#     h = (cm[0,0] / cm[0].sum()) if cm[0].sum() else np.nan\n","#     d = (cm[1,1] / cm[1].sum()) if cm[1].sum() else np.nan\n","#     return float(h), float(d)\n","\n","# def balanced_accuracy_at_threshold(y_true, y_prob, thr):\n","#     y_pred = (y_prob >= thr).astype(int)\n","#     h,d = per_class_acc(y_true, y_pred)\n","#     return 0.5*(h+d)\n","\n","# def pick_threshold_balacc(y_true, y_prob):\n","#     fpr, tpr, thr = roc_curve(y_true, y_prob)\n","#     cand = np.unique(np.clip(np.concatenate([thr, np.array([0.5])]), 0, 1))\n","#     best_t, best_ba = 0.5, -1.0\n","#     for t in cand:\n","#         ba = balanced_accuracy_at_threshold(y_true, y_prob, t)\n","#         if ba > best_ba:\n","#             best_ba, best_t = ba, t\n","#     return float(best_t)\n","\n","# def pack_metrics(y_true, y_prob, thr):\n","#     y_pred = (y_prob >= thr).astype(int)\n","#     acc = accuracy_score(y_true, y_pred)\n","#     f1  = f1_score(y_true, y_pred)\n","#     try:\n","#         auroc = roc_auc_score(y_true, y_prob)\n","#     except Exception:\n","#         auroc = float(\"nan\")\n","#     prec = precision_score(y_true, y_pred, zero_division=0)\n","#     rec  = recall_score(y_true, y_pred, zero_division=0)\n","#     hacc, dacc = per_class_acc(y_true, y_pred)\n","#     return {\n","#         \"accuracy\": acc, \"healthy_acc\": hacc, \"diseased_acc\": dacc,\n","#         \"f1\": f1, \"auroc\": auroc, \"precision\": prec, \"recall\": rec, \"threshold\": thr,\n","#         \"balanced_acc\": 0.5*(hacc+dacc)\n","#     }\n","\n","# def print_block(name, m):\n","#     print(f\"\\n== {name} ==\")\n","#     print(f\" Balanced Acc : {m['balanced_acc']:.4f}\")\n","#     print(f\"        Acc   : {m['accuracy']:.4f}\")\n","#     print(f\" Healthy Acc  : {m['healthy_acc']:.4f}\")\n","#     print(f\" Diseased Acc : {m['diseased_acc']:.4f}\")\n","#     print(f\" F1           : {m['f1']:.4f}\")\n","#     print(f\" AUROC        : {m['auroc']:.4f}\")\n","#     print(f\" Precision    : {m['precision']:.4f}\")\n","#     print(f\" Recall       : {m['recall']:.4f}\")\n","#     print(f\" Threshold    : {m['threshold']:.3f}\")\n","\n","# # ---- 1) Reduced sequence from Lasso-selected species ----\n","# selected_idx_sorted = np.sort(selected_idx)\n","# reduced_species = [species_names[i] for i in selected_idx_sorted]\n","\n","# # Map to vocab; OOV -> pad\n","# gene_id_list = []\n","# for s in reduced_species:\n","#     try:\n","#         gene_id_list.append(int(vocab[s]))\n","#     except Exception:\n","#         gene_id_list.append(int(vocab[pad_token]))\n","# reduced_gene_ids_vec = torch.tensor(gene_id_list, dtype=torch.long)\n","\n","# # Build discovery/external matrices with only selected columns\n","# disc_df_sel = ab[reduced_species].copy().astype(np.float32)\n","# ext_df_sel  = val_ab_masked[reduced_species].copy().astype(np.float32)\n","# if USE_CLR:\n","#     disc_df_sel.iloc[:, :] = clr_transform(disc_df_sel.values).astype(np.float32)\n","#     ext_df_sel.iloc[:, :]  = clr_transform(ext_df_sel.values).astype(np.float32)\n","\n","# # ---- 2) DataLoaders (values only; gene ids are fixed and expanded per batch) ----\n","# Xd_tr_df, Xd_val_df, yd_tr, yd_val = train_test_split(\n","#     disc_df_sel, y_all, test_size=0.1, random_state=42, stratify=y_all\n","# )\n","# def mk_loader(df, y, bs, shuffle):\n","#     x = torch.from_numpy(df.values.astype(np.float32))\n","#     y = torch.from_numpy(np.asarray(y, dtype=np.int64))\n","#     return DataLoader(TensorDataset(x, y), batch_size=bs, shuffle=shuffle, drop_last=False, pin_memory=True)\n","# train_loader = mk_loader(Xd_tr_df, yd_tr, BATCH_SIZE, True)\n","# valid_loader = mk_loader(Xd_val_df, yd_val, BATCH_SIZE, False)\n","\n","# # External (just features; labels are y_val)\n","# ext_loader = DataLoader(torch.from_numpy(ext_df_sel.values.astype(np.float32)),\n","#                         batch_size=BATCH_SIZE, shuffle=False, drop_last=False, pin_memory=True)\n","\n","# # ---- 3) Small torch head for classification on CLS embedding ----\n","# class ClsHead(nn.Module):\n","#     def __init__(self, in_dim=512, hidden=128, p=0.2):\n","#         super().__init__()\n","#         self.net = nn.Sequential(\n","#             nn.LayerNorm(in_dim),\n","#             nn.Linear(in_dim, hidden),\n","#             nn.ReLU(),\n","#             nn.Dropout(p),\n","#             nn.Linear(hidden, 1),\n","#         )\n","#     def forward(self, z):\n","#         return self.net(z).squeeze(-1)\n","\n","# head = ClsHead(in_dim=disc_df_sel.shape[1] * 0 + 512).to(device)  # 512 from your embeddings\n","\n","# # ---- 4) Load pretrained weights (if not already) ----\n","# state = torch.load(save_dir / \"best_model.pt\", map_location=device)\n","# model.load_state_dict(state, strict=False)\n","# model.to(device)\n","\n","# # ---- 5) Freeze everything, then selectively unfreeze last K later ----\n","# for p in model.parameters():\n","#     p.requires_grad = False\n","\n","# # Try to locate encoder blocks robustly\n","# enc_layers = None\n","# if hasattr(model, \"transformer_encoder\") and hasattr(model.transformer_encoder, \"layers\"):\n","#     enc_layers = list(model.transformer_encoder.layers)\n","# else:\n","#     # fallback: collect TransformerEncoderLayer modules in order of appearance\n","#     from torch.nn.modules.transformer import TransformerEncoderLayer\n","#     enc_layers = [m for m in model.modules() if isinstance(m, TransformerEncoderLayer)]\n","# assert len(enc_layers) > 0, \"Could not locate transformer encoder layers to unfreeze.\"\n","\n","# # ---- loss and class balance ----\n","# pos = max(1, int((np.asarray(yd_tr)==1).sum()))\n","# neg = max(1, int((np.asarray(yd_tr)==0).sum()))\n","# pos_weight = torch.tensor([neg/pos], device=device, dtype=torch.float32)\n","# bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","\n","# scaler = torch.amp.GradScaler('cuda', enabled=AMP_ENABLED)\n","\n","# def forward_cell_emb(xb):\n","#     # xb: (B, T_sel) values\n","#     gids = reduced_gene_ids_vec.to(device).unsqueeze(0).expand(xb.size(0), -1)  # (B, T_sel)\n","#     attn = create_attention_mask(xb, config.nhead)\n","#     src_pad = gids.eq(vocab[pad_token]).float()\n","#     out = model(gids, xb, attention_mask=attn, src_key_padding_mask=src_pad)\n","#     return out[\"cell_emb\"]  # (B, 512)\n","\n","# def run_epoch(head, loaders, train_mode=True, opt=None):\n","#     if train_mode:\n","#         head.train()\n","#         model.train()  # dropout on in the unfrozen blocks\n","#     else:\n","#         head.eval()\n","#         model.eval()\n","#     tot_loss, tot, probs, trues = 0.0, 0, [], []\n","#     for batch in loaders:\n","#         if train_mode:\n","#             xb, yb = batch[0].to(device), batch[1].to(device)\n","#         else:\n","#             xb, yb = batch[0].to(device), batch[1].to(device)\n","#         with torch.amp.autocast('cuda', enabled=AMP_ENABLED):\n","#             z = forward_cell_emb(xb)                 # (B, 512)\n","#             logit = head(z)                          # (B,)\n","#             loss = bce(logit, yb.float())\n","#         if train_mode:\n","#             opt.zero_grad(set_to_none=True)\n","#             scaler.scale(loss).backward()\n","#             torch.nn.utils.clip_grad_norm_(head.parameters(), 1.0)\n","#             scaler.step(opt)\n","#             scaler.update()\n","#         with torch.no_grad():\n","#             prob = torch.sigmoid(logit).detach().float()\n","#             tot_loss += loss.detach().float().item() * xb.size(0)\n","#             tot += xb.size(0)\n","#             probs.append(prob.cpu())\n","#             trues.append(yb.cpu())\n","#         del xb, yb, z, logit, loss\n","#         torch.cuda.empty_cache()\n","#     probs = torch.cat(probs).numpy()\n","#     trues = torch.cat(trues).numpy()\n","#     return tot_loss / max(1, tot), probs, trues\n","\n","# # ---- 6) Stage A: warmup head-only ----\n","# opt_head = torch.optim.AdamW(head.parameters(), lr=LR_HEAD_WARMUP, weight_decay=WEIGHT_DECAY)\n","# for _ in range(HEAD_WARMUP_EPS):\n","#     loss_tr, _, _ = run_epoch(head, train_loader, train_mode=True, opt=opt_head)\n","#     loss_va, p_va, y_va = run_epoch(head, valid_loader, train_mode=False)\n","#     print(f\"[Warmup] train_loss={loss_tr:.4f}  val_loss={loss_va:.4f}\")\n","# thr0 = pick_threshold_balacc(y_va, p_va)\n","\n","# # ---- 7) Stage B: unfreeze last K blocks + fine-tune ----\n","# for p in model.parameters():\n","#     p.requires_grad = False\n","# for layer in enc_layers[-UNFREEZE_K:]:\n","#     for p in layer.parameters():\n","#         p.requires_grad = True\n","\n","# # two param groups: encoder (small LR) and head (bigger LR)\n","# enc_params = [p for layer in enc_layers[-UNFREEZE_K:] for p in layer.parameters() if p.requires_grad]\n","# opt = torch.optim.AdamW(\n","#     [{\"params\": head.parameters(), \"lr\": LR_HEAD_FT},\n","#      {\"params\": enc_params,        \"lr\": LR_ENC_FT}],\n","#     weight_decay=WEIGHT_DECAY\n","# )\n","\n","# best_val = float(\"inf\")\n","# for ep in range(1, FT_EPS+1):\n","#     tl, _, _ = run_epoch(head, train_loader, train_mode=True, opt=opt)\n","#     vl, p_va, y_va = run_epoch(head, valid_loader, train_mode=False)\n","#     print(f\"[FT {ep}/{FT_EPS}] train_loss={tl:.4f}  val_loss={vl:.4f}\")\n","#     if vl < best_val:\n","#         best_val = vl\n","#         best_head_state = {k: v.detach().cpu().clone() for k,v in head.state_dict().items()}\n","#         # (encoder is small change; we skip deep copy for speed)\n","\n","# # restore best head weights if improved\n","# if 'best_head_state' in locals():\n","#     head.load_state_dict(best_head_state)\n","\n","# # ---- 8) Threshold from internal val (balanced accuracy) ----\n","# thr = pick_threshold_balacc(y_va, p_va)\n","\n","# # ---- 9) Evaluate on external ----\n","# @torch.no_grad()\n","# def infer_external(head, loader):\n","#     head.eval(); model.eval()\n","#     probs = []\n","#     for xb in loader:\n","#         xb = xb.to(device)\n","#         with torch.amp.autocast('cuda', enabled=AMP_ENABLED):\n","#             z = forward_cell_emb(xb)\n","#             logit = head(z)\n","#             pr = torch.sigmoid(logit).detach().float().cpu()\n","#         probs.append(pr)\n","#         del xb, z, logit, pr\n","#         torch.cuda.empty_cache()\n","#     return torch.cat(probs).numpy()\n","\n","# ext_prob = infer_external(head, ext_loader)\n","# metrics = pack_metrics(y_val, ext_prob, thr)\n","# print_block(f\"End-to-End FT (unfrozen last {UNFREEZE_K})\", metrics)\n","\n","# # Optional: small grid around chosen threshold\n","# def small_table(around=thr, window=0.05, steps=9):\n","#     grid = np.linspace(max(0, around-window), min(1, around+window), steps)\n","#     rows = []\n","#     for t in grid:\n","#         rows.append(pack_metrics(y_val, ext_prob, t) | {\"threshold\": float(t)})\n","#     return pd.DataFrame(rows).loc[:, [\"threshold\",\"balanced_acc\",\"accuracy\",\"healthy_acc\",\"diseased_acc\",\"f1\",\"auroc\",\"precision\",\"recall\"]]\n","\n","# display(small_table())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"TBuJNZJarGFV","executionInfo":{"status":"error","timestamp":1756435019140,"user_tz":240,"elapsed":43973,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"f46fa0ac-5771-40d1-ef4d-5ab44c16e9f8"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["[Warmup] train_loss=0.8263  val_loss=0.7876\n","[FT 1/3] train_loss=0.8203  val_loss=0.7950\n","[FT 2/3] train_loss=0.8106  val_loss=0.7716\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute '_log'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2812740644.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0mbest_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFT_EPS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0mvl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[FT {ep}/{FT_EPS}] train_loss={tl:.4f}  val_loss={vl:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2812740644.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(head, loaders, train_mode, opt)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/integration/torch/wandb_torch.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hook_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/integration/torch/wandb_torch.py\u001b[0m in \u001b[0;36m_callback\u001b[0;34m(grad, log_track)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlog_track_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/integration/torch/wandb_torch.py\u001b[0m in \u001b[0;36mlog_tensor_stats\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         wandb.run._log(\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_histogram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mcommit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_log'"]}]},{"cell_type":"code","source":["# --- kill wandb and purge any hooks it left on the model ---\n","import os, gc, torch\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","try:\n","    import wandb\n","    try: wandb.finish()\n","    except: pass\n","    try: wandb.init(mode=\"disabled\")  # creates a dummy run to silence internals\n","    except: pass\n","except Exception:\n","    pass\n","\n","# Remove any forward/backward hooks wandb may have attached\n","for m in model.modules():\n","    for name in (\"_forward_hooks\", \"_forward_pre_hooks\", \"_backward_hooks\"):\n","        d = getattr(m, name, None)\n","        if isinstance(d, dict):\n","            for h in list(d.values()):\n","                try: h.remove()\n","                except Exception: pass\n","            d.clear()\n","\n","gc.collect()\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","print(\"wandb disabled and hooks cleared.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"id":"_SNmQXyos6lF","executionInfo":{"status":"ok","timestamp":1756435486388,"user_tz":240,"elapsed":271,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"ea004c70-5b6d-4fcd-cc48-99c1f2cfc8b4"},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["wandb disabled and hooks cleared.\n"]}]},{"cell_type":"code","source":["# If optimizer 'opt' somehow got cleared, rebuild it:\n","UNFREEZE_K = 2\n","FT_EPS = 30\n","try:\n","    opt\n","except NameError:\n","    enc_params = [p for layer in enc_layers[-UNFREEZE_K:] for p in layer.parameters() if p.requires_grad]\n","    opt = torch.optim.AdamW(\n","        [{\"params\": head.parameters(), \"lr\": LR_HEAD_FT},\n","         {\"params\": enc_params,        \"lr\": LR_ENC_FT}],\n","        weight_decay=WEIGHT_DECAY\n","    )\n","\n","best_val = float(\"inf\")\n","best_head_state = None\n","for ep in range(1, FT_EPS+1):\n","    tl, _, _ = run_epoch(head, train_loader, train_mode=True, opt=opt)\n","    vl, p_va, y_va = run_epoch(head, valid_loader, train_mode=False)\n","    print(f\"[FT {ep}/{FT_EPS}] train_loss={tl:.4f}  val_loss={vl:.4f}\")\n","    if vl < best_val:\n","        best_val = vl\n","        best_head_state = {k: v.detach().cpu().clone() for k, v in head.state_dict().items()}\n","\n","if best_head_state is not None:\n","    head.load_state_dict(best_head_state)\n","\n","# Pick threshold on internal-val for balanced accuracy\n","thr = pick_threshold_balacc(y_va, p_va)\n","\n","# Evaluate on external\n","@torch.no_grad()\n","def infer_external(head, loader):\n","    head.eval(); model.eval()\n","    probs = []\n","    for xb in loader:\n","        xb = xb.to(device)\n","        with torch.amp.autocast('cuda', enabled=AMP_ENABLED):\n","            z = forward_cell_emb(xb)\n","            logit = head(z)\n","            pr = torch.sigmoid(logit).detach().float().cpu()\n","        probs.append(pr)\n","    return torch.cat(probs).numpy()\n","\n","ext_prob = infer_external(head, ext_loader)\n","\n","from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score,\n","                             precision_score, recall_score, confusion_matrix)\n","\n","def per_class_acc(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n","    h = (cm[0,0] / cm[0].sum()) if cm[0].sum() else float(\"nan\")\n","    d = (cm[1,1] / cm[1].sum()) if cm[1].sum() else float(\"nan\")\n","    return h, d\n","\n","def pack_metrics(y_true, y_prob, thr):\n","    y_pred = (y_prob >= thr).astype(int)\n","    acc = accuracy_score(y_true, y_pred)\n","    f1  = f1_score(y_true, y_pred)\n","    try: auroc = roc_auc_score(y_true, y_prob)\n","    except: auroc = float(\"nan\")\n","    prec = precision_score(y_true, y_pred, zero_division=0)\n","    rec  = recall_score(y_true, y_pred, zero_division=0)\n","    hacc, dacc = per_class_acc(y_true, y_pred)\n","    return {\"accuracy\": acc, \"healthy_acc\": hacc, \"diseased_acc\": dacc,\n","            \"f1\": f1, \"auroc\": auroc, \"precision\": prec, \"recall\": rec,\n","            \"threshold\": float(thr), \"balanced_acc\": 0.5*(hacc+dacc)}\n","\n","def print_block(name, m):\n","    print(f\"\\n== {name} ==\")\n","    print(f\" Balanced Acc : {m['balanced_acc']:.4f}\")\n","    print(f\"        Acc   : {m['accuracy']:.4f}\")\n","    print(f\" Healthy Acc  : {m['healthy_acc']:.4f}\")\n","    print(f\" Diseased Acc : {m['diseased_acc']:.4f}\")\n","    print(f\" F1           : {m['f1']:.4f}\")\n","    print(f\" AUROC        : {m['auroc']:.4f}\")\n","    print(f\" Precision    : {m['precision']:.4f}\")\n","    print(f\" Recall       : {m['recall']:.4f}\")\n","    print(f\" Threshold    : {m['threshold']:.3f}\")\n","\n","metrics = pack_metrics(y_val, ext_prob, thr)\n","print_block(f\"End-to-End FT (unfrozen last {UNFREEZE_K})\", metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XNpCJ_vs7ur","executionInfo":{"status":"ok","timestamp":1756436025534,"user_tz":240,"elapsed":412673,"user":{"displayName":"Siyao Zhu","userId":"18112458800520300765"}},"outputId":"223e137b-0d23-4d18-af74-edd2ae4ebee3"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["[FT 1/30] train_loss=0.8135  val_loss=0.7748\n","[FT 2/30] train_loss=0.8082  val_loss=0.7679\n","[FT 3/30] train_loss=0.7999  val_loss=0.7677\n","[FT 4/30] train_loss=0.8011  val_loss=0.7668\n","[FT 5/30] train_loss=0.7970  val_loss=0.7607\n","[FT 6/30] train_loss=0.7965  val_loss=0.7648\n","[FT 7/30] train_loss=0.7972  val_loss=0.7702\n","[FT 8/30] train_loss=0.7980  val_loss=0.8144\n","[FT 9/30] train_loss=0.8159  val_loss=0.7888\n","[FT 10/30] train_loss=0.7936  val_loss=0.7471\n","[FT 11/30] train_loss=0.7975  val_loss=0.7806\n","[FT 12/30] train_loss=0.7987  val_loss=0.7752\n","[FT 13/30] train_loss=0.7841  val_loss=0.8163\n","[FT 14/30] train_loss=0.7948  val_loss=0.7722\n","[FT 15/30] train_loss=0.7887  val_loss=0.7944\n","[FT 16/30] train_loss=0.7855  val_loss=0.7769\n","[FT 17/30] train_loss=0.7801  val_loss=0.7895\n","[FT 18/30] train_loss=0.7879  val_loss=0.7716\n","[FT 19/30] train_loss=0.7840  val_loss=0.7614\n","[FT 20/30] train_loss=0.7887  val_loss=0.7562\n","[FT 21/30] train_loss=0.7924  val_loss=0.7771\n","[FT 22/30] train_loss=0.7871  val_loss=0.7628\n","[FT 23/30] train_loss=0.7875  val_loss=0.7590\n","[FT 24/30] train_loss=0.7800  val_loss=0.7896\n","[FT 25/30] train_loss=0.7878  val_loss=0.7966\n","[FT 26/30] train_loss=0.7855  val_loss=0.7846\n","[FT 27/30] train_loss=0.7824  val_loss=0.7977\n","[FT 28/30] train_loss=0.7849  val_loss=0.7635\n","[FT 29/30] train_loss=0.7802  val_loss=0.7879\n","[FT 30/30] train_loss=0.7788  val_loss=0.7928\n","\n","== End-to-End FT (unfrozen last 2) ==\n"," Balanced Acc : 0.5573\n","        Acc   : 0.5026\n"," Healthy Acc  : 0.6356\n"," Diseased Acc : 0.4789\n"," F1           : 0.6205\n"," AUROC        : 0.5817\n"," Precision    : 0.8809\n"," Recall       : 0.4789\n"," Threshold    : 0.637\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1rKNpK9NLGK4KMgLEvRHs5daRmqn5LhFg","timestamp":1754515701535},{"file_id":"1W86lbwtWa07mQcqSmqMZXeDSWH-lZ2Ml","timestamp":1743462077913}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}